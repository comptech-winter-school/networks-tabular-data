{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TabNet_autoML_benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zUhToOclFr0D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz-wYqaiF-sg"
      },
      "source": [
        "#Танцы с бубном для запуска AutoML benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHXStE8EZqoh"
      },
      "source": [
        "##Установка и проверка необходимых пакетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkbC5l5jcB8A",
        "outputId": "03f14533-3172-4559-c162-d441e15dc080"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l0JanGnGKP5"
      },
      "source": [
        "Разработчики просят такие вещи для запуска\n",
        "\n",
        "boto3>=1.9,<2.0\n",
        "\n",
        "liac-arff>=2.5,<3.0\n",
        "\n",
        "numpy>=1.15,<2.0\n",
        "\n",
        "pandas>=0.23,<2.0\n",
        "\n",
        "psutil>=5.4,<6.0\n",
        "\n",
        "ruamel.yaml>=0.15,<1.0\n",
        "\n",
        "openml==0.11.0\n",
        "\n",
        "scikit-learn>=0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46_gMNasJQhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e494228-0db2-4875-c84c-82f6339d186a"
      },
      "source": [
        "!pip install boto3"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (1.17.2)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.3.4)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.2 in /usr/local/lib/python3.6/dist-packages (from boto3) (1.20.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.2->boto3) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.2->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.2->boto3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2sRRHjgHQ7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2298a214-806e-4246-9e17-449d865ae8ba"
      },
      "source": [
        "!pip install liac-arff"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oyd-QuSHd4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d9f36d-bff3-4afa-c344-2602d0f7eb6a"
      },
      "source": [
        "!pip install ruamel.yaml"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.6/dist-packages (0.16.12)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml) (0.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd_GM-SBH139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f4ce42-bb0d-46a0-b125-19bf9dffc248"
      },
      "source": [
        "!pip install openml"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openml in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from openml) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from openml) (2.8.1)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from openml) (2.5.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from openml) (1.1.5)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (from openml) (0.12.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from openml) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from openml) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.6/dist-packages (from openml) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->openml) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->openml) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->openml) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->openml) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->openml) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->openml) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->openml) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vng9h21kY4l6"
      },
      "source": [
        "Удостоверимся, что всё есть (команды должны выводить имя пакета и его версию, если не выводит, значит, пакет не установлен)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zbKEkT_G5LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd08827e-5b55-499c-81b5-cbd35c8b0a02"
      },
      "source": [
        "!pip list -v | grep boto3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boto3                         1.17.2          /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LtcjEDSHK7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ccbee2-4f58-4fbe-d3f7-58e38226c68d"
      },
      "source": [
        "!pip list -v | grep liac-arff"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liac-arff                     2.5.0           /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5L_nFeXHXnp",
        "outputId": "96ae4a6e-1ea7-4508-b1a0-f1410f461643"
      },
      "source": [
        "!pip list -v | grep psutil"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "psutil                        5.4.8           /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbGNiOI2ZVY-",
        "outputId": "24edae74-c728-4ecd-9dab-fd29bb6dda01"
      },
      "source": [
        "!pip list -v | grep numpy"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy                         1.19.5          /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMQkv1MLZVJo",
        "outputId": "7a7bcecb-c1d5-4c9b-f67d-a543bd7ea94c"
      },
      "source": [
        "!pip list -v | grep pandas"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pandas                        1.1.5           /usr/local/lib/python3.6/dist-packages pip      \n",
            "pandas-datareader             0.9.0           /usr/local/lib/python3.6/dist-packages pip      \n",
            "pandas-gbq                    0.13.3          /usr/local/lib/python3.6/dist-packages pip      \n",
            "pandas-profiling              1.4.1           /usr/local/lib/python3.6/dist-packages pip      \n",
            "sklearn-pandas                1.8.0           /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVVzSH6CHu2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0e43f8-1e13-4d50-c108-85e6a3986862"
      },
      "source": [
        "!pip list -v | grep ruamel"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ruamel.yaml                   0.16.12         /usr/local/lib/python3.6/dist-packages pip      \n",
            "ruamel.yaml.clib              0.2.2           /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tMVYIT5H7HA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fc01fc-32ca-47e7-f9b7-4451fdda9bd0"
      },
      "source": [
        "!pip list -v | grep openml"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openml                        0.11.0          /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWSMUmKZIvsQ",
        "outputId": "d94708bf-f244-4115-e1ff-6e49fc7b8c29"
      },
      "source": [
        "!pip list -v | grep scikit-learn"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scikit-learn                  0.22.2.post1    /usr/local/lib/python3.6/dist-packages pip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMBJNHQ8ZyJU"
      },
      "source": [
        "Теперь попробуем установить сам benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopdr969Zppg",
        "outputId": "3ed7188c-a1e2-4d3c-d714-27420b801750"
      },
      "source": [
        "%cd gdrive/MyDrive/AutoML_benchmark/"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/AutoML_benchmark/'\n",
            "/content/gdrive/MyDrive/AutoML_benchmark/automlbenchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoxysJNznbEX"
      },
      "source": [
        "IS_REP_CLONED = True"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYpTBOCAc980"
      },
      "source": [
        "if IS_REP_CLONED == False:\n",
        "    ! git clone https://github.com/openml/automlbenchmark.git"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Hi1VPfdHsC",
        "outputId": "7a3e7cad-2afd-4a87-bdcd-8056e579abe5"
      },
      "source": [
        "%cd automlbenchmark/"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'automlbenchmark/'\n",
            "/content/gdrive/MyDrive/AutoML_benchmark/automlbenchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjvlw9PpenNM",
        "outputId": "317a68d0-d80f-4701-c21a-3fd329b47e42"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amlb\t\t      frameworks\t  reports\t    runbenchmark.py\n",
            "aws_monitor.ipynb     LICENSE\t\t  requirements.txt  runscores.py\n",
            "dev-requirements.txt  logs\t\t  resources\t    runstable.sh\n",
            "docs\t\t      pytest.ini\t  results\t    scripts\n",
            "examples\t      recover_results.py  runall.py\t    tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUhToOclFr0D"
      },
      "source": [
        "#Реализация TabNet на tensorflow (от авторов из Google)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOAVbINCFcdb"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2021 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"TabNet model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def glu(act, n_units):\n",
        "  \"\"\"Generalized linear unit nonlinear activation.\"\"\"\n",
        "  return act[:, :n_units] * tf.nn.sigmoid(act[:, n_units:])\n",
        "\n",
        "\n",
        "class TabNet(object):\n",
        "  \"\"\"TabNet model class.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               columns,\n",
        "               num_features,\n",
        "               feature_dim,\n",
        "               output_dim,\n",
        "               num_decision_steps,\n",
        "               relaxation_factor,\n",
        "               batch_momentum,\n",
        "               virtual_batch_size,\n",
        "               num_classes,\n",
        "               epsilon=0.00001):\n",
        "    \"\"\"Initializes a TabNet instance.\n",
        "    Args:\n",
        "      columns: The Tensorflow column names for the dataset.\n",
        "      num_features: The number of input features (i.e the number of columns for\n",
        "        tabular data assuming each feature is represented with 1 dimension).\n",
        "      feature_dim: Dimensionality of the hidden representation in feature\n",
        "        transformation block. Each layer first maps the representation to a\n",
        "        2*feature_dim-dimensional output and half of it is used to determine the\n",
        "        nonlinearity of the GLU activation where the other half is used as an\n",
        "        input to GLU, and eventually feature_dim-dimensional output is\n",
        "        transferred to the next layer.\n",
        "      output_dim: Dimensionality of the outputs of each decision step, which is\n",
        "        later mapped to the final classification or regression output.\n",
        "      num_decision_steps: Number of sequential decision steps.\n",
        "      relaxation_factor: Relaxation factor that promotes the reuse of each\n",
        "        feature at different decision steps. When it is 1, a feature is enforced\n",
        "        to be used only at one decision step and as it increases, more\n",
        "        flexibility is provided to use a feature at multiple decision steps.\n",
        "      batch_momentum: Momentum in ghost batch normalization.\n",
        "      virtual_batch_size: Virtual batch size in ghost batch normalization. The\n",
        "        overall batch size should be an integer multiple of virtual_batch_size.\n",
        "      num_classes: Number of output classes.\n",
        "      epsilon: A small number for numerical stability of the entropy calcations.\n",
        "    Returns:\n",
        "      A TabNet instance.\n",
        "    \"\"\"\n",
        "\n",
        "    self.columns = columns\n",
        "    self.num_features = num_features\n",
        "    self.feature_dim = feature_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.num_decision_steps = num_decision_steps\n",
        "    self.relaxation_factor = relaxation_factor\n",
        "    self.batch_momentum = batch_momentum\n",
        "    self.virtual_batch_size = virtual_batch_size\n",
        "    self.num_classes = num_classes\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def encoder(self, data, reuse, is_training):\n",
        "    \"\"\"TabNet encoder model.\"\"\"\n",
        "\n",
        "    with tf.variable_scope(\"Encoder\", reuse=reuse):\n",
        "\n",
        "      # Reads and normalizes input features.\n",
        "      features = tf.feature_column.input_layer(data, self.columns)\n",
        "      features = tf.layers.batch_normalization(\n",
        "          features, training=is_training, momentum=self.batch_momentum)\n",
        "      batch_size = tf.shape(features)[0]\n",
        "\n",
        "      # Initializes decision-step dependent variables.\n",
        "      output_aggregated = tf.zeros([batch_size, self.output_dim])\n",
        "      masked_features = features\n",
        "      mask_values = tf.zeros([batch_size, self.num_features])\n",
        "      aggregated_mask_values = tf.zeros([batch_size, self.num_features])\n",
        "      complemantary_aggregated_mask_values = tf.ones(\n",
        "          [batch_size, self.num_features])\n",
        "      total_entropy = 0\n",
        "\n",
        "      if is_training:\n",
        "        v_b = self.virtual_batch_size\n",
        "      else:\n",
        "        v_b = 1\n",
        "\n",
        "      for ni in range(self.num_decision_steps):\n",
        "\n",
        "        # Feature transformer with two shared and two decision step dependent\n",
        "        # blocks is used below.\n",
        "\n",
        "        reuse_flag = (ni > 0)\n",
        "\n",
        "        transform_f1 = tf.layers.dense(\n",
        "            masked_features,\n",
        "            self.feature_dim * 2,\n",
        "            name=\"Transform_f1\",\n",
        "            reuse=reuse_flag,\n",
        "            use_bias=False)\n",
        "        transform_f1 = tf.layers.batch_normalization(\n",
        "            transform_f1,\n",
        "            training=is_training,\n",
        "            momentum=self.batch_momentum,\n",
        "            virtual_batch_size=v_b)\n",
        "        transform_f1 = glu(transform_f1, self.feature_dim)\n",
        "\n",
        "        transform_f2 = tf.layers.dense(\n",
        "            transform_f1,\n",
        "            self.feature_dim * 2,\n",
        "            name=\"Transform_f2\",\n",
        "            reuse=reuse_flag,\n",
        "            use_bias=False)\n",
        "        transform_f2 = tf.layers.batch_normalization(\n",
        "            transform_f2,\n",
        "            training=is_training,\n",
        "            momentum=self.batch_momentum,\n",
        "            virtual_batch_size=v_b)\n",
        "        transform_f2 = (glu(transform_f2, self.feature_dim) +\n",
        "                        transform_f1) * np.sqrt(0.5)\n",
        "\n",
        "        transform_f3 = tf.layers.dense(\n",
        "            transform_f2,\n",
        "            self.feature_dim * 2,\n",
        "            name=\"Transform_f3\" + str(ni),\n",
        "            use_bias=False)\n",
        "        transform_f3 = tf.layers.batch_normalization(\n",
        "            transform_f3,\n",
        "            training=is_training,\n",
        "            momentum=self.batch_momentum,\n",
        "            virtual_batch_size=v_b)\n",
        "        transform_f3 = (glu(transform_f3, self.feature_dim) +\n",
        "                        transform_f2) * np.sqrt(0.5)\n",
        "\n",
        "        transform_f4 = tf.layers.dense(\n",
        "            transform_f3,\n",
        "            self.feature_dim * 2,\n",
        "            name=\"Transform_f4\" + str(ni),\n",
        "            use_bias=False)\n",
        "        transform_f4 = tf.layers.batch_normalization(\n",
        "            transform_f4,\n",
        "            training=is_training,\n",
        "            momentum=self.batch_momentum,\n",
        "            virtual_batch_size=v_b)\n",
        "        transform_f4 = (glu(transform_f4, self.feature_dim) +\n",
        "                        transform_f3) * np.sqrt(0.5)\n",
        "\n",
        "        if ni > 0:\n",
        "\n",
        "          decision_out = tf.nn.relu(transform_f4[:, :self.output_dim])\n",
        "\n",
        "          # Decision aggregation.\n",
        "          output_aggregated += decision_out\n",
        "\n",
        "          # Aggregated masks are used for visualization of the\n",
        "          # feature importance attributes.\n",
        "          scale_agg = tf.reduce_sum(\n",
        "              decision_out, axis=1, keep_dims=True) / (\n",
        "                  self.num_decision_steps - 1)\n",
        "          aggregated_mask_values += mask_values * scale_agg\n",
        "\n",
        "        features_for_coef = (transform_f4[:, self.output_dim:])\n",
        "\n",
        "        if ni < self.num_decision_steps - 1:\n",
        "\n",
        "          # Determines the feature masks via linear and nonlinear\n",
        "          # transformations, taking into account of aggregated feature use.\n",
        "          mask_values = tf.layers.dense(\n",
        "              features_for_coef,\n",
        "              self.num_features,\n",
        "              name=\"Transform_coef\" + str(ni),\n",
        "              use_bias=False)\n",
        "          mask_values = tf.layers.batch_normalization(\n",
        "              mask_values,\n",
        "              training=is_training,\n",
        "              momentum=self.batch_momentum,\n",
        "              virtual_batch_size=v_b)\n",
        "          mask_values *= complemantary_aggregated_mask_values\n",
        "          mask_values = tf.contrib.sparsemax.sparsemax(mask_values)\n",
        "\n",
        "          # Relaxation factor controls the amount of reuse of features between\n",
        "          # different decision blocks and updated with the values of\n",
        "          # coefficients.\n",
        "          complemantary_aggregated_mask_values *= (\n",
        "              self.relaxation_factor - mask_values)\n",
        "\n",
        "          # Entropy is used to penalize the amount of sparsity in feature\n",
        "          # selection.\n",
        "          total_entropy += tf.reduce_mean(\n",
        "              tf.reduce_sum(\n",
        "                  -mask_values * tf.log(mask_values + self.epsilon),\n",
        "                  axis=1)) / (\n",
        "                      self.num_decision_steps - 1)\n",
        "\n",
        "          # Feature selection.\n",
        "          masked_features = tf.multiply(mask_values, features)\n",
        "\n",
        "          # Visualization of the feature selection mask at decision step ni\n",
        "          tf.summary.image(\n",
        "              \"Mask for step\" + str(ni),\n",
        "              tf.expand_dims(tf.expand_dims(mask_values, 0), 3),\n",
        "              max_outputs=1)\n",
        "\n",
        "      # Visualization of the aggregated feature importances\n",
        "      tf.summary.image(\n",
        "          \"Aggregated mask\",\n",
        "          tf.expand_dims(tf.expand_dims(aggregated_mask_values, 0), 3),\n",
        "          max_outputs=1)\n",
        "\n",
        "      return output_aggregated, total_entropy\n",
        "\n",
        "  def classify(self, activations, reuse):\n",
        "    \"\"\"TabNet classify block.\"\"\"\n",
        "\n",
        "    with tf.variable_scope(\"Classify\", reuse=reuse):\n",
        "      logits = tf.layers.dense(activations, self.num_classes, use_bias=False)\n",
        "      predictions = tf.nn.softmax(logits)\n",
        "      return logits, predictions\n",
        "\n",
        "  def regress(self, activations, reuse):\n",
        "    \"\"\"TabNet regress block.\"\"\"\n",
        "\n",
        "    with tf.variable_scope(\"Regress\", reuse=reuse):\n",
        "      predictions = tf.layers.dense(activations, 1)\n",
        "      return predictions"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK1tQ3UJQBAh"
      },
      "source": [
        "# Реализация на pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZj-20q0QARQ",
        "outputId": "d67209c9-d8b2-47a0-f85b-1f9b4dc61345"
      },
      "source": [
        "! pip install pytorch-tabnet"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.7.0+cu101)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H4RKisuTIf4"
      },
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh6qxzYco18H"
      },
      "source": [
        "# benchmark TabNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBUy10kdo-g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3a3e1a-59a9-4094-dcea-686cd62480e1"
      },
      "source": [
        "! python3 runbenchmark.py TabNet benchmark39datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Assigning 2 cores (total=2) for new task Amazon_employee_access.\n",
            "Assigning 7960 MB (total=13021 MB) for new Amazon_employee_access task.\n",
            "Running task Amazon_employee_access on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Amazon_employee_access', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7960, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.45222 | val_0_auc: 0.50402 | val_1_auc: 0.51494 |  0:00:01s\n",
            "epoch 1  | loss: 0.22899 | val_0_auc: 0.47382 | val_1_auc: 0.4542  |  0:00:03s\n",
            "epoch 2  | loss: 0.22316 | val_0_auc: 0.45672 | val_1_auc: 0.43087 |  0:00:05s\n",
            "epoch 3  | loss: 0.22172 | val_0_auc: 0.47922 | val_1_auc: 0.47733 |  0:00:07s\n",
            "epoch 4  | loss: 0.22099 | val_0_auc: 0.515   | val_1_auc: 0.49924 |  0:00:09s\n",
            "epoch 5  | loss: 0.22026 | val_0_auc: 0.50344 | val_1_auc: 0.48726 |  0:00:11s\n",
            "epoch 6  | loss: 0.22018 | val_0_auc: 0.5332  | val_1_auc: 0.53147 |  0:00:13s\n",
            "epoch 7  | loss: 0.21932 | val_0_auc: 0.5378  | val_1_auc: 0.48105 |  0:00:15s\n",
            "epoch 8  | loss: 0.21904 | val_0_auc: 0.54763 | val_1_auc: 0.51563 |  0:00:17s\n",
            "epoch 9  | loss: 0.21847 | val_0_auc: 0.53886 | val_1_auc: 0.50305 |  0:00:18s\n",
            "epoch 10 | loss: 0.21873 | val_0_auc: 0.55894 | val_1_auc: 0.55375 |  0:00:20s\n",
            "epoch 11 | loss: 0.21876 | val_0_auc: 0.5846  | val_1_auc: 0.55541 |  0:00:22s\n",
            "epoch 12 | loss: 0.21816 | val_0_auc: 0.57435 | val_1_auc: 0.56058 |  0:00:24s\n",
            "epoch 13 | loss: 0.21755 | val_0_auc: 0.58319 | val_1_auc: 0.57063 |  0:00:26s\n",
            "epoch 14 | loss: 0.21677 | val_0_auc: 0.60738 | val_1_auc: 0.59623 |  0:00:28s\n",
            "epoch 15 | loss: 0.21687 | val_0_auc: 0.62274 | val_1_auc: 0.59781 |  0:00:30s\n",
            "epoch 16 | loss: 0.21709 | val_0_auc: 0.62085 | val_1_auc: 0.58471 |  0:00:32s\n",
            "epoch 17 | loss: 0.21657 | val_0_auc: 0.63383 | val_1_auc: 0.61556 |  0:00:33s\n",
            "epoch 18 | loss: 0.2167  | val_0_auc: 0.63489 | val_1_auc: 0.61548 |  0:00:35s\n",
            "epoch 19 | loss: 0.21582 | val_0_auc: 0.63495 | val_1_auc: 0.632   |  0:00:37s\n",
            "epoch 20 | loss: 0.21525 | val_0_auc: 0.64268 | val_1_auc: 0.6233  |  0:00:39s\n",
            "epoch 21 | loss: 0.21469 | val_0_auc: 0.63733 | val_1_auc: 0.60961 |  0:00:41s\n",
            "epoch 22 | loss: 0.21453 | val_0_auc: 0.64395 | val_1_auc: 0.62799 |  0:00:43s\n",
            "epoch 23 | loss: 0.21551 | val_0_auc: 0.61879 | val_1_auc: 0.60325 |  0:00:45s\n",
            "epoch 24 | loss: 0.21563 | val_0_auc: 0.6294  | val_1_auc: 0.61677 |  0:00:47s\n",
            "epoch 25 | loss: 0.21403 | val_0_auc: 0.63901 | val_1_auc: 0.62773 |  0:00:48s\n",
            "epoch 26 | loss: 0.215   | val_0_auc: 0.63935 | val_1_auc: 0.62149 |  0:00:50s\n",
            "epoch 27 | loss: 0.21479 | val_0_auc: 0.64184 | val_1_auc: 0.62103 |  0:00:52s\n",
            "epoch 28 | loss: 0.21455 | val_0_auc: 0.64259 | val_1_auc: 0.63481 |  0:00:54s\n",
            "epoch 29 | loss: 0.2141  | val_0_auc: 0.64449 | val_1_auc: 0.61603 |  0:00:56s\n",
            "epoch 30 | loss: 0.21367 | val_0_auc: 0.64707 | val_1_auc: 0.62921 |  0:00:58s\n",
            "epoch 31 | loss: 0.21415 | val_0_auc: 0.64254 | val_1_auc: 0.59656 |  0:01:00s\n",
            "epoch 32 | loss: 0.21424 | val_0_auc: 0.64003 | val_1_auc: 0.62185 |  0:01:02s\n",
            "epoch 33 | loss: 0.21546 | val_0_auc: 0.627   | val_1_auc: 0.58342 |  0:01:03s\n",
            "epoch 34 | loss: 0.21542 | val_0_auc: 0.63647 | val_1_auc: 0.61135 |  0:01:05s\n",
            "epoch 35 | loss: 0.21554 | val_0_auc: 0.63941 | val_1_auc: 0.62606 |  0:01:07s\n",
            "epoch 36 | loss: 0.21463 | val_0_auc: 0.65213 | val_1_auc: 0.64529 |  0:01:09s\n",
            "epoch 37 | loss: 0.21377 | val_0_auc: 0.65633 | val_1_auc: 0.64264 |  0:01:11s\n",
            "epoch 38 | loss: 0.21381 | val_0_auc: 0.64727 | val_1_auc: 0.6158  |  0:01:13s\n",
            "epoch 39 | loss: 0.21389 | val_0_auc: 0.63954 | val_1_auc: 0.61338 |  0:01:15s\n",
            "epoch 40 | loss: 0.21459 | val_0_auc: 0.63715 | val_1_auc: 0.6056  |  0:01:17s\n",
            "epoch 41 | loss: 0.21537 | val_0_auc: 0.64997 | val_1_auc: 0.62296 |  0:01:18s\n",
            "epoch 42 | loss: 0.21416 | val_0_auc: 0.64742 | val_1_auc: 0.63815 |  0:01:20s\n",
            "epoch 43 | loss: 0.21521 | val_0_auc: 0.63635 | val_1_auc: 0.60802 |  0:01:22s\n",
            "epoch 44 | loss: 0.21374 | val_0_auc: 0.65036 | val_1_auc: 0.62564 |  0:01:24s\n",
            "epoch 45 | loss: 0.21341 | val_0_auc: 0.65508 | val_1_auc: 0.63161 |  0:01:26s\n",
            "epoch 46 | loss: 0.21379 | val_0_auc: 0.6479  | val_1_auc: 0.62017 |  0:01:28s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_1_auc = 0.64529\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.065009  0.934991           1     1\n",
            "1   0.044926  0.955074           1     1\n",
            "2   0.056452  0.943548           1     1\n",
            "3   0.035467  0.964533           1     1\n",
            "4   0.043889  0.956111           1     1\n",
            "5   0.065852  0.934148           1     1\n",
            "6   0.058274  0.941726           1     1\n",
            "7   0.037596  0.962404           1     1\n",
            "8   0.056719  0.943281           1     1\n",
            "9   0.079502  0.920498           1     1\n",
            "10  0.036140  0.963860           1     1\n",
            "11  0.036444  0.963556           1     1\n",
            "12  0.077191  0.922809           1     1\n",
            "13  0.079358  0.920642           1     1\n",
            "14  0.043672  0.956328           1     1\n",
            "15  0.069146  0.930854           1     1\n",
            "16  0.066105  0.933895           1     1\n",
            "17  0.056419  0.943581           1     1\n",
            "18  0.068183  0.931817           1     1\n",
            "19  0.037405  0.962595           1     1\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9426304546841623,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.6452867560380515,\n",
            "  'balacc': 0.5026455026455027,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/34539',\n",
            "  'info': None,\n",
            "  'logloss': 0.21274341620633988,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.06090950965881348,\n",
            "  'result': 0.6452867560380515,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Amazon_employee_access',\n",
            "  'training_duration': 88.96610379219055,\n",
            "  'utc': '2021-02-04T15:52:06',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Amazon_employee_access.0.TabNet executed in 104.617 seconds.\n",
            "\n",
            "----------------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Amazon_employee_access.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Amazon_employee_access.\n",
            "Assigning 7951 MB (total=13021 MB) for new Amazon_employee_access task.\n",
            "Running task Amazon_employee_access on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Amazon_employee_access', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7951, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.46506 | val_0_auc: 0.48909 | val_1_auc: 0.45418 |  0:00:01s\n",
            "epoch 1  | loss: 0.22915 | val_0_auc: 0.48819 | val_1_auc: 0.47491 |  0:00:03s\n",
            "epoch 2  | loss: 0.22127 | val_0_auc: 0.50641 | val_1_auc: 0.50417 |  0:00:05s\n",
            "epoch 3  | loss: 0.22042 | val_0_auc: 0.50293 | val_1_auc: 0.51388 |  0:00:07s\n",
            "epoch 4  | loss: 0.22046 | val_0_auc: 0.49974 | val_1_auc: 0.50674 |  0:00:09s\n",
            "[499] CPU Utilization: 46.7%\n",
            "[499] Memory Usage: 23.2%\n",
            "[499] Disk Usage: 22.8%\n",
            "epoch 5  | loss: 0.21882 | val_0_auc: 0.52593 | val_1_auc: 0.52201 |  0:00:11s\n",
            "epoch 6  | loss: 0.21858 | val_0_auc: 0.53665 | val_1_auc: 0.54482 |  0:00:13s\n",
            "epoch 7  | loss: 0.21915 | val_0_auc: 0.5383  | val_1_auc: 0.55704 |  0:00:15s\n",
            "epoch 8  | loss: 0.21812 | val_0_auc: 0.57052 | val_1_auc: 0.55661 |  0:00:16s\n",
            "epoch 9  | loss: 0.2177  | val_0_auc: 0.58535 | val_1_auc: 0.60509 |  0:00:18s\n",
            "epoch 10 | loss: 0.21746 | val_0_auc: 0.59607 | val_1_auc: 0.61022 |  0:00:20s\n",
            "epoch 11 | loss: 0.21799 | val_0_auc: 0.60216 | val_1_auc: 0.6012  |  0:00:22s\n",
            "epoch 12 | loss: 0.21696 | val_0_auc: 0.60016 | val_1_auc: 0.61515 |  0:00:24s\n",
            "epoch 13 | loss: 0.216   | val_0_auc: 0.61213 | val_1_auc: 0.61767 |  0:00:26s\n",
            "epoch 14 | loss: 0.21642 | val_0_auc: 0.62214 | val_1_auc: 0.63173 |  0:00:28s\n",
            "epoch 15 | loss: 0.21606 | val_0_auc: 0.63307 | val_1_auc: 0.63141 |  0:00:30s\n",
            "epoch 16 | loss: 0.2157  | val_0_auc: 0.6353  | val_1_auc: 0.64102 |  0:00:31s\n",
            "epoch 17 | loss: 0.21638 | val_0_auc: 0.62389 | val_1_auc: 0.62892 |  0:00:33s\n",
            "epoch 18 | loss: 0.21628 | val_0_auc: 0.63245 | val_1_auc: 0.62433 |  0:00:35s\n",
            "epoch 19 | loss: 0.21586 | val_0_auc: 0.63678 | val_1_auc: 0.63211 |  0:00:37s\n",
            "epoch 20 | loss: 0.21559 | val_0_auc: 0.63883 | val_1_auc: 0.64384 |  0:00:39s\n",
            "epoch 21 | loss: 0.21588 | val_0_auc: 0.64007 | val_1_auc: 0.62487 |  0:00:41s\n",
            "epoch 22 | loss: 0.21612 | val_0_auc: 0.64201 | val_1_auc: 0.62995 |  0:00:43s\n",
            "epoch 23 | loss: 0.21548 | val_0_auc: 0.64114 | val_1_auc: 0.62998 |  0:00:45s\n",
            "epoch 24 | loss: 0.21503 | val_0_auc: 0.64703 | val_1_auc: 0.64958 |  0:00:46s\n",
            "epoch 25 | loss: 0.21488 | val_0_auc: 0.65174 | val_1_auc: 0.63451 |  0:00:48s\n",
            "epoch 26 | loss: 0.21439 | val_0_auc: 0.64617 | val_1_auc: 0.63677 |  0:00:50s\n",
            "epoch 27 | loss: 0.21484 | val_0_auc: 0.63904 | val_1_auc: 0.6212  |  0:00:52s\n",
            "epoch 28 | loss: 0.21459 | val_0_auc: 0.64809 | val_1_auc: 0.6246  |  0:00:54s\n",
            "epoch 29 | loss: 0.21411 | val_0_auc: 0.65047 | val_1_auc: 0.62682 |  0:00:56s\n",
            "epoch 30 | loss: 0.21397 | val_0_auc: 0.63238 | val_1_auc: 0.63112 |  0:00:58s\n",
            "epoch 31 | loss: 0.2154  | val_0_auc: 0.654   | val_1_auc: 0.64172 |  0:01:00s\n",
            "epoch 32 | loss: 0.21517 | val_0_auc: 0.64829 | val_1_auc: 0.63061 |  0:01:01s\n",
            "epoch 33 | loss: 0.21361 | val_0_auc: 0.64445 | val_1_auc: 0.63588 |  0:01:03s\n",
            "epoch 34 | loss: 0.21488 | val_0_auc: 0.63709 | val_1_auc: 0.6147  |  0:01:05s\n",
            "\n",
            "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_1_auc = 0.64958\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.060644  0.939356           1     1\n",
            "1   0.055019  0.944981           1     1\n",
            "2   0.049818  0.950182           1     1\n",
            "3   0.033936  0.966064           1     1\n",
            "4   0.017966  0.982034           1     1\n",
            "5   0.040132  0.959868           1     1\n",
            "6   0.032111  0.967889           1     1\n",
            "7   0.047964  0.952036           1     1\n",
            "8   0.066948  0.933052           1     1\n",
            "9   0.041871  0.958129           1     1\n",
            "10  0.042843  0.957157           1     1\n",
            "11  0.068517  0.931484           1     1\n",
            "12  0.041845  0.958155           1     1\n",
            "13  0.061388  0.938612           1     1\n",
            "14  0.057057  0.942943           1     1\n",
            "15  0.079040  0.920960           1     1\n",
            "16  0.029123  0.970877           1     1\n",
            "17  0.058063  0.941937           1     1\n",
            "18  0.078753  0.921247           1     1\n",
            "19  0.024394  0.975606           1     1\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Amazon_employee_access/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.942325297528227,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.6495754173862982,\n",
            "  'balacc': 0.5,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/34539',\n",
            "  'info': None,\n",
            "  'logloss': 0.21382013728132498,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.06152677536010742,\n",
            "  'result': 0.6495754173862982,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Amazon_employee_access',\n",
            "  'training_duration': 66.34620571136475,\n",
            "  'utc': '2021-02-04T15:53:14',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Amazon_employee_access.1.TabNet executed in 67.779 seconds.\n",
            "\n",
            "----------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.APSFailure.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task APSFailure.\n",
            "Assigning 7956 MB (total=13021 MB) for new APSFailure task.\n",
            "Running task APSFailure on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='APSFailure', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7956, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.1509  | val_0_auc: 0.47694 | val_1_auc: 0.46831 |  0:00:04s\n",
            "[499] CPU Utilization: 44.4%\n",
            "[499] Memory Usage: 24.4%\n",
            "[499] Disk Usage: 22.9%\n",
            "epoch 1  | loss: 0.06046 | val_0_auc: 0.96465 | val_1_auc: 0.98078 |  0:00:09s\n",
            "epoch 2  | loss: 0.05559 | val_0_auc: 0.96904 | val_1_auc: 0.97882 |  0:00:13s\n",
            "epoch 3  | loss: 0.04906 | val_0_auc: 0.96747 | val_1_auc: 0.97319 |  0:00:18s\n",
            "epoch 4  | loss: 0.04756 | val_0_auc: 0.96848 | val_1_auc: 0.97735 |  0:00:22s\n",
            "epoch 5  | loss: 0.04667 | val_0_auc: 0.97065 | val_1_auc: 0.98308 |  0:00:27s\n",
            "epoch 6  | loss: 0.04487 | val_0_auc: 0.97159 | val_1_auc: 0.98274 |  0:00:31s\n",
            "epoch 7  | loss: 0.04396 | val_0_auc: 0.96928 | val_1_auc: 0.97974 |  0:00:36s\n",
            "epoch 8  | loss: 0.0441  | val_0_auc: 0.96616 | val_1_auc: 0.97767 |  0:00:41s\n",
            "epoch 9  | loss: 0.04324 | val_0_auc: 0.97228 | val_1_auc: 0.98293 |  0:00:45s\n",
            "epoch 10 | loss: 0.04234 | val_0_auc: 0.97207 | val_1_auc: 0.98294 |  0:00:50s\n",
            "epoch 11 | loss: 0.04215 | val_0_auc: 0.97151 | val_1_auc: 0.98283 |  0:00:54s\n",
            "epoch 12 | loss: 0.04172 | val_0_auc: 0.96667 | val_1_auc: 0.97574 |  0:00:59s\n",
            "epoch 13 | loss: 0.04142 | val_0_auc: 0.96403 | val_1_auc: 0.97305 |  0:01:03s\n",
            "epoch 14 | loss: 0.04084 | val_0_auc: 0.96734 | val_1_auc: 0.97692 |  0:01:08s\n",
            "epoch 15 | loss: 0.0402  | val_0_auc: 0.96829 | val_1_auc: 0.97741 |  0:01:12s\n",
            "\n",
            "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_1_auc = 0.98308\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "          neg       pos predictions truth\n",
            "0   0.996896  0.003104         neg   neg\n",
            "1   0.997319  0.002681         neg   neg\n",
            "2   0.997805  0.002195         neg   neg\n",
            "3   0.997269  0.002731         neg   neg\n",
            "4   0.997564  0.002436         neg   neg\n",
            "5   0.997166  0.002834         neg   neg\n",
            "6   0.997158  0.002842         neg   neg\n",
            "7   0.997804  0.002196         neg   neg\n",
            "8   0.905697  0.094304         neg   neg\n",
            "9   0.997813  0.002187         neg   neg\n",
            "10  0.965683  0.034317         neg   neg\n",
            "11  0.550267  0.449733         neg   neg\n",
            "12  0.997071  0.002929         neg   neg\n",
            "13  0.994225  0.005775         neg   neg\n",
            "14  0.997291  0.002709         neg   neg\n",
            "15  0.997643  0.002357         neg   neg\n",
            "16  0.995644  0.004356         neg   neg\n",
            "17  0.997390  0.002610         neg   neg\n",
            "18  0.997224  0.002776         neg   neg\n",
            "19  0.996420  0.003580         neg   neg\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9823684210526316,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.9830780756843249,\n",
            "  'balacc': 0.5288620943613799,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168868',\n",
            "  'info': None,\n",
            "  'logloss': 0.04151395713156459,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.14640259742736816,\n",
            "  'result': 0.9830780756843249,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'APSFailure',\n",
            "  'training_duration': 74.50378894805908,\n",
            "  'utc': '2021-02-04T15:55:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.APSFailure.0.TabNet executed in 129.515 seconds.\n",
            "\n",
            "----------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.APSFailure.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task APSFailure.\n",
            "Assigning 7949 MB (total=13021 MB) for new APSFailure task.\n",
            "Running task APSFailure on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='APSFailure', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7949, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.15663 | val_0_auc: 0.97088 | val_1_auc: 0.94919 |  0:00:04s\n",
            "epoch 1  | loss: 0.0546  | val_0_auc: 0.97332 | val_1_auc: 0.96026 |  0:00:09s\n",
            "epoch 2  | loss: 0.04934 | val_0_auc: 0.97519 | val_1_auc: 0.96177 |  0:00:13s\n",
            "epoch 3  | loss: 0.04863 | val_0_auc: 0.97673 | val_1_auc: 0.96152 |  0:00:18s\n",
            "epoch 4  | loss: 0.04516 | val_0_auc: 0.97454 | val_1_auc: 0.96006 |  0:00:22s\n",
            "epoch 5  | loss: 0.04255 | val_0_auc: 0.97954 | val_1_auc: 0.96246 |  0:00:27s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 24.4%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 6  | loss: 0.04191 | val_0_auc: 0.97945 | val_1_auc: 0.96186 |  0:00:31s\n",
            "epoch 7  | loss: 0.03981 | val_0_auc: 0.97899 | val_1_auc: 0.9618  |  0:00:36s\n",
            "epoch 8  | loss: 0.03933 | val_0_auc: 0.97819 | val_1_auc: 0.96205 |  0:00:40s\n",
            "epoch 9  | loss: 0.03938 | val_0_auc: 0.97937 | val_1_auc: 0.96315 |  0:00:45s\n",
            "epoch 10 | loss: 0.03741 | val_0_auc: 0.9791  | val_1_auc: 0.96309 |  0:00:50s\n",
            "epoch 11 | loss: 0.03753 | val_0_auc: 0.96715 | val_1_auc: 0.95806 |  0:00:54s\n",
            "epoch 12 | loss: 0.03827 | val_0_auc: 0.97774 | val_1_auc: 0.96236 |  0:00:59s\n",
            "epoch 13 | loss: 0.03889 | val_0_auc: 0.9755  | val_1_auc: 0.95829 |  0:01:03s\n",
            "epoch 14 | loss: 0.03936 | val_0_auc: 0.97539 | val_1_auc: 0.96003 |  0:01:08s\n",
            "epoch 15 | loss: 0.03882 | val_0_auc: 0.97699 | val_1_auc: 0.96229 |  0:01:12s\n",
            "epoch 16 | loss: 0.04074 | val_0_auc: 0.97433 | val_1_auc: 0.96765 |  0:01:17s\n",
            "epoch 17 | loss: 0.04115 | val_0_auc: 0.9763  | val_1_auc: 0.96278 |  0:01:21s\n",
            "epoch 18 | loss: 0.04043 | val_0_auc: 0.9758  | val_1_auc: 0.95971 |  0:01:26s\n",
            "epoch 19 | loss: 0.03952 | val_0_auc: 0.97525 | val_1_auc: 0.96037 |  0:01:30s\n",
            "epoch 20 | loss: 0.03965 | val_0_auc: 0.97569 | val_1_auc: 0.96271 |  0:01:35s\n",
            "epoch 21 | loss: 0.04066 | val_0_auc: 0.97623 | val_1_auc: 0.95922 |  0:01:40s\n",
            "epoch 22 | loss: 0.0404  | val_0_auc: 0.97553 | val_1_auc: 0.9615  |  0:01:44s\n",
            "epoch 23 | loss: 0.0408  | val_0_auc: 0.97232 | val_1_auc: 0.97155 |  0:01:49s\n",
            "epoch 24 | loss: 0.04047 | val_0_auc: 0.97287 | val_1_auc: 0.95234 |  0:01:53s\n",
            "epoch 25 | loss: 0.0401  | val_0_auc: 0.97662 | val_1_auc: 0.96159 |  0:01:58s\n",
            "epoch 26 | loss: 0.04011 | val_0_auc: 0.97683 | val_1_auc: 0.96188 |  0:02:02s\n",
            "epoch 27 | loss: 0.04068 | val_0_auc: 0.97587 | val_1_auc: 0.96395 |  0:02:07s\n",
            "epoch 28 | loss: 0.03996 | val_0_auc: 0.97608 | val_1_auc: 0.96099 |  0:02:11s\n",
            "epoch 29 | loss: 0.03891 | val_0_auc: 0.97582 | val_1_auc: 0.96181 |  0:02:16s\n",
            "epoch 30 | loss: 0.03873 | val_0_auc: 0.97546 | val_1_auc: 0.96    |  0:02:20s\n",
            "epoch 31 | loss: 0.03868 | val_0_auc: 0.97366 | val_1_auc: 0.95921 |  0:02:25s\n",
            "epoch 32 | loss: 0.03872 | val_0_auc: 0.97595 | val_1_auc: 0.9611  |  0:02:29s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 24.5%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 33 | loss: 0.03856 | val_0_auc: 0.97597 | val_1_auc: 0.9616  |  0:02:34s\n",
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_1_auc = 0.97155\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "          neg       pos predictions truth\n",
            "0   0.998435  0.001565         neg   neg\n",
            "1   0.996610  0.003390         neg   neg\n",
            "2   0.998182  0.001818         neg   neg\n",
            "3   0.996957  0.003043         neg   neg\n",
            "4   0.999538  0.000462         neg   neg\n",
            "5   0.996467  0.003532         neg   neg\n",
            "6   0.996461  0.003539         neg   neg\n",
            "7   0.999545  0.000455         neg   neg\n",
            "8   0.988094  0.011906         neg   neg\n",
            "9   0.999507  0.000493         neg   neg\n",
            "10  0.998022  0.001978         neg   neg\n",
            "11  0.997699  0.002301         neg   neg\n",
            "12  0.999342  0.000658         neg   neg\n",
            "13  0.979963  0.020037         neg   neg\n",
            "14  0.998763  0.001237         neg   neg\n",
            "15  0.999579  0.000421         neg   neg\n",
            "16  0.999180  0.000820         neg   neg\n",
            "17  0.999425  0.000575         neg   neg\n",
            "18  0.996974  0.003026         neg   neg\n",
            "19  0.999408  0.000592         neg   neg\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/APSFailure/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9826315789473684,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.971552603549775,\n",
            "  'balacc': 0.6579710513472303,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168868',\n",
            "  'info': None,\n",
            "  'logloss': 0.045305219185861736,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.14142799377441406,\n",
            "  'result': 0.971552603549775,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'APSFailure',\n",
            "  'training_duration': 155.903804063797,\n",
            "  'utc': '2021-02-04T15:58:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.APSFailure.1.TabNet executed in 179.787 seconds.\n",
            "\n",
            "--------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.bank-marketing.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task bank-marketing.\n",
            "Assigning 7957 MB (total=13021 MB) for new bank-marketing task.\n",
            "Running task bank-marketing on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='bank-marketing', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7957, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'self-employed'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'self-employed'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/14965',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'self-employed'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'bank-marketing',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T15:58:40',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.bank-marketing.0.TabNet executed in 16.844 seconds.\n",
            "\n",
            "--------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.bank-marketing.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task bank-marketing.\n",
            "Assigning 7957 MB (total=13021 MB) for new bank-marketing task.\n",
            "Running task bank-marketing on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='bank-marketing', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7957, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'management'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'management'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/bank-marketing/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/14965',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'management'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'bank-marketing',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T15:58:42',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.bank-marketing.1.TabNet executed in 1.849 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.connect-4.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task connect-4.\n",
            "Assigning 7947 MB (total=13021 MB) for new connect-4 task.\n",
            "Running task connect-4 on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='connect-4', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7947, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.86315 | val_0_accuracy: 0.65466 | val_1_accuracy: 0.65616 |  0:00:03s\n",
            "epoch 1  | loss: 0.80577 | val_0_accuracy: 0.66343 | val_1_accuracy: 0.66504 |  0:00:07s\n",
            "epoch 2  | loss: 0.77596 | val_0_accuracy: 0.6844  | val_1_accuracy: 0.68976 |  0:00:11s\n",
            "epoch 3  | loss: 0.74914 | val_0_accuracy: 0.69716 | val_1_accuracy: 0.69953 |  0:00:15s\n",
            "epoch 4  | loss: 0.7424  | val_0_accuracy: 0.69588 | val_1_accuracy: 0.69938 |  0:00:19s\n",
            "epoch 5  | loss: 0.72153 | val_0_accuracy: 0.71114 | val_1_accuracy: 0.71477 |  0:00:23s\n",
            "epoch 6  | loss: 0.70689 | val_0_accuracy: 0.71599 | val_1_accuracy: 0.71314 |  0:00:27s\n",
            "epoch 7  | loss: 0.69696 | val_0_accuracy: 0.72486 | val_1_accuracy: 0.72321 |  0:00:30s\n",
            "epoch 8  | loss: 0.68435 | val_0_accuracy: 0.72741 | val_1_accuracy: 0.7275  |  0:00:34s\n",
            "epoch 9  | loss: 0.67641 | val_0_accuracy: 0.73606 | val_1_accuracy: 0.73372 |  0:00:38s\n",
            "epoch 10 | loss: 0.66713 | val_0_accuracy: 0.73519 | val_1_accuracy: 0.72691 |  0:00:42s\n",
            "epoch 11 | loss: 0.66053 | val_0_accuracy: 0.74421 | val_1_accuracy: 0.73934 |  0:00:46s\n",
            "epoch 12 | loss: 0.65303 | val_0_accuracy: 0.73607 | val_1_accuracy: 0.72943 |  0:00:50s\n",
            "epoch 13 | loss: 0.65861 | val_0_accuracy: 0.74344 | val_1_accuracy: 0.73653 |  0:00:54s\n",
            "epoch 14 | loss: 0.64516 | val_0_accuracy: 0.74948 | val_1_accuracy: 0.74364 |  0:00:58s\n",
            "epoch 15 | loss: 0.6416  | val_0_accuracy: 0.75255 | val_1_accuracy: 0.75148 |  0:01:01s\n",
            "[499] CPU Utilization: 38.2%\n",
            "[499] Memory Usage: 23.6%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 16 | loss: 0.64627 | val_0_accuracy: 0.73298 | val_1_accuracy: 0.73061 |  0:01:05s\n",
            "epoch 17 | loss: 0.661   | val_0_accuracy: 0.73823 | val_1_accuracy: 0.73535 |  0:01:09s\n",
            "epoch 18 | loss: 0.64834 | val_0_accuracy: 0.74461 | val_1_accuracy: 0.74734 |  0:01:13s\n",
            "epoch 19 | loss: 0.64968 | val_0_accuracy: 0.73894 | val_1_accuracy: 0.73905 |  0:01:17s\n",
            "epoch 20 | loss: 0.65736 | val_0_accuracy: 0.74453 | val_1_accuracy: 0.746   |  0:01:21s\n",
            "epoch 21 | loss: 0.63761 | val_0_accuracy: 0.74956 | val_1_accuracy: 0.74778 |  0:01:25s\n",
            "epoch 22 | loss: 0.63586 | val_0_accuracy: 0.7502  | val_1_accuracy: 0.75178 |  0:01:29s\n",
            "epoch 23 | loss: 0.63243 | val_0_accuracy: 0.75372 | val_1_accuracy: 0.7534  |  0:01:32s\n",
            "epoch 24 | loss: 0.61955 | val_0_accuracy: 0.75954 | val_1_accuracy: 0.75562 |  0:01:36s\n",
            "epoch 25 | loss: 0.61653 | val_0_accuracy: 0.76171 | val_1_accuracy: 0.76288 |  0:01:40s\n",
            "epoch 26 | loss: 0.60974 | val_0_accuracy: 0.76359 | val_1_accuracy: 0.76613 |  0:01:44s\n",
            "epoch 27 | loss: 0.60379 | val_0_accuracy: 0.76237 | val_1_accuracy: 0.75903 |  0:01:48s\n",
            "epoch 28 | loss: 0.59811 | val_0_accuracy: 0.76545 | val_1_accuracy: 0.76702 |  0:01:52s\n",
            "epoch 29 | loss: 0.59372 | val_0_accuracy: 0.76867 | val_1_accuracy: 0.76687 |  0:01:56s\n",
            "epoch 30 | loss: 0.59427 | val_0_accuracy: 0.77537 | val_1_accuracy: 0.77516 |  0:01:59s\n",
            "epoch 31 | loss: 0.5882  | val_0_accuracy: 0.77239 | val_1_accuracy: 0.77161 |  0:02:03s\n",
            "epoch 32 | loss: 0.58625 | val_0_accuracy: 0.77467 | val_1_accuracy: 0.77146 |  0:02:07s\n",
            "epoch 33 | loss: 0.58595 | val_0_accuracy: 0.77678 | val_1_accuracy: 0.77353 |  0:02:11s\n",
            "epoch 34 | loss: 0.57969 | val_0_accuracy: 0.7792  | val_1_accuracy: 0.77353 |  0:02:15s\n",
            "epoch 35 | loss: 0.60049 | val_0_accuracy: 0.7594  | val_1_accuracy: 0.76332 |  0:02:19s\n",
            "epoch 36 | loss: 0.59931 | val_0_accuracy: 0.77459 | val_1_accuracy: 0.76939 |  0:02:23s\n",
            "epoch 37 | loss: 0.58343 | val_0_accuracy: 0.77887 | val_1_accuracy: 0.77664 |  0:02:27s\n",
            "epoch 38 | loss: 0.57957 | val_0_accuracy: 0.78012 | val_1_accuracy: 0.77368 |  0:02:30s\n",
            "epoch 39 | loss: 0.57529 | val_0_accuracy: 0.77918 | val_1_accuracy: 0.77161 |  0:02:34s\n",
            "epoch 40 | loss: 0.56802 | val_0_accuracy: 0.78334 | val_1_accuracy: 0.77738 |  0:02:38s\n",
            "epoch 41 | loss: 0.56544 | val_0_accuracy: 0.78094 | val_1_accuracy: 0.77339 |  0:02:42s\n",
            "epoch 42 | loss: 0.56495 | val_0_accuracy: 0.78711 | val_1_accuracy: 0.78064 |  0:02:46s\n",
            "epoch 43 | loss: 0.56356 | val_0_accuracy: 0.78463 | val_1_accuracy: 0.7762  |  0:02:50s\n",
            "epoch 44 | loss: 0.56378 | val_0_accuracy: 0.78793 | val_1_accuracy: 0.77812 |  0:02:54s\n",
            "epoch 45 | loss: 0.5561  | val_0_accuracy: 0.78997 | val_1_accuracy: 0.78316 |  0:02:58s\n",
            "epoch 46 | loss: 0.55156 | val_0_accuracy: 0.79051 | val_1_accuracy: 0.77649 |  0:03:01s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 23.6%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 47 | loss: 0.55003 | val_0_accuracy: 0.79226 | val_1_accuracy: 0.78197 |  0:03:05s\n",
            "epoch 48 | loss: 0.55246 | val_0_accuracy: 0.78323 | val_1_accuracy: 0.76954 |  0:03:09s\n",
            "epoch 49 | loss: 0.5503  | val_0_accuracy: 0.79606 | val_1_accuracy: 0.78286 |  0:03:13s\n",
            "epoch 50 | loss: 0.5457  | val_0_accuracy: 0.79287 | val_1_accuracy: 0.77842 |  0:03:17s\n",
            "epoch 51 | loss: 0.54565 | val_0_accuracy: 0.79716 | val_1_accuracy: 0.78538 |  0:03:21s\n",
            "epoch 52 | loss: 0.53945 | val_0_accuracy: 0.7913  | val_1_accuracy: 0.77709 |  0:03:25s\n",
            "epoch 53 | loss: 0.54214 | val_0_accuracy: 0.79783 | val_1_accuracy: 0.78567 |  0:03:29s\n",
            "epoch 54 | loss: 0.54022 | val_0_accuracy: 0.79527 | val_1_accuracy: 0.78286 |  0:03:32s\n",
            "epoch 55 | loss: 0.53994 | val_0_accuracy: 0.80013 | val_1_accuracy: 0.78745 |  0:03:36s\n",
            "epoch 56 | loss: 0.5361  | val_0_accuracy: 0.79148 | val_1_accuracy: 0.77649 |  0:03:40s\n",
            "epoch 57 | loss: 0.53542 | val_0_accuracy: 0.79711 | val_1_accuracy: 0.78449 |  0:03:44s\n",
            "epoch 58 | loss: 0.53478 | val_0_accuracy: 0.79849 | val_1_accuracy: 0.78493 |  0:03:48s\n",
            "epoch 59 | loss: 0.53393 | val_0_accuracy: 0.80104 | val_1_accuracy: 0.78774 |  0:03:52s\n",
            "epoch 60 | loss: 0.53312 | val_0_accuracy: 0.80263 | val_1_accuracy: 0.78952 |  0:03:56s\n",
            "epoch 61 | loss: 0.5301  | val_0_accuracy: 0.8031  | val_1_accuracy: 0.78582 |  0:03:59s\n",
            "epoch 62 | loss: 0.53448 | val_0_accuracy: 0.80017 | val_1_accuracy: 0.78686 |  0:04:03s\n",
            "epoch 63 | loss: 0.53058 | val_0_accuracy: 0.79139 | val_1_accuracy: 0.77798 |  0:04:07s\n",
            "epoch 64 | loss: 0.52795 | val_0_accuracy: 0.80209 | val_1_accuracy: 0.78834 |  0:04:11s\n",
            "epoch 65 | loss: 0.52333 | val_0_accuracy: 0.79867 | val_1_accuracy: 0.78493 |  0:04:15s\n",
            "epoch 66 | loss: 0.52408 | val_0_accuracy: 0.80344 | val_1_accuracy: 0.79056 |  0:04:19s\n",
            "epoch 67 | loss: 0.52284 | val_0_accuracy: 0.80033 | val_1_accuracy: 0.7873  |  0:04:22s\n",
            "epoch 68 | loss: 0.52771 | val_0_accuracy: 0.80064 | val_1_accuracy: 0.7876  |  0:04:26s\n",
            "epoch 69 | loss: 0.52363 | val_0_accuracy: 0.80295 | val_1_accuracy: 0.79485 |  0:04:30s\n",
            "epoch 70 | loss: 0.52529 | val_0_accuracy: 0.80364 | val_1_accuracy: 0.78922 |  0:04:34s\n",
            "epoch 71 | loss: 0.51903 | val_0_accuracy: 0.80712 | val_1_accuracy: 0.79322 |  0:04:38s\n",
            "epoch 72 | loss: 0.51614 | val_0_accuracy: 0.80226 | val_1_accuracy: 0.78819 |  0:04:42s\n",
            "epoch 73 | loss: 0.51576 | val_0_accuracy: 0.80864 | val_1_accuracy: 0.79618 |  0:04:46s\n",
            "epoch 74 | loss: 0.5186  | val_0_accuracy: 0.78476 | val_1_accuracy: 0.76643 |  0:04:50s\n",
            "epoch 75 | loss: 0.51604 | val_0_accuracy: 0.80867 | val_1_accuracy: 0.7947  |  0:04:53s\n",
            "epoch 76 | loss: 0.51506 | val_0_accuracy: 0.80658 | val_1_accuracy: 0.79233 |  0:04:57s\n",
            "epoch 77 | loss: 0.52288 | val_0_accuracy: 0.80563 | val_1_accuracy: 0.79455 |  0:05:01s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 23.6%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 78 | loss: 0.5179  | val_0_accuracy: 0.80084 | val_1_accuracy: 0.79396 |  0:05:05s\n",
            "epoch 79 | loss: 0.51396 | val_0_accuracy: 0.80724 | val_1_accuracy: 0.79307 |  0:05:09s\n",
            "epoch 80 | loss: 0.5155  | val_0_accuracy: 0.80913 | val_1_accuracy: 0.79707 |  0:05:13s\n",
            "epoch 81 | loss: 0.51272 | val_0_accuracy: 0.81099 | val_1_accuracy: 0.79529 |  0:05:17s\n",
            "epoch 82 | loss: 0.51264 | val_0_accuracy: 0.80806 | val_1_accuracy: 0.79233 |  0:05:20s\n",
            "epoch 83 | loss: 0.51172 | val_0_accuracy: 0.80893 | val_1_accuracy: 0.79899 |  0:05:24s\n",
            "epoch 84 | loss: 0.51257 | val_0_accuracy: 0.80791 | val_1_accuracy: 0.79189 |  0:05:28s\n",
            "epoch 85 | loss: 0.50934 | val_0_accuracy: 0.80841 | val_1_accuracy: 0.79633 |  0:05:32s\n",
            "epoch 86 | loss: 0.50987 | val_0_accuracy: 0.80727 | val_1_accuracy: 0.79455 |  0:05:36s\n",
            "epoch 87 | loss: 0.50677 | val_0_accuracy: 0.81239 | val_1_accuracy: 0.79944 |  0:05:40s\n",
            "epoch 88 | loss: 0.50622 | val_0_accuracy: 0.80806 | val_1_accuracy: 0.79544 |  0:05:43s\n",
            "epoch 89 | loss: 0.51218 | val_0_accuracy: 0.80793 | val_1_accuracy: 0.79485 |  0:05:47s\n",
            "epoch 90 | loss: 0.50978 | val_0_accuracy: 0.8103  | val_1_accuracy: 0.79455 |  0:05:51s\n",
            "epoch 91 | loss: 0.50952 | val_0_accuracy: 0.8125  | val_1_accuracy: 0.79737 |  0:05:55s\n",
            "epoch 92 | loss: 0.50279 | val_0_accuracy: 0.81004 | val_1_accuracy: 0.79248 |  0:05:59s\n",
            "epoch 93 | loss: 0.50396 | val_0_accuracy: 0.8093  | val_1_accuracy: 0.78908 |  0:06:03s\n",
            "epoch 94 | loss: 0.50874 | val_0_accuracy: 0.81089 | val_1_accuracy: 0.79781 |  0:06:07s\n",
            "epoch 95 | loss: 0.5077  | val_0_accuracy: 0.81479 | val_1_accuracy: 0.79914 |  0:06:11s\n",
            "epoch 96 | loss: 0.50077 | val_0_accuracy: 0.8141  | val_1_accuracy: 0.79825 |  0:06:14s\n",
            "epoch 97 | loss: 0.50302 | val_0_accuracy: 0.81546 | val_1_accuracy: 0.79707 |  0:06:18s\n",
            "\n",
            "Early stopping occurred at epoch 97 with best_epoch = 87 and best_val_1_accuracy = 0.79944\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2 predictions truth\n",
            "0   0.116486  0.085798  0.797716           2     2\n",
            "1   0.140744  0.231525  0.627732           2     2\n",
            "2   0.009396  0.003618  0.986986           2     2\n",
            "3   0.010546  0.002761  0.986693           2     2\n",
            "4   0.005172  0.000566  0.994262           2     2\n",
            "5   0.023313  0.083762  0.892925           2     2\n",
            "6   0.031927  0.024029  0.944044           2     2\n",
            "7   0.015168  0.024321  0.960510           2     2\n",
            "8   0.030602  0.023368  0.946030           2     2\n",
            "9   0.013414  0.009467  0.977119           2     2\n",
            "10  0.049409  0.028523  0.922069           2     2\n",
            "11  0.079382  0.120427  0.800191           2     2\n",
            "12  0.021199  0.005867  0.972933           2     2\n",
            "13  0.091637  0.210001  0.698362           2     2\n",
            "14  0.003188  0.000328  0.996484           2     2\n",
            "15  0.028908  0.023844  0.947247           2     2\n",
            "16  0.067200  0.027342  0.905458           2     2\n",
            "17  0.136768  0.065087  0.798145           2     2\n",
            "18  0.060824  0.335110  0.604066           2     2\n",
            "19  0.088060  0.641004  0.270936           1     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.7994375370041444,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.5805305677845115,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146195',\n",
            "  'info': None,\n",
            "  'logloss': 0.514357744963175,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.11871337890625,\n",
            "  'result': 0.514357744963175,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'connect-4',\n",
            "  'training_duration': 380.00733852386475,\n",
            "  'utc': '2021-02-04T16:05:32',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.connect-4.0.TabNet executed in 410.330 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.connect-4.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task connect-4.\n",
            "Assigning 7945 MB (total=13021 MB) for new connect-4 task.\n",
            "Running task connect-4 on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='connect-4', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7945, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.85483 | val_0_accuracy: 0.65828 | val_1_accuracy: 0.65838 |  0:00:03s\n",
            "epoch 1  | loss: 0.80308 | val_0_accuracy: 0.66172 | val_1_accuracy: 0.66297 |  0:00:07s\n",
            "epoch 2  | loss: 0.77906 | val_0_accuracy: 0.68257 | val_1_accuracy: 0.68443 |  0:00:11s\n",
            "epoch 3  | loss: 0.76606 | val_0_accuracy: 0.68306 | val_1_accuracy: 0.68546 |  0:00:15s\n",
            "epoch 4  | loss: 0.75985 | val_0_accuracy: 0.68989 | val_1_accuracy: 0.68413 |  0:00:19s\n",
            "epoch 5  | loss: 0.75119 | val_0_accuracy: 0.68982 | val_1_accuracy: 0.69449 |  0:00:23s\n",
            "epoch 6  | loss: 0.73896 | val_0_accuracy: 0.69979 | val_1_accuracy: 0.70515 |  0:00:26s\n",
            "epoch 7  | loss: 0.73616 | val_0_accuracy: 0.69575 | val_1_accuracy: 0.69775 |  0:00:30s\n",
            "epoch 8  | loss: 0.73075 | val_0_accuracy: 0.70571 | val_1_accuracy: 0.70619 |  0:00:34s\n",
            "epoch 9  | loss: 0.72614 | val_0_accuracy: 0.70481 | val_1_accuracy: 0.70426 |  0:00:38s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 23.3%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 10 | loss: 0.71858 | val_0_accuracy: 0.71425 | val_1_accuracy: 0.71226 |  0:00:42s\n",
            "epoch 11 | loss: 0.71678 | val_0_accuracy: 0.71466 | val_1_accuracy: 0.71684 |  0:00:46s\n",
            "epoch 12 | loss: 0.7133  | val_0_accuracy: 0.71625 | val_1_accuracy: 0.72336 |  0:00:50s\n",
            "epoch 13 | loss: 0.70505 | val_0_accuracy: 0.71191 | val_1_accuracy: 0.71329 |  0:00:53s\n",
            "epoch 14 | loss: 0.70366 | val_0_accuracy: 0.71739 | val_1_accuracy: 0.72158 |  0:00:57s\n",
            "epoch 15 | loss: 0.6966  | val_0_accuracy: 0.72222 | val_1_accuracy: 0.72291 |  0:01:01s\n",
            "epoch 16 | loss: 0.68981 | val_0_accuracy: 0.72367 | val_1_accuracy: 0.72513 |  0:01:05s\n",
            "epoch 17 | loss: 0.69399 | val_0_accuracy: 0.71665 | val_1_accuracy: 0.71566 |  0:01:09s\n",
            "epoch 18 | loss: 0.69364 | val_0_accuracy: 0.72    | val_1_accuracy: 0.71847 |  0:01:13s\n",
            "epoch 19 | loss: 0.69109 | val_0_accuracy: 0.7278  | val_1_accuracy: 0.72721 |  0:01:17s\n",
            "epoch 20 | loss: 0.68306 | val_0_accuracy: 0.73097 | val_1_accuracy: 0.72721 |  0:01:20s\n",
            "epoch 21 | loss: 0.67318 | val_0_accuracy: 0.73782 | val_1_accuracy: 0.73076 |  0:01:24s\n",
            "epoch 22 | loss: 0.67173 | val_0_accuracy: 0.73558 | val_1_accuracy: 0.73446 |  0:01:28s\n",
            "epoch 23 | loss: 0.67143 | val_0_accuracy: 0.73252 | val_1_accuracy: 0.72839 |  0:01:32s\n",
            "epoch 24 | loss: 0.67033 | val_0_accuracy: 0.74167 | val_1_accuracy: 0.73934 |  0:01:36s\n",
            "epoch 25 | loss: 0.6533  | val_0_accuracy: 0.75099 | val_1_accuracy: 0.74704 |  0:01:40s\n",
            "epoch 26 | loss: 0.64636 | val_0_accuracy: 0.75366 | val_1_accuracy: 0.74911 |  0:01:43s\n",
            "epoch 27 | loss: 0.64441 | val_0_accuracy: 0.75292 | val_1_accuracy: 0.74867 |  0:01:47s\n",
            "epoch 28 | loss: 0.64752 | val_0_accuracy: 0.74275 | val_1_accuracy: 0.73949 |  0:01:51s\n",
            "epoch 29 | loss: 0.64797 | val_0_accuracy: 0.72675 | val_1_accuracy: 0.72484 |  0:01:55s\n",
            "epoch 30 | loss: 0.64021 | val_0_accuracy: 0.75583 | val_1_accuracy: 0.74985 |  0:01:59s\n",
            "epoch 31 | loss: 0.62733 | val_0_accuracy: 0.75946 | val_1_accuracy: 0.7571  |  0:02:03s\n",
            "epoch 32 | loss: 0.6257  | val_0_accuracy: 0.75152 | val_1_accuracy: 0.74704 |  0:02:06s\n",
            "epoch 33 | loss: 0.62436 | val_0_accuracy: 0.76198 | val_1_accuracy: 0.75429 |  0:02:10s\n",
            "epoch 34 | loss: 0.61923 | val_0_accuracy: 0.76316 | val_1_accuracy: 0.7571  |  0:02:14s\n",
            "epoch 35 | loss: 0.61338 | val_0_accuracy: 0.76724 | val_1_accuracy: 0.75903 |  0:02:18s\n",
            "epoch 36 | loss: 0.6079  | val_0_accuracy: 0.7688  | val_1_accuracy: 0.75888 |  0:02:22s\n",
            "epoch 37 | loss: 0.60689 | val_0_accuracy: 0.76665 | val_1_accuracy: 0.75977 |  0:02:26s\n",
            "epoch 38 | loss: 0.60326 | val_0_accuracy: 0.77301 | val_1_accuracy: 0.76451 |  0:02:30s\n",
            "epoch 39 | loss: 0.59345 | val_0_accuracy: 0.77681 | val_1_accuracy: 0.76924 |  0:02:33s\n",
            "epoch 40 | loss: 0.58864 | val_0_accuracy: 0.77912 | val_1_accuracy: 0.76776 |  0:02:37s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 23.3%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 41 | loss: 0.58681 | val_0_accuracy: 0.77699 | val_1_accuracy: 0.77265 |  0:02:41s\n",
            "epoch 42 | loss: 0.58447 | val_0_accuracy: 0.77838 | val_1_accuracy: 0.77087 |  0:02:45s\n",
            "epoch 43 | loss: 0.58115 | val_0_accuracy: 0.77395 | val_1_accuracy: 0.7685  |  0:02:49s\n",
            "epoch 44 | loss: 0.5776  | val_0_accuracy: 0.78678 | val_1_accuracy: 0.7796  |  0:02:53s\n",
            "epoch 45 | loss: 0.56986 | val_0_accuracy: 0.78555 | val_1_accuracy: 0.77501 |  0:02:57s\n",
            "epoch 46 | loss: 0.57333 | val_0_accuracy: 0.78708 | val_1_accuracy: 0.7796  |  0:03:00s\n",
            "epoch 47 | loss: 0.56731 | val_0_accuracy: 0.78717 | val_1_accuracy: 0.77709 |  0:03:04s\n",
            "epoch 48 | loss: 0.56593 | val_0_accuracy: 0.78724 | val_1_accuracy: 0.77886 |  0:03:08s\n",
            "epoch 49 | loss: 0.56307 | val_0_accuracy: 0.79089 | val_1_accuracy: 0.78301 |  0:03:12s\n",
            "epoch 50 | loss: 0.55966 | val_0_accuracy: 0.78594 | val_1_accuracy: 0.77798 |  0:03:16s\n",
            "epoch 51 | loss: 0.5582  | val_0_accuracy: 0.7949  | val_1_accuracy: 0.78612 |  0:03:19s\n",
            "epoch 52 | loss: 0.55671 | val_0_accuracy: 0.78854 | val_1_accuracy: 0.78064 |  0:03:24s\n",
            "epoch 53 | loss: 0.55738 | val_0_accuracy: 0.79453 | val_1_accuracy: 0.78271 |  0:03:27s\n",
            "epoch 54 | loss: 0.55061 | val_0_accuracy: 0.79119 | val_1_accuracy: 0.78138 |  0:03:31s\n",
            "epoch 55 | loss: 0.55207 | val_0_accuracy: 0.7963  | val_1_accuracy: 0.78256 |  0:03:35s\n",
            "epoch 56 | loss: 0.54426 | val_0_accuracy: 0.79221 | val_1_accuracy: 0.77931 |  0:03:39s\n",
            "epoch 57 | loss: 0.55105 | val_0_accuracy: 0.79268 | val_1_accuracy: 0.78345 |  0:03:43s\n",
            "epoch 58 | loss: 0.55079 | val_0_accuracy: 0.79704 | val_1_accuracy: 0.78819 |  0:03:47s\n",
            "epoch 59 | loss: 0.54336 | val_0_accuracy: 0.79507 | val_1_accuracy: 0.78789 |  0:03:51s\n",
            "epoch 60 | loss: 0.54136 | val_0_accuracy: 0.79852 | val_1_accuracy: 0.79115 |  0:03:54s\n",
            "epoch 61 | loss: 0.54277 | val_0_accuracy: 0.79974 | val_1_accuracy: 0.78804 |  0:03:58s\n",
            "epoch 62 | loss: 0.53816 | val_0_accuracy: 0.8018  | val_1_accuracy: 0.79189 |  0:04:02s\n",
            "epoch 63 | loss: 0.5367  | val_0_accuracy: 0.80449 | val_1_accuracy: 0.79278 |  0:04:06s\n",
            "epoch 64 | loss: 0.53702 | val_0_accuracy: 0.80148 | val_1_accuracy: 0.79026 |  0:04:10s\n",
            "epoch 65 | loss: 0.53495 | val_0_accuracy: 0.80022 | val_1_accuracy: 0.79159 |  0:04:14s\n",
            "epoch 66 | loss: 0.54417 | val_0_accuracy: 0.80033 | val_1_accuracy: 0.78582 |  0:04:17s\n",
            "epoch 67 | loss: 0.5312  | val_0_accuracy: 0.80201 | val_1_accuracy: 0.79366 |  0:04:21s\n",
            "epoch 68 | loss: 0.53172 | val_0_accuracy: 0.79699 | val_1_accuracy: 0.78316 |  0:04:25s\n",
            "epoch 69 | loss: 0.53879 | val_0_accuracy: 0.7999  | val_1_accuracy: 0.78538 |  0:04:29s\n",
            "epoch 70 | loss: 0.52961 | val_0_accuracy: 0.80282 | val_1_accuracy: 0.78967 |  0:04:33s\n",
            "epoch 71 | loss: 0.5272  | val_0_accuracy: 0.80527 | val_1_accuracy: 0.78967 |  0:04:37s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 23.4%\n",
            "[499] Disk Usage: 23.0%\n",
            "epoch 72 | loss: 0.52589 | val_0_accuracy: 0.80555 | val_1_accuracy: 0.79144 |  0:04:41s\n",
            "epoch 73 | loss: 0.52981 | val_0_accuracy: 0.80517 | val_1_accuracy: 0.79174 |  0:04:45s\n",
            "epoch 74 | loss: 0.5262  | val_0_accuracy: 0.80444 | val_1_accuracy: 0.78789 |  0:04:48s\n",
            "epoch 75 | loss: 0.5243  | val_0_accuracy: 0.80884 | val_1_accuracy: 0.79337 |  0:04:52s\n",
            "epoch 76 | loss: 0.52221 | val_0_accuracy: 0.80933 | val_1_accuracy: 0.79292 |  0:04:56s\n",
            "epoch 77 | loss: 0.52402 | val_0_accuracy: 0.81066 | val_1_accuracy: 0.79751 |  0:05:00s\n",
            "epoch 78 | loss: 0.51841 | val_0_accuracy: 0.81051 | val_1_accuracy: 0.80033 |  0:05:04s\n",
            "epoch 79 | loss: 0.52084 | val_0_accuracy: 0.80106 | val_1_accuracy: 0.78656 |  0:05:08s\n",
            "epoch 80 | loss: 0.52381 | val_0_accuracy: 0.80041 | val_1_accuracy: 0.78612 |  0:05:11s\n",
            "epoch 81 | loss: 0.5208  | val_0_accuracy: 0.81028 | val_1_accuracy: 0.79722 |  0:05:15s\n",
            "epoch 82 | loss: 0.51802 | val_0_accuracy: 0.80734 | val_1_accuracy: 0.79618 |  0:05:19s\n",
            "epoch 83 | loss: 0.52539 | val_0_accuracy: 0.80624 | val_1_accuracy: 0.79233 |  0:05:23s\n",
            "epoch 84 | loss: 0.52261 | val_0_accuracy: 0.8062  | val_1_accuracy: 0.79263 |  0:05:27s\n",
            "epoch 85 | loss: 0.51565 | val_0_accuracy: 0.80819 | val_1_accuracy: 0.791   |  0:05:31s\n",
            "epoch 86 | loss: 0.52246 | val_0_accuracy: 0.79112 | val_1_accuracy: 0.7836  |  0:05:35s\n",
            "epoch 87 | loss: 0.52016 | val_0_accuracy: 0.8112  | val_1_accuracy: 0.79529 |  0:05:38s\n",
            "epoch 88 | loss: 0.51239 | val_0_accuracy: 0.80913 | val_1_accuracy: 0.79559 |  0:05:42s\n",
            "\n",
            "Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_1_accuracy = 0.80033\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2 predictions truth\n",
            "0   0.103103  0.721179  0.175719           1     2\n",
            "1   0.317127  0.225312  0.457561           2     2\n",
            "2   0.022696  0.033507  0.943797           2     2\n",
            "3   0.003844  0.027169  0.968987           2     2\n",
            "4   0.016539  0.028121  0.955340           2     2\n",
            "5   0.057666  0.055304  0.887030           2     2\n",
            "6   0.020346  0.010673  0.968981           2     2\n",
            "7   0.046829  0.027386  0.925785           2     2\n",
            "8   0.011458  0.002044  0.986497           2     2\n",
            "9   0.110725  0.051552  0.837723           2     2\n",
            "10  0.011765  0.006527  0.981708           2     2\n",
            "11  0.016306  0.003536  0.980158           2     2\n",
            "12  0.214295  0.521152  0.264554           1     2\n",
            "13  0.034533  0.047836  0.917631           2     2\n",
            "14  0.118852  0.576209  0.304940           1     2\n",
            "15  0.066413  0.033720  0.899867           2     2\n",
            "16  0.010372  0.008968  0.980660           2     2\n",
            "17  0.209351  0.565665  0.224985           1     2\n",
            "18  0.087741  0.349424  0.562835           2     2\n",
            "19  0.048138  0.021611  0.930251           2     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/connect-4/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.8003256364712847,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.5622337240473462,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146195',\n",
            "  'info': None,\n",
            "  'logloss': 0.5196316631937495,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.12123632431030273,\n",
            "  'result': 0.5196316631937495,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'connect-4',\n",
            "  'training_duration': 344.0655241012573,\n",
            "  'utc': '2021-02-04T16:11:21',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.connect-4.1.TabNet executed in 349.259 seconds.\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Fashion-MNIST.0.TabNet.\n",
            "[499] CPU Utilization: 41.8%\n",
            "[499] Memory Usage: 23.5%\n",
            "[499] Disk Usage: 23.4%\n",
            "Assigning 2 cores (total=2) for new task Fashion-MNIST.\n",
            "Assigning 7925 MB (total=13021 MB) for new Fashion-MNIST task.\n",
            "Running task Fashion-MNIST on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Fashion-MNIST', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7925, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.53224 | val_0_accuracy: 0.54059 | val_1_accuracy: 0.54671 |  0:00:05s\n",
            "epoch 1  | loss: 0.74535 | val_0_accuracy: 0.74081 | val_1_accuracy: 0.743   |  0:00:10s\n",
            "epoch 2  | loss: 0.58993 | val_0_accuracy: 0.81249 | val_1_accuracy: 0.80971 |  0:00:16s\n",
            "epoch 3  | loss: 0.52068 | val_0_accuracy: 0.83298 | val_1_accuracy: 0.82957 |  0:00:21s\n",
            "epoch 4  | loss: 0.48267 | val_0_accuracy: 0.84325 | val_1_accuracy: 0.84314 |  0:00:27s\n",
            "[499] CPU Utilization: 50.8%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 23.6%\n",
            "epoch 5  | loss: 0.44206 | val_0_accuracy: 0.8553  | val_1_accuracy: 0.852   |  0:00:32s\n",
            "epoch 6  | loss: 0.42127 | val_0_accuracy: 0.8649  | val_1_accuracy: 0.86314 |  0:00:38s\n",
            "epoch 7  | loss: 0.40041 | val_0_accuracy: 0.86798 | val_1_accuracy: 0.86357 |  0:00:43s\n",
            "epoch 8  | loss: 0.38767 | val_0_accuracy: 0.87824 | val_1_accuracy: 0.86843 |  0:00:48s\n",
            "epoch 9  | loss: 0.38385 | val_0_accuracy: 0.87444 | val_1_accuracy: 0.86586 |  0:00:54s\n",
            "epoch 10 | loss: 0.36454 | val_0_accuracy: 0.88117 | val_1_accuracy: 0.87086 |  0:00:59s\n",
            "epoch 11 | loss: 0.36015 | val_0_accuracy: 0.87905 | val_1_accuracy: 0.86971 |  0:01:05s\n",
            "epoch 12 | loss: 0.3483  | val_0_accuracy: 0.88368 | val_1_accuracy: 0.87143 |  0:01:10s\n",
            "epoch 13 | loss: 0.34299 | val_0_accuracy: 0.88289 | val_1_accuracy: 0.87214 |  0:01:16s\n",
            "epoch 14 | loss: 0.33819 | val_0_accuracy: 0.88532 | val_1_accuracy: 0.86986 |  0:01:21s\n",
            "epoch 15 | loss: 0.33161 | val_0_accuracy: 0.89135 | val_1_accuracy: 0.87843 |  0:01:27s\n",
            "epoch 16 | loss: 0.3282  | val_0_accuracy: 0.89343 | val_1_accuracy: 0.87714 |  0:01:32s\n",
            "epoch 17 | loss: 0.31622 | val_0_accuracy: 0.89927 | val_1_accuracy: 0.87971 |  0:01:38s\n",
            "epoch 18 | loss: 0.31284 | val_0_accuracy: 0.90073 | val_1_accuracy: 0.88457 |  0:01:43s\n",
            "epoch 19 | loss: 0.30781 | val_0_accuracy: 0.89906 | val_1_accuracy: 0.87914 |  0:01:48s\n",
            "epoch 20 | loss: 0.30533 | val_0_accuracy: 0.89227 | val_1_accuracy: 0.86957 |  0:01:54s\n",
            "epoch 21 | loss: 0.30278 | val_0_accuracy: 0.8981  | val_1_accuracy: 0.87429 |  0:01:59s\n",
            "epoch 22 | loss: 0.30523 | val_0_accuracy: 0.89673 | val_1_accuracy: 0.87557 |  0:02:05s\n",
            "epoch 23 | loss: 0.31031 | val_0_accuracy: 0.898   | val_1_accuracy: 0.87857 |  0:02:10s\n",
            "epoch 24 | loss: 0.29918 | val_0_accuracy: 0.89767 | val_1_accuracy: 0.87414 |  0:02:16s\n",
            "epoch 25 | loss: 0.29229 | val_0_accuracy: 0.9029  | val_1_accuracy: 0.88057 |  0:02:21s\n",
            "epoch 26 | loss: 0.29356 | val_0_accuracy: 0.90495 | val_1_accuracy: 0.87943 |  0:02:26s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 34.6%\n",
            "[499] Disk Usage: 23.6%\n",
            "epoch 27 | loss: 0.2861  | val_0_accuracy: 0.91038 | val_1_accuracy: 0.88186 |  0:02:32s\n",
            "epoch 28 | loss: 0.28218 | val_0_accuracy: 0.90925 | val_1_accuracy: 0.88171 |  0:02:37s\n",
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_1_accuracy = 0.88457\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "                0         1             2             3             4         5         6         7             8         9 predictions truth\n",
            "0   2.238413e-07  0.000027  1.159347e-06  3.917663e-08  1.902567e-05  0.999914  0.000031  0.000005  1.608583e-07  0.000002           5     5\n",
            "1   2.605773e-06  0.000006  4.573218e-06  6.475587e-08  6.082016e-06  0.999366  0.000067  0.000443  6.576615e-06  0.000098           5     5\n",
            "2   2.280545e-05  0.000022  1.248223e-06  7.830851e-07  3.375644e-07  0.993977  0.000030  0.005744  4.308326e-05  0.000159           5     5\n",
            "3   5.094233e-04  0.000360  5.341390e-03  1.779776e-05  1.538660e-03  0.892684  0.005994  0.033206  1.912511e-03  0.058436           5     5\n",
            "4   1.149707e-05  0.000007  9.474015e-04  2.040564e-07  8.881956e-05  0.350914  0.000242  0.222052  1.288441e-04  0.425608           9     5\n",
            "5   2.229404e-03  0.001552  1.728204e-03  7.651107e-05  3.062332e-04  0.909073  0.003643  0.028448  7.723215e-03  0.045221           5     5\n",
            "6   4.344609e-06  0.000008  2.844350e-06  1.092694e-07  6.395944e-06  0.999781  0.000093  0.000064  1.805065e-05  0.000023           5     5\n",
            "7   7.261684e-05  0.005303  3.245530e-05  2.932590e-05  5.085124e-06  0.962486  0.000085  0.031132  2.647533e-05  0.000828           5     5\n",
            "8   2.120477e-07  0.000046  5.380678e-07  6.156186e-08  5.413906e-06  0.999922  0.000014  0.000010  1.492959e-07  0.000002           5     5\n",
            "9   8.901006e-07  0.000168  1.834037e-06  2.459596e-07  1.535279e-07  0.937569  0.000002  0.061078  1.594596e-06  0.001178           5     5\n",
            "10  4.646696e-07  0.000077  4.816328e-07  1.564816e-07  3.257671e-06  0.999882  0.000014  0.000020  3.027584e-07  0.000002           5     5\n",
            "11  9.490959e-06  0.000126  1.119026e-05  4.556543e-07  5.666938e-06  0.995999  0.000036  0.000602  1.275148e-04  0.003083           5     5\n",
            "12  4.802162e-07  0.000003  9.817717e-07  1.510779e-08  1.315004e-06  0.999568  0.000013  0.000348  1.283756e-06  0.000063           5     5\n",
            "13  2.455626e-05  0.004127  2.500491e-05  1.111683e-05  5.682138e-06  0.980074  0.000055  0.015074  8.828702e-06  0.000594           5     5\n",
            "14  8.399479e-07  0.000052  2.952424e-06  4.497999e-08  4.803614e-06  0.999071  0.000011  0.000022  3.100649e-05  0.000805           5     5\n",
            "15  2.104804e-07  0.000002  1.072803e-06  6.686599e-09  3.003790e-06  0.999838  0.000015  0.000105  7.146033e-07  0.000036           5     5\n",
            "16  3.092489e-06  0.000104  6.459872e-06  2.324530e-07  9.853625e-06  0.999066  0.000030  0.000066  5.936553e-05  0.000655           5     5\n",
            "17  6.634537e-06  0.000110  8.829095e-06  3.919070e-07  1.073947e-05  0.998551  0.000044  0.000096  1.474438e-04  0.001025           5     5\n",
            "18  3.803812e-06  0.000037  4.887916e-05  8.439656e-08  2.414374e-05  0.993011  0.000091  0.002791  9.205089e-06  0.003983           5     5\n",
            "19  2.291287e-06  0.000137  4.721833e-06  4.492322e-07  1.933770e-05  0.999635  0.000058  0.000111  1.631283e-06  0.000030           5     5\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.8845714285714286,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.8845714285714287,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146825',\n",
            "  'info': None,\n",
            "  'logloss': 0.33177728830893644,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.1596841812133789,\n",
            "  'result': 0.33177728830893644,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Fashion-MNIST',\n",
            "  'training_duration': 160.49723863601685,\n",
            "  'utc': '2021-02-04T16:16:30',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Fashion-MNIST.0.TabNet executed in 308.523 seconds.\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Fashion-MNIST.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Fashion-MNIST.\n",
            "Assigning 7930 MB (total=13021 MB) for new Fashion-MNIST task.\n",
            "Running task Fashion-MNIST on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Fashion-MNIST', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7930, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.64626 | val_0_accuracy: 0.54673 | val_1_accuracy: 0.54986 |  0:00:05s\n",
            "epoch 1  | loss: 0.79924 | val_0_accuracy: 0.73221 | val_1_accuracy: 0.73257 |  0:00:10s\n",
            "epoch 2  | loss: 0.64594 | val_0_accuracy: 0.79411 | val_1_accuracy: 0.79729 |  0:00:16s\n",
            "epoch 3  | loss: 0.56345 | val_0_accuracy: 0.82008 | val_1_accuracy: 0.81957 |  0:00:21s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 33.9%\n",
            "[499] Disk Usage: 23.7%\n",
            "epoch 4  | loss: 0.52514 | val_0_accuracy: 0.83343 | val_1_accuracy: 0.82929 |  0:00:27s\n",
            "epoch 5  | loss: 0.48858 | val_0_accuracy: 0.84306 | val_1_accuracy: 0.84314 |  0:00:32s\n",
            "epoch 6  | loss: 0.46114 | val_0_accuracy: 0.8586  | val_1_accuracy: 0.85614 |  0:00:38s\n",
            "epoch 7  | loss: 0.41955 | val_0_accuracy: 0.86548 | val_1_accuracy: 0.86029 |  0:00:43s\n",
            "epoch 8  | loss: 0.40347 | val_0_accuracy: 0.87214 | val_1_accuracy: 0.86529 |  0:00:48s\n",
            "epoch 9  | loss: 0.39199 | val_0_accuracy: 0.87002 | val_1_accuracy: 0.86343 |  0:00:54s\n",
            "epoch 10 | loss: 0.37828 | val_0_accuracy: 0.87457 | val_1_accuracy: 0.864   |  0:00:59s\n",
            "epoch 11 | loss: 0.37268 | val_0_accuracy: 0.8833  | val_1_accuracy: 0.87229 |  0:01:05s\n",
            "epoch 12 | loss: 0.35666 | val_0_accuracy: 0.88489 | val_1_accuracy: 0.87514 |  0:01:10s\n",
            "epoch 13 | loss: 0.34617 | val_0_accuracy: 0.88783 | val_1_accuracy: 0.87086 |  0:01:16s\n",
            "epoch 14 | loss: 0.33719 | val_0_accuracy: 0.8901  | val_1_accuracy: 0.87071 |  0:01:21s\n",
            "epoch 15 | loss: 0.32745 | val_0_accuracy: 0.89276 | val_1_accuracy: 0.88371 |  0:01:27s\n",
            "epoch 16 | loss: 0.32804 | val_0_accuracy: 0.89427 | val_1_accuracy: 0.87657 |  0:01:32s\n",
            "epoch 17 | loss: 0.31715 | val_0_accuracy: 0.89713 | val_1_accuracy: 0.87943 |  0:01:38s\n",
            "epoch 18 | loss: 0.32176 | val_0_accuracy: 0.89649 | val_1_accuracy: 0.88271 |  0:01:43s\n",
            "epoch 19 | loss: 0.31192 | val_0_accuracy: 0.89856 | val_1_accuracy: 0.87886 |  0:01:48s\n",
            "epoch 20 | loss: 0.30913 | val_0_accuracy: 0.89646 | val_1_accuracy: 0.87657 |  0:01:54s\n",
            "epoch 21 | loss: 0.30293 | val_0_accuracy: 0.90554 | val_1_accuracy: 0.88857 |  0:01:59s\n",
            "epoch 22 | loss: 0.29422 | val_0_accuracy: 0.90386 | val_1_accuracy: 0.88429 |  0:02:04s\n",
            "epoch 23 | loss: 0.29763 | val_0_accuracy: 0.90254 | val_1_accuracy: 0.87943 |  0:02:10s\n",
            "epoch 24 | loss: 0.28929 | val_0_accuracy: 0.90657 | val_1_accuracy: 0.88429 |  0:02:15s\n",
            "epoch 25 | loss: 0.2932  | val_0_accuracy: 0.90749 | val_1_accuracy: 0.88529 |  0:02:20s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 34.4%\n",
            "[499] Disk Usage: 23.7%\n",
            "epoch 26 | loss: 0.28809 | val_0_accuracy: 0.90875 | val_1_accuracy: 0.88629 |  0:02:25s\n",
            "epoch 27 | loss: 0.28688 | val_0_accuracy: 0.90392 | val_1_accuracy: 0.88243 |  0:02:30s\n",
            "epoch 28 | loss: 0.28116 | val_0_accuracy: 0.91002 | val_1_accuracy: 0.88457 |  0:02:36s\n",
            "epoch 29 | loss: 0.27715 | val_0_accuracy: 0.90998 | val_1_accuracy: 0.883   |  0:02:41s\n",
            "epoch 30 | loss: 0.27218 | val_0_accuracy: 0.91011 | val_1_accuracy: 0.88414 |  0:02:46s\n",
            "epoch 31 | loss: 0.2659  | val_0_accuracy: 0.91797 | val_1_accuracy: 0.89257 |  0:02:51s\n",
            "epoch 32 | loss: 0.26071 | val_0_accuracy: 0.90895 | val_1_accuracy: 0.88557 |  0:02:56s\n",
            "epoch 33 | loss: 0.26811 | val_0_accuracy: 0.91529 | val_1_accuracy: 0.88714 |  0:03:01s\n",
            "epoch 34 | loss: 0.2607  | val_0_accuracy: 0.90459 | val_1_accuracy: 0.87029 |  0:03:06s\n",
            "epoch 35 | loss: 0.2587  | val_0_accuracy: 0.91567 | val_1_accuracy: 0.88457 |  0:03:11s\n",
            "epoch 36 | loss: 0.25793 | val_0_accuracy: 0.91552 | val_1_accuracy: 0.88614 |  0:03:16s\n",
            "epoch 37 | loss: 0.26106 | val_0_accuracy: 0.91354 | val_1_accuracy: 0.88329 |  0:03:21s\n",
            "epoch 38 | loss: 0.25885 | val_0_accuracy: 0.91925 | val_1_accuracy: 0.88814 |  0:03:26s\n",
            "epoch 39 | loss: 0.24684 | val_0_accuracy: 0.91802 | val_1_accuracy: 0.88471 |  0:03:31s\n",
            "epoch 40 | loss: 0.24856 | val_0_accuracy: 0.91829 | val_1_accuracy: 0.883   |  0:03:36s\n",
            "epoch 41 | loss: 0.24333 | val_0_accuracy: 0.92373 | val_1_accuracy: 0.88886 |  0:03:41s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_1_accuracy = 0.89257\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "                0             1             2             3             4         5             6         7             8             9 predictions truth\n",
            "0   1.014753e-06  8.551270e-06  1.833157e-05  5.641643e-07  8.889421e-06  0.993607  1.093009e-05  0.005893  8.037785e-05  3.708455e-04           5     5\n",
            "1   1.322250e-08  4.136670e-08  3.698679e-08  1.054623e-09  2.400056e-08  0.999840  3.150053e-07  0.000138  1.103963e-05  1.043735e-05           5     5\n",
            "2   9.662235e-07  4.825074e-07  1.865170e-05  3.696682e-08  4.749714e-06  0.998531  2.050133e-05  0.000673  3.731750e-04  3.780787e-04           5     5\n",
            "3   2.692058e-07  1.961422e-05  5.732698e-07  1.449519e-07  2.611685e-06  0.999846  5.478942e-06  0.000052  7.005192e-05  2.861116e-06           5     5\n",
            "4   3.996811e-07  2.329949e-06  5.100539e-06  4.144842e-08  3.388915e-06  0.999464  9.268061e-06  0.000328  1.598659e-04  2.767320e-05           5     5\n",
            "5   2.972794e-09  1.785040e-07  5.378231e-09  7.038200e-10  1.121645e-08  0.999949  8.363850e-08  0.000048  2.310385e-06  4.825685e-07           5     5\n",
            "6   5.298177e-09  2.288619e-05  1.314381e-08  1.179389e-08  1.189636e-07  0.999912  5.584318e-08  0.000052  1.350242e-05  4.822677e-08           5     5\n",
            "7   4.314113e-09  3.674104e-05  7.033055e-09  1.496154e-08  8.157200e-08  0.999898  3.572634e-08  0.000055  9.871389e-06  3.252064e-08           5     5\n",
            "8   3.101920e-06  1.381144e-06  1.485216e-05  1.817492e-07  3.600947e-06  0.998595  7.703026e-05  0.000683  4.389203e-05  5.780301e-04           5     5\n",
            "9   2.569183e-08  7.087143e-08  7.843825e-08  1.830971e-09  4.480731e-08  0.999825  5.851518e-07  0.000145  1.527798e-05  1.408835e-05           5     5\n",
            "10  1.164820e-09  1.039901e-06  1.850933e-09  1.142722e-09  1.045781e-08  0.999953  2.029913e-08  0.000044  1.992928e-06  7.854025e-08           5     5\n",
            "11  2.643939e-08  1.165408e-07  8.976804e-08  2.241019e-09  6.726226e-08  0.999833  9.829540e-07  0.000150  7.439101e-06  7.889347e-06           5     5\n",
            "12  2.179599e-07  2.048455e-06  2.935838e-06  2.832961e-08  1.880585e-06  0.999571  3.745527e-06  0.000310  7.694976e-05  3.093634e-05           5     5\n",
            "13  7.408030e-07  7.197364e-07  1.249075e-05  4.080696e-08  3.842159e-06  0.998764  1.422789e-05  0.000660  3.545613e-04  1.897836e-04           5     5\n",
            "14  1.795097e-10  5.704599e-07  1.629431e-10  3.155955e-10  1.692829e-09  0.999970  2.740588e-09  0.000029  5.293425e-07  2.093838e-08           5     5\n",
            "15  3.061829e-09  1.458616e-07  6.298157e-09  6.750827e-10  1.172904e-08  0.999941  8.530013e-08  0.000055  2.532029e-06  6.456996e-07           5     5\n",
            "16  8.672141e-08  1.525966e-08  5.123719e-07  2.015139e-09  1.239127e-07  0.999254  2.877436e-06  0.000391  1.994997e-05  3.314253e-04           5     5\n",
            "17  6.711600e-08  2.208108e-05  6.023567e-07  4.524091e-08  1.318286e-06  0.999781  9.374390e-07  0.000126  6.741993e-05  6.673716e-07           5     5\n",
            "18  4.162031e-05  2.426404e-07  1.490819e-04  7.437758e-07  4.928698e-06  0.739216  4.793560e-04  0.018307  5.183201e-05  2.417495e-01           5     5\n",
            "19  1.264507e-07  2.496623e-08  7.076436e-07  3.397215e-09  1.828905e-07  0.999221  3.937546e-06  0.000410  2.679105e-05  3.373169e-04           5     5\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Fashion-MNIST/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.8925714285714286,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.8925714285714286,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146825',\n",
            "  'info': None,\n",
            "  'logloss': 0.32802775854038063,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.16330671310424805,\n",
            "  'result': 0.32802775854038063,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Fashion-MNIST',\n",
            "  'training_duration': 224.17473649978638,\n",
            "  'utc': '2021-02-04T16:21:40',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Fashion-MNIST.1.TabNet executed in 310.463 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.guillermo.0.TabNet.\n",
            "[499] CPU Utilization: 37.2%\n",
            "[499] Memory Usage: 24.3%\n",
            "[499] Disk Usage: 23.7%\n",
            "[499] CPU Utilization: 48.0%\n",
            "[499] Memory Usage: 33.1%\n",
            "[499] Disk Usage: 24.0%\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 46.9%\n",
            "[499] Disk Usage: 24.0%\n",
            "Assigning 2 cores (total=2) for new task guillermo.\n",
            "Assigning 7404 MB (total=13021 MB) for new guillermo task.\n",
            "Running task guillermo on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='guillermo', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7404, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/0/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 50.1%\n",
            "[499] Memory Usage: 37.4%\n",
            "[499] Disk Usage: 24.5%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 44.8%\n",
            "[499] Disk Usage: 24.5%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.75742 | val_0_auc: 0.49795 | val_1_auc: 0.51587 |  0:00:05s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 45.5%\n",
            "[499] Disk Usage: 24.8%\n",
            "epoch 1  | loss: 0.68419 | val_0_auc: 0.50543 | val_1_auc: 0.48257 |  0:00:10s\n",
            "epoch 2  | loss: 0.6774  | val_0_auc: 0.50557 | val_1_auc: 0.49522 |  0:00:15s\n",
            "epoch 3  | loss: 0.67651 | val_0_auc: 0.51226 | val_1_auc: 0.52296 |  0:00:20s\n",
            "epoch 4  | loss: 0.67285 | val_0_auc: 0.53217 | val_1_auc: 0.52081 |  0:00:25s\n",
            "epoch 5  | loss: 0.66795 | val_0_auc: 0.54499 | val_1_auc: 0.53668 |  0:00:30s\n",
            "epoch 6  | loss: 0.6654  | val_0_auc: 0.53676 | val_1_auc: 0.51633 |  0:00:35s\n",
            "epoch 7  | loss: 0.66365 | val_0_auc: 0.53054 | val_1_auc: 0.51965 |  0:00:40s\n",
            "epoch 8  | loss: 0.66396 | val_0_auc: 0.53635 | val_1_auc: 0.51303 |  0:00:45s\n",
            "epoch 9  | loss: 0.6648  | val_0_auc: 0.54004 | val_1_auc: 0.49843 |  0:00:50s\n",
            "epoch 10 | loss: 0.66284 | val_0_auc: 0.53539 | val_1_auc: 0.51284 |  0:00:55s\n",
            "epoch 11 | loss: 0.66115 | val_0_auc: 0.51761 | val_1_auc: 0.49117 |  0:01:00s\n",
            "epoch 12 | loss: 0.66158 | val_0_auc: 0.55353 | val_1_auc: 0.53078 |  0:01:05s\n",
            "epoch 13 | loss: 0.66215 | val_0_auc: 0.55428 | val_1_auc: 0.53399 |  0:01:09s\n",
            "epoch 14 | loss: 0.66081 | val_0_auc: 0.54541 | val_1_auc: 0.53171 |  0:01:14s\n",
            "epoch 15 | loss: 0.66176 | val_0_auc: 0.55891 | val_1_auc: 0.55297 |  0:01:19s\n",
            "epoch 16 | loss: 0.66188 | val_0_auc: 0.54798 | val_1_auc: 0.53865 |  0:01:24s\n",
            "epoch 17 | loss: 0.66348 | val_0_auc: 0.54836 | val_1_auc: 0.56434 |  0:01:30s\n",
            "epoch 18 | loss: 0.66451 | val_0_auc: 0.573   | val_1_auc: 0.56885 |  0:01:35s\n",
            "epoch 19 | loss: 0.66147 | val_0_auc: 0.57128 | val_1_auc: 0.57203 |  0:01:40s\n",
            "epoch 20 | loss: 0.66189 | val_0_auc: 0.56918 | val_1_auc: 0.58856 |  0:01:45s\n",
            "epoch 21 | loss: 0.66247 | val_0_auc: 0.57009 | val_1_auc: 0.57113 |  0:01:50s\n",
            "epoch 22 | loss: 0.66196 | val_0_auc: 0.57143 | val_1_auc: 0.57742 |  0:01:55s\n",
            "epoch 23 | loss: 0.66145 | val_0_auc: 0.58068 | val_1_auc: 0.56936 |  0:02:00s\n",
            "epoch 24 | loss: 0.65954 | val_0_auc: 0.5841  | val_1_auc: 0.57705 |  0:02:05s\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 46.5%\n",
            "[499] Disk Usage: 24.8%\n",
            "epoch 25 | loss: 0.66096 | val_0_auc: 0.58255 | val_1_auc: 0.57645 |  0:02:09s\n",
            "epoch 26 | loss: 0.66022 | val_0_auc: 0.57918 | val_1_auc: 0.58596 |  0:02:14s\n",
            "epoch 27 | loss: 0.65996 | val_0_auc: 0.58651 | val_1_auc: 0.5856  |  0:02:19s\n",
            "epoch 28 | loss: 0.65994 | val_0_auc: 0.58468 | val_1_auc: 0.58508 |  0:02:24s\n",
            "epoch 29 | loss: 0.65945 | val_0_auc: 0.59102 | val_1_auc: 0.58669 |  0:02:29s\n",
            "epoch 30 | loss: 0.65975 | val_0_auc: 0.59278 | val_1_auc: 0.58764 |  0:02:34s\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_1_auc = 0.58856\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.593955  0.406045           0     0\n",
            "1   0.593959  0.406041           0     0\n",
            "2   0.429991  0.570009           1     0\n",
            "3   0.565252  0.434747           0     0\n",
            "4   0.597076  0.402924           0     0\n",
            "5   0.593034  0.406966           0     0\n",
            "6   0.581961  0.418038           0     0\n",
            "7   0.584399  0.415601           0     0\n",
            "8   0.589982  0.410018           0     0\n",
            "9   0.592017  0.407983           0     0\n",
            "10  0.591012  0.408988           0     0\n",
            "11  0.450472  0.549528           1     0\n",
            "12  0.591942  0.408058           0     0\n",
            "13  0.591346  0.408654           0     0\n",
            "14  0.566260  0.433740           0     0\n",
            "15  0.606312  0.393688           0     0\n",
            "16  0.602456  0.397544           0     0\n",
            "17  0.575419  0.424581           0     0\n",
            "18  0.598468  0.401532           0     0\n",
            "19  0.586754  0.413246           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.6025,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.5885619791666666,\n",
            "  'balacc': 0.505,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168337',\n",
            "  'info': None,\n",
            "  'logloss': 0.6601931944826838,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.21326565742492676,\n",
            "  'result': 0.5885619791666666,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'guillermo',\n",
            "  'training_duration': 158.42767143249512,\n",
            "  'utc': '2021-02-04T16:34:56',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.guillermo.0.TabNet executed in 796.128 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.guillermo.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task guillermo.\n",
            "Assigning 7347 MB (total=13021 MB) for new guillermo task.\n",
            "Running task guillermo on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='guillermo', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7347, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/1/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 47.5%\n",
            "[499] Memory Usage: 35.5%\n",
            "[499] Disk Usage: 24.8%\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 42.9%\n",
            "[499] Disk Usage: 24.8%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 41.8%\n",
            "[499] Disk Usage: 25.1%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.75485 | val_0_auc: 0.50615 | val_1_auc: 0.48708 |  0:00:05s\n",
            "epoch 1  | loss: 0.68356 | val_0_auc: 0.50242 | val_1_auc: 0.51297 |  0:00:10s\n",
            "epoch 2  | loss: 0.67712 | val_0_auc: 0.50328 | val_1_auc: 0.52098 |  0:00:15s\n",
            "epoch 3  | loss: 0.67475 | val_0_auc: 0.53012 | val_1_auc: 0.53172 |  0:00:20s\n",
            "epoch 4  | loss: 0.67023 | val_0_auc: 0.58964 | val_1_auc: 0.5753  |  0:00:25s\n",
            "epoch 5  | loss: 0.66221 | val_0_auc: 0.60047 | val_1_auc: 0.55943 |  0:00:29s\n",
            "epoch 6  | loss: 0.65838 | val_0_auc: 0.60669 | val_1_auc: 0.57786 |  0:00:34s\n",
            "epoch 7  | loss: 0.65423 | val_0_auc: 0.61134 | val_1_auc: 0.58603 |  0:00:39s\n",
            "epoch 8  | loss: 0.65293 | val_0_auc: 0.61562 | val_1_auc: 0.59445 |  0:00:44s\n",
            "epoch 9  | loss: 0.653   | val_0_auc: 0.61857 | val_1_auc: 0.58758 |  0:00:49s\n",
            "epoch 10 | loss: 0.65099 | val_0_auc: 0.62    | val_1_auc: 0.59652 |  0:00:54s\n",
            "epoch 11 | loss: 0.64809 | val_0_auc: 0.62316 | val_1_auc: 0.60396 |  0:00:59s\n",
            "epoch 12 | loss: 0.64709 | val_0_auc: 0.62632 | val_1_auc: 0.60448 |  0:01:04s\n",
            "epoch 13 | loss: 0.64512 | val_0_auc: 0.62824 | val_1_auc: 0.60454 |  0:01:09s\n",
            "epoch 14 | loss: 0.64321 | val_0_auc: 0.63322 | val_1_auc: 0.61323 |  0:01:14s\n",
            "epoch 15 | loss: 0.64107 | val_0_auc: 0.63737 | val_1_auc: 0.61956 |  0:01:19s\n",
            "epoch 16 | loss: 0.63944 | val_0_auc: 0.63825 | val_1_auc: 0.61674 |  0:01:24s\n",
            "epoch 17 | loss: 0.63982 | val_0_auc: 0.63934 | val_1_auc: 0.62363 |  0:01:29s\n",
            "epoch 18 | loss: 0.63879 | val_0_auc: 0.64027 | val_1_auc: 0.62129 |  0:01:34s\n",
            "epoch 19 | loss: 0.63741 | val_0_auc: 0.64507 | val_1_auc: 0.63154 |  0:01:39s\n",
            "epoch 20 | loss: 0.63521 | val_0_auc: 0.64709 | val_1_auc: 0.62834 |  0:01:44s\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 45.0%\n",
            "[499] Disk Usage: 25.1%\n",
            "epoch 21 | loss: 0.63278 | val_0_auc: 0.64901 | val_1_auc: 0.62926 |  0:01:49s\n",
            "epoch 22 | loss: 0.6313  | val_0_auc: 0.6507  | val_1_auc: 0.62766 |  0:01:54s\n",
            "epoch 23 | loss: 0.63076 | val_0_auc: 0.65596 | val_1_auc: 0.63743 |  0:01:59s\n",
            "epoch 24 | loss: 0.62771 | val_0_auc: 0.66386 | val_1_auc: 0.63916 |  0:02:04s\n",
            "epoch 25 | loss: 0.62523 | val_0_auc: 0.66503 | val_1_auc: 0.62864 |  0:02:09s\n",
            "epoch 26 | loss: 0.62242 | val_0_auc: 0.6735  | val_1_auc: 0.64955 |  0:02:14s\n",
            "epoch 27 | loss: 0.61648 | val_0_auc: 0.68273 | val_1_auc: 0.6558  |  0:02:19s\n",
            "epoch 28 | loss: 0.61071 | val_0_auc: 0.68985 | val_1_auc: 0.66126 |  0:02:24s\n",
            "epoch 29 | loss: 0.6057  | val_0_auc: 0.69501 | val_1_auc: 0.65951 |  0:02:29s\n",
            "epoch 30 | loss: 0.59803 | val_0_auc: 0.70659 | val_1_auc: 0.66727 |  0:02:34s\n",
            "epoch 31 | loss: 0.59188 | val_0_auc: 0.71682 | val_1_auc: 0.68206 |  0:02:39s\n",
            "epoch 32 | loss: 0.5844  | val_0_auc: 0.72464 | val_1_auc: 0.66998 |  0:02:44s\n",
            "epoch 33 | loss: 0.58031 | val_0_auc: 0.7286  | val_1_auc: 0.68016 |  0:02:49s\n",
            "epoch 34 | loss: 0.57714 | val_0_auc: 0.73676 | val_1_auc: 0.67741 |  0:02:54s\n",
            "epoch 35 | loss: 0.57404 | val_0_auc: 0.73867 | val_1_auc: 0.68581 |  0:02:58s\n",
            "epoch 36 | loss: 0.57032 | val_0_auc: 0.75365 | val_1_auc: 0.68905 |  0:03:03s\n",
            "epoch 37 | loss: 0.56243 | val_0_auc: 0.76279 | val_1_auc: 0.6917  |  0:03:08s\n",
            "epoch 38 | loss: 0.55349 | val_0_auc: 0.77411 | val_1_auc: 0.71018 |  0:03:13s\n",
            "epoch 39 | loss: 0.54703 | val_0_auc: 0.77763 | val_1_auc: 0.71733 |  0:03:18s\n",
            "epoch 40 | loss: 0.54113 | val_0_auc: 0.79009 | val_1_auc: 0.7243  |  0:03:23s\n",
            "epoch 41 | loss: 0.53439 | val_0_auc: 0.8036  | val_1_auc: 0.73177 |  0:03:28s\n",
            "epoch 42 | loss: 0.52223 | val_0_auc: 0.81887 | val_1_auc: 0.74637 |  0:03:33s\n",
            "epoch 43 | loss: 0.50617 | val_0_auc: 0.83464 | val_1_auc: 0.75067 |  0:03:38s\n",
            "epoch 44 | loss: 0.49136 | val_0_auc: 0.84995 | val_1_auc: 0.76384 |  0:03:43s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 44.9%\n",
            "[499] Disk Usage: 25.1%\n",
            "epoch 45 | loss: 0.48657 | val_0_auc: 0.84139 | val_1_auc: 0.76483 |  0:03:48s\n",
            "epoch 46 | loss: 0.47593 | val_0_auc: 0.86611 | val_1_auc: 0.77188 |  0:03:53s\n",
            "epoch 47 | loss: 0.45131 | val_0_auc: 0.8812  | val_1_auc: 0.78707 |  0:03:58s\n",
            "epoch 48 | loss: 0.43737 | val_0_auc: 0.88749 | val_1_auc: 0.80114 |  0:04:03s\n",
            "epoch 49 | loss: 0.42323 | val_0_auc: 0.89804 | val_1_auc: 0.80276 |  0:04:08s\n",
            "epoch 50 | loss: 0.40942 | val_0_auc: 0.91138 | val_1_auc: 0.81359 |  0:04:13s\n",
            "epoch 51 | loss: 0.39216 | val_0_auc: 0.91914 | val_1_auc: 0.81057 |  0:04:18s\n",
            "epoch 52 | loss: 0.37364 | val_0_auc: 0.92674 | val_1_auc: 0.81758 |  0:04:23s\n",
            "epoch 53 | loss: 0.35813 | val_0_auc: 0.93302 | val_1_auc: 0.81833 |  0:04:28s\n",
            "epoch 54 | loss: 0.34943 | val_0_auc: 0.94123 | val_1_auc: 0.81479 |  0:04:33s\n",
            "epoch 55 | loss: 0.3309  | val_0_auc: 0.94485 | val_1_auc: 0.82344 |  0:04:38s\n",
            "epoch 56 | loss: 0.32002 | val_0_auc: 0.94989 | val_1_auc: 0.8288  |  0:04:43s\n",
            "epoch 57 | loss: 0.30748 | val_0_auc: 0.95327 | val_1_auc: 0.8205  |  0:04:48s\n",
            "epoch 58 | loss: 0.30373 | val_0_auc: 0.95759 | val_1_auc: 0.82495 |  0:04:53s\n",
            "epoch 59 | loss: 0.28586 | val_0_auc: 0.96187 | val_1_auc: 0.8244  |  0:04:58s\n",
            "epoch 60 | loss: 0.27779 | val_0_auc: 0.96379 | val_1_auc: 0.82237 |  0:05:02s\n",
            "epoch 61 | loss: 0.27244 | val_0_auc: 0.96735 | val_1_auc: 0.83377 |  0:05:07s\n",
            "epoch 62 | loss: 0.264   | val_0_auc: 0.96959 | val_1_auc: 0.82926 |  0:05:12s\n",
            "epoch 63 | loss: 0.25246 | val_0_auc: 0.96854 | val_1_auc: 0.82877 |  0:05:17s\n",
            "epoch 64 | loss: 0.25253 | val_0_auc: 0.97099 | val_1_auc: 0.83077 |  0:05:22s\n",
            "epoch 65 | loss: 0.2433  | val_0_auc: 0.97504 | val_1_auc: 0.83065 |  0:05:27s\n",
            "epoch 66 | loss: 0.23151 | val_0_auc: 0.97751 | val_1_auc: 0.831   |  0:05:32s\n",
            "epoch 67 | loss: 0.22544 | val_0_auc: 0.97811 | val_1_auc: 0.82745 |  0:05:37s\n",
            "epoch 68 | loss: 0.22105 | val_0_auc: 0.97925 | val_1_auc: 0.8275  |  0:05:42s\n",
            "epoch 69 | loss: 0.21229 | val_0_auc: 0.98017 | val_1_auc: 0.83446 |  0:05:47s\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 44.9%\n",
            "[499] Disk Usage: 25.1%\n",
            "epoch 70 | loss: 0.2051  | val_0_auc: 0.98453 | val_1_auc: 0.83142 |  0:05:52s\n",
            "epoch 71 | loss: 0.20497 | val_0_auc: 0.98347 | val_1_auc: 0.82701 |  0:05:57s\n",
            "epoch 72 | loss: 0.20989 | val_0_auc: 0.98243 | val_1_auc: 0.82783 |  0:06:02s\n",
            "epoch 73 | loss: 0.19398 | val_0_auc: 0.98439 | val_1_auc: 0.82739 |  0:06:07s\n",
            "epoch 74 | loss: 0.18602 | val_0_auc: 0.98684 | val_1_auc: 0.82634 |  0:06:12s\n",
            "epoch 75 | loss: 0.17397 | val_0_auc: 0.98759 | val_1_auc: 0.82193 |  0:06:17s\n",
            "epoch 76 | loss: 0.17387 | val_0_auc: 0.98767 | val_1_auc: 0.82901 |  0:06:22s\n",
            "epoch 77 | loss: 0.16558 | val_0_auc: 0.98967 | val_1_auc: 0.82618 |  0:06:27s\n",
            "epoch 78 | loss: 0.16122 | val_0_auc: 0.98912 | val_1_auc: 0.82305 |  0:06:32s\n",
            "epoch 79 | loss: 0.16213 | val_0_auc: 0.99066 | val_1_auc: 0.83003 |  0:06:37s\n",
            "\n",
            "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_1_auc = 0.83446\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.993316  0.006684           0     0\n",
            "1   0.705368  0.294632           0     0\n",
            "2   0.993988  0.006012           0     0\n",
            "3   0.991446  0.008554           0     0\n",
            "4   0.899792  0.100208           0     0\n",
            "5   0.960088  0.039912           0     0\n",
            "6   0.717498  0.282502           0     0\n",
            "7   0.984040  0.015960           0     0\n",
            "8   0.869319  0.130681           0     0\n",
            "9   0.336235  0.663765           1     0\n",
            "10  0.994125  0.005874           0     0\n",
            "11  0.995949  0.004051           0     0\n",
            "12  0.807880  0.192120           0     0\n",
            "13  0.998869  0.001131           0     0\n",
            "14  0.399680  0.600320           1     0\n",
            "15  0.978371  0.021629           0     0\n",
            "16  0.171817  0.828183           1     0\n",
            "17  0.989825  0.010175           0     0\n",
            "18  0.393730  0.606270           1     0\n",
            "19  0.427544  0.572456           1     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/guillermo/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.761,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.8344624999999999,\n",
            "  'balacc': 0.7562500000000001,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168337',\n",
            "  'info': None,\n",
            "  'logloss': 0.6479387695006594,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.1595160961151123,\n",
            "  'result': 0.8344624999999999,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'guillermo',\n",
            "  'training_duration': 400.2812376022339,\n",
            "  'utc': '2021-02-04T16:47:28',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.guillermo.1.TabNet executed in 751.648 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Helena.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Helena.\n",
            "Assigning 7333 MB (total=13021 MB) for new Helena task.\n",
            "Running task Helena on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Helena', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7333, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 4.27414 | val_0_accuracy: 0.09268 | val_1_accuracy: 0.09034 |  0:00:03s\n",
            "epoch 1  | loss: 3.48707 | val_0_accuracy: 0.18273 | val_1_accuracy: 0.1816  |  0:00:07s\n",
            "epoch 2  | loss: 3.32459 | val_0_accuracy: 0.22861 | val_1_accuracy: 0.23113 |  0:00:11s\n",
            "epoch 3  | loss: 3.22614 | val_0_accuracy: 0.25205 | val_1_accuracy: 0.24954 |  0:00:15s\n",
            "epoch 4  | loss: 3.17145 | val_0_accuracy: 0.26546 | val_1_accuracy: 0.2638  |  0:00:19s\n",
            "epoch 5  | loss: 3.12407 | val_0_accuracy: 0.2736  | val_1_accuracy: 0.27699 |  0:00:23s\n",
            "epoch 6  | loss: 3.09948 | val_0_accuracy: 0.27113 | val_1_accuracy: 0.27224 |  0:00:27s\n",
            "epoch 7  | loss: 3.07919 | val_0_accuracy: 0.28071 | val_1_accuracy: 0.28344 |  0:00:31s\n",
            "epoch 8  | loss: 3.05804 | val_0_accuracy: 0.284   | val_1_accuracy: 0.28574 |  0:00:35s\n",
            "epoch 9  | loss: 3.04422 | val_0_accuracy: 0.28618 | val_1_accuracy: 0.28451 |  0:00:39s\n",
            "[499] CPU Utilization: 46.0%\n",
            "[499] Memory Usage: 28.0%\n",
            "[499] Disk Usage: 25.2%\n",
            "epoch 10 | loss: 3.02952 | val_0_accuracy: 0.28865 | val_1_accuracy: 0.29294 |  0:00:42s\n",
            "epoch 11 | loss: 3.01757 | val_0_accuracy: 0.28674 | val_1_accuracy: 0.28742 |  0:00:46s\n",
            "epoch 12 | loss: 3.00637 | val_0_accuracy: 0.28961 | val_1_accuracy: 0.29034 |  0:00:50s\n",
            "epoch 13 | loss: 3.0057  | val_0_accuracy: 0.28453 | val_1_accuracy: 0.28298 |  0:00:54s\n",
            "epoch 14 | loss: 3.01218 | val_0_accuracy: 0.29584 | val_1_accuracy: 0.2977  |  0:00:58s\n",
            "epoch 15 | loss: 2.9873  | val_0_accuracy: 0.2974  | val_1_accuracy: 0.30169 |  0:01:01s\n",
            "epoch 16 | loss: 2.9731  | val_0_accuracy: 0.29804 | val_1_accuracy: 0.29969 |  0:01:05s\n",
            "epoch 17 | loss: 2.96382 | val_0_accuracy: 0.29823 | val_1_accuracy: 0.29571 |  0:01:09s\n",
            "epoch 18 | loss: 2.95643 | val_0_accuracy: 0.30116 | val_1_accuracy: 0.3023  |  0:01:13s\n",
            "epoch 19 | loss: 2.95539 | val_0_accuracy: 0.30159 | val_1_accuracy: 0.3     |  0:01:16s\n",
            "epoch 20 | loss: 2.9435  | val_0_accuracy: 0.30234 | val_1_accuracy: 0.30521 |  0:01:20s\n",
            "epoch 21 | loss: 2.93963 | val_0_accuracy: 0.30196 | val_1_accuracy: 0.29893 |  0:01:24s\n",
            "epoch 22 | loss: 2.9345  | val_0_accuracy: 0.29968 | val_1_accuracy: 0.29739 |  0:01:28s\n",
            "epoch 23 | loss: 2.92571 | val_0_accuracy: 0.30933 | val_1_accuracy: 0.31074 |  0:01:31s\n",
            "epoch 24 | loss: 2.91829 | val_0_accuracy: 0.30629 | val_1_accuracy: 0.30414 |  0:01:35s\n",
            "epoch 25 | loss: 2.91383 | val_0_accuracy: 0.31374 | val_1_accuracy: 0.31258 |  0:01:39s\n",
            "epoch 26 | loss: 2.90432 | val_0_accuracy: 0.30721 | val_1_accuracy: 0.30491 |  0:01:43s\n",
            "epoch 27 | loss: 2.89985 | val_0_accuracy: 0.3112  | val_1_accuracy: 0.31089 |  0:01:47s\n",
            "epoch 28 | loss: 2.90159 | val_0_accuracy: 0.30639 | val_1_accuracy: 0.30629 |  0:01:50s\n",
            "epoch 29 | loss: 2.88579 | val_0_accuracy: 0.30861 | val_1_accuracy: 0.30092 |  0:01:54s\n",
            "epoch 30 | loss: 2.88203 | val_0_accuracy: 0.31594 | val_1_accuracy: 0.31227 |  0:01:58s\n",
            "epoch 31 | loss: 2.87675 | val_0_accuracy: 0.31423 | val_1_accuracy: 0.30874 |  0:02:02s\n",
            "epoch 32 | loss: 2.8747  | val_0_accuracy: 0.31948 | val_1_accuracy: 0.31917 |  0:02:06s\n",
            "epoch 33 | loss: 2.86658 | val_0_accuracy: 0.3151  | val_1_accuracy: 0.3112  |  0:02:09s\n",
            "epoch 34 | loss: 2.86752 | val_0_accuracy: 0.32138 | val_1_accuracy: 0.31933 |  0:02:13s\n",
            "epoch 35 | loss: 2.85984 | val_0_accuracy: 0.3203  | val_1_accuracy: 0.31595 |  0:02:17s\n",
            "epoch 36 | loss: 2.85389 | val_0_accuracy: 0.30888 | val_1_accuracy: 0.30982 |  0:02:21s\n",
            "epoch 37 | loss: 2.85056 | val_0_accuracy: 0.31996 | val_1_accuracy: 0.32009 |  0:02:24s\n",
            "epoch 38 | loss: 2.84703 | val_0_accuracy: 0.3197  | val_1_accuracy: 0.31718 |  0:02:28s\n",
            "epoch 39 | loss: 2.84294 | val_0_accuracy: 0.32349 | val_1_accuracy: 0.32301 |  0:02:32s\n",
            "epoch 40 | loss: 2.84461 | val_0_accuracy: 0.32347 | val_1_accuracy: 0.32086 |  0:02:36s\n",
            "epoch 41 | loss: 2.84202 | val_0_accuracy: 0.32473 | val_1_accuracy: 0.31902 |  0:02:40s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 28.0%\n",
            "[499] Disk Usage: 25.2%\n",
            "epoch 42 | loss: 2.83438 | val_0_accuracy: 0.31766 | val_1_accuracy: 0.31396 |  0:02:44s\n",
            "epoch 43 | loss: 2.83615 | val_0_accuracy: 0.31793 | val_1_accuracy: 0.31396 |  0:02:47s\n",
            "epoch 44 | loss: 2.83365 | val_0_accuracy: 0.32259 | val_1_accuracy: 0.3204  |  0:02:51s\n",
            "epoch 45 | loss: 2.82915 | val_0_accuracy: 0.3238  | val_1_accuracy: 0.32163 |  0:02:55s\n",
            "epoch 46 | loss: 2.82704 | val_0_accuracy: 0.32633 | val_1_accuracy: 0.32577 |  0:02:59s\n",
            "epoch 47 | loss: 2.82296 | val_0_accuracy: 0.32741 | val_1_accuracy: 0.32653 |  0:03:02s\n",
            "epoch 48 | loss: 2.82033 | val_0_accuracy: 0.31636 | val_1_accuracy: 0.31595 |  0:03:06s\n",
            "epoch 49 | loss: 2.82095 | val_0_accuracy: 0.32548 | val_1_accuracy: 0.31887 |  0:03:10s\n",
            "epoch 50 | loss: 2.81968 | val_0_accuracy: 0.31897 | val_1_accuracy: 0.31518 |  0:03:14s\n",
            "epoch 51 | loss: 2.81954 | val_0_accuracy: 0.32575 | val_1_accuracy: 0.31963 |  0:03:18s\n",
            "epoch 52 | loss: 2.81423 | val_0_accuracy: 0.32775 | val_1_accuracy: 0.32331 |  0:03:22s\n",
            "epoch 53 | loss: 2.81563 | val_0_accuracy: 0.33034 | val_1_accuracy: 0.32393 |  0:03:25s\n",
            "epoch 54 | loss: 2.81178 | val_0_accuracy: 0.32688 | val_1_accuracy: 0.32009 |  0:03:29s\n",
            "epoch 55 | loss: 2.81079 | val_0_accuracy: 0.32962 | val_1_accuracy: 0.32454 |  0:03:33s\n",
            "epoch 56 | loss: 2.81274 | val_0_accuracy: 0.33007 | val_1_accuracy: 0.32531 |  0:03:37s\n",
            "epoch 57 | loss: 2.81146 | val_0_accuracy: 0.32644 | val_1_accuracy: 0.32239 |  0:03:40s\n",
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_1_accuracy = 0.32653\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0             1        10        11        12        13        14        15        16        17        18        19             2        20        21        22        23        24        25        26        27        28        29         3        30        31            32        33        34        35        36        37        38        39         4        40        41        42        43        44        45        46        47        48        49         5        50        51        52        53        54        55        56        57        58        59         6        60        61        62        63        64        65        66        67        68        69         7        70        71        72            73            74        75        76        77        78        79         8            80        81        82        83        84        85        86        87        88        89         9        90        91        92        93        94            95        96        97        98        99 predictions truth\n",
            "0   0.014681  2.156397e-02  0.000991  0.013135  0.010204  0.009961  0.004113  0.004293  0.011763  0.000900  0.001117  0.003854  4.764781e-03  0.053400  0.000791  0.012084  0.004785  0.005582  0.027002  0.001409  0.006371  0.005330  0.002971  0.020102  0.001640  0.000702  6.767193e-03  0.007212  0.002330  0.004600  0.006277  0.008437  0.005379  0.003858  0.009679  0.239697  0.000954  0.003121  0.013788  0.003382  0.000066  0.001299  0.008803  0.019911  0.006473  0.002723  0.004454  0.000414  0.005583  0.000443  0.001600  0.092832  0.001050  0.003947  0.003853  0.000843  0.014276  0.005281  0.003217  0.002670  0.028411  0.016869  0.002464  0.011557  0.001067  0.000853  0.012562  0.004436  0.002138  0.000466  0.000180  1.651199e-05  2.295249e-03  0.006889  0.005430  0.000152  0.004055  0.000203  0.001949  7.788821e-06  0.000171  0.000091  0.001705  0.000993  0.002856  0.016080  0.010114  0.006846  0.000743  0.040987  0.003900  0.005923  0.005214  0.001777  0.000657  6.626105e-05  0.009858  0.040837  0.001818  0.008635          40    66\n",
            "1   0.001557  1.609260e-04  0.000179  0.006853  0.000459  0.000292  0.000436  0.002969  0.002871  0.000942  0.001083  0.004337  1.727429e-05  0.000918  0.005310  0.007011  0.006193  0.005834  0.013861  0.000005  0.019321  0.001802  0.001194  0.005621  0.001308  0.000297  3.890661e-03  0.008642  0.000036  0.005746  0.004454  0.003214  0.013717  0.000447  0.001277  0.012837  0.000002  0.001359  0.008884  0.000019  0.000091  0.009383  0.000337  0.017946  0.003526  0.018450  0.002071  0.007955  0.007000  0.029460  0.000012  0.002077  0.000045  0.004520  0.010091  0.012331  0.022075  0.042005  0.002828  0.004920  0.000578  0.038814  0.002580  0.060556  0.010177  0.000204  0.003853  0.009224  0.019278  0.000242  0.000089  4.807829e-06  2.137026e-05  0.001312  0.001917  0.002698  0.068537  0.000672  0.000436  1.819039e-03  0.001499  0.000005  0.001367  0.000009  0.001342  0.006963  0.021717  0.107724  0.000169  0.003245  0.009075  0.134350  0.046137  0.023502  0.003332  5.915180e-06  0.057135  0.000539  0.002678  0.003720          91    66\n",
            "2   0.001441  3.846336e-04  0.000095  0.015251  0.002511  0.001620  0.000410  0.000595  0.007252  0.002534  0.004024  0.003543  8.530316e-05  0.002832  0.016503  0.014000  0.020339  0.005640  0.026826  0.000223  0.008321  0.022110  0.003835  0.004608  0.003658  0.001512  1.188836e-02  0.006261  0.000102  0.009176  0.010425  0.014572  0.007044  0.000816  0.011540  0.010798  0.000088  0.002414  0.018820  0.000498  0.000120  0.002436  0.000684  0.011045  0.003070  0.009007  0.007603  0.003393  0.025742  0.024933  0.000038  0.007208  0.000118  0.001678  0.013309  0.004619  0.015683  0.075768  0.003634  0.015752  0.003813  0.025562  0.007891  0.062463  0.004291  0.000468  0.002778  0.005997  0.020617  0.000075  0.000312  2.782726e-05  5.874301e-05  0.001137  0.003901  0.008700  0.074522  0.005216  0.000926  5.653475e-03  0.002101  0.000076  0.001645  0.000047  0.002512  0.013858  0.012776  0.016647  0.000604  0.004330  0.014639  0.020309  0.056003  0.011101  0.000913  4.228313e-05  0.090789  0.003126  0.005905  0.007736          96    66\n",
            "3   0.030971  4.736684e-03  0.001265  0.008475  0.001296  0.002054  0.002037  0.016860  0.006771  0.000050  0.000244  0.003309  4.127103e-04  0.015965  0.000306  0.051428  0.002237  0.004040  0.018110  0.000397  0.020175  0.001302  0.001399  0.042741  0.000962  0.000543  8.173754e-03  0.033756  0.000391  0.007203  0.006927  0.006809  0.002177  0.000626  0.004368  0.340224  0.000128  0.002112  0.006305  0.001033  0.000050  0.000587  0.002221  0.028658  0.003870  0.002236  0.003493  0.001152  0.001527  0.000996  0.000222  0.005830  0.000109  0.001085  0.005444  0.002478  0.011973  0.012841  0.000490  0.003266  0.002663  0.019905  0.001419  0.026019  0.002037  0.000384  0.005185  0.002972  0.001737  0.000683  0.000039  2.113312e-06  2.760695e-04  0.021788  0.003089  0.000018  0.002645  0.000013  0.000246  1.895680e-06  0.000220  0.000024  0.001511  0.000040  0.001900  0.020111  0.003894  0.007327  0.000058  0.081326  0.003894  0.009225  0.002211  0.003661  0.006571  4.530921e-06  0.008563  0.002797  0.000789  0.007901          40    66\n",
            "4   0.029883  4.455881e-07  0.000082  0.002830  0.001849  0.000847  0.000174  0.000266  0.013892  0.000032  0.001196  0.001183  2.420548e-08  0.000077  0.012569  0.017670  0.005701  0.000603  0.004319  0.001214  0.000807  0.000208  0.001952  0.000032  0.004238  0.011974  4.734713e-03  0.000265  0.000001  0.007104  0.001130  0.003308  0.004852  0.005186  0.000404  0.000314  0.000411  0.001880  0.002607  0.000032  0.000028  0.000685  0.000032  0.000961  0.000761  0.000274  0.001371  0.000174  0.004122  0.001605  0.000055  0.000618  0.000006  0.000430  0.004329  0.000185  0.000593  0.014074  0.000006  0.012915  0.000030  0.001334  0.000801  0.010458  0.000734  0.000356  0.011959  0.000602  0.039697  0.006485  0.000622  2.277269e-04  9.332284e-07  0.000004  0.000376  0.000651  0.000694  0.000058  0.000123  1.394251e-02  0.240246  0.000002  0.000231  0.000002  0.000122  0.016748  0.000045  0.000449  0.000244  0.000002  0.001413  0.007789  0.385633  0.002646  0.000204  2.981873e-07  0.002191  0.000801  0.039661  0.023365          92    66\n",
            "5   0.001862  6.016755e-04  0.001436  0.011892  0.003115  0.001935  0.006636  0.002970  0.006146  0.004885  0.006527  0.006935  1.432674e-03  0.006270  0.024164  0.005223  0.039193  0.024836  0.016826  0.003755  0.010478  0.003149  0.002407  0.004323  0.001440  0.000451  1.184423e-03  0.000556  0.000856  0.001524  0.006360  0.009104  0.001374  0.002464  0.003884  0.017206  0.000330  0.004298  0.027582  0.004324  0.000177  0.004438  0.001015  0.055639  0.009360  0.015820  0.005694  0.001484  0.010646  0.000603  0.000343  0.017187  0.002140  0.005479  0.013559  0.004319  0.117024  0.021657  0.006336  0.004386  0.005455  0.009645  0.005128  0.036612  0.004004  0.000503  0.028007  0.003281  0.017488  0.000529  0.000273  3.032694e-05  1.376527e-03  0.002108  0.003865  0.001591  0.007330  0.002333  0.002659  9.202967e-04  0.000273  0.000170  0.002636  0.001473  0.002702  0.005877  0.022067  0.024502  0.003296  0.015002  0.007164  0.013351  0.045713  0.005108  0.000460  2.373380e-03  0.114570  0.007648  0.006586  0.008652           6    66\n",
            "6   0.005590  8.677296e-04  0.003919  0.002052  0.001453  0.000401  0.008804  0.014667  0.005704  0.023076  0.001783  0.004130  9.265231e-04  0.001617  0.001882  0.000286  0.003977  0.006216  0.004569  0.001496  0.005222  0.000016  0.011304  0.001256  0.007353  0.001396  1.825965e-05  0.000046  0.002635  0.000081  0.000818  0.000831  0.007202  0.147105  0.000189  0.004594  0.000701  0.002267  0.004491  0.000613  0.013919  0.025503  0.000800  0.009937  0.003509  0.002778  0.000917  0.005899  0.001190  0.000007  0.001802  0.010847  0.006712  0.071373  0.002278  0.016792  0.015251  0.000216  0.001375  0.000929  0.001517  0.000849  0.000929  0.002027  0.024093  0.010274  0.236855  0.002705  0.006358  0.015075  0.022606  2.051011e-02  6.762843e-03  0.000441  0.009811  0.002794  0.000688  0.001812  0.002483  2.785916e-05  0.001297  0.003666  0.005185  0.005931  0.011654  0.002492  0.002056  0.009920  0.003734  0.000791  0.000849  0.008781  0.051297  0.012827  0.001864  1.000802e-02  0.003791  0.004554  0.004957  0.002144          69    66\n",
            "7   0.009569  5.241020e-04  0.001887  0.008950  0.008713  0.005931  0.006016  0.012083  0.017140  0.003257  0.002211  0.007800  4.114687e-04  0.008736  0.013389  0.014565  0.019104  0.017727  0.027233  0.008070  0.010989  0.004186  0.002384  0.008408  0.001711  0.000530  4.866370e-03  0.001900  0.000310  0.002957  0.010194  0.009459  0.001813  0.002268  0.003640  0.048439  0.000487  0.005433  0.030811  0.002866  0.000157  0.005255  0.000553  0.060480  0.006750  0.005427  0.006054  0.004204  0.005128  0.000718  0.000164  0.011238  0.000585  0.008861  0.012632  0.013804  0.072157  0.027116  0.000983  0.013002  0.002482  0.005971  0.003694  0.069443  0.007201  0.000661  0.021391  0.001467  0.023602  0.000905  0.000360  7.322471e-05  4.865132e-04  0.005506  0.003350  0.002128  0.022502  0.000511  0.000629  1.598337e-03  0.004821  0.000514  0.001607  0.000351  0.002121  0.010880  0.005400  0.012062  0.000413  0.011132  0.013094  0.010756  0.053687  0.012783  0.001737  4.323867e-04  0.062403  0.006317  0.005851  0.007441           6    66\n",
            "8   0.003405  3.813101e-04  0.000113  0.027426  0.009549  0.008426  0.000675  0.000052  0.009003  0.000385  0.015604  0.002434  1.299743e-04  0.005245  0.024575  0.023341  0.031689  0.003005  0.015603  0.002473  0.001527  0.053628  0.003414  0.000632  0.003541  0.008502  3.903443e-02  0.002803  0.000276  0.032348  0.006269  0.027578  0.006081  0.002116  0.031112  0.003690  0.003346  0.004059  0.013235  0.002956  0.000020  0.000382  0.004127  0.002948  0.004900  0.004028  0.010051  0.000050  0.074390  0.022386  0.001531  0.039072  0.000414  0.000278  0.008847  0.000037  0.003575  0.052253  0.003647  0.008158  0.014407  0.027751  0.009001  0.012506  0.000167  0.000393  0.003819  0.007235  0.010962  0.000281  0.000214  1.911739e-05  1.456218e-04  0.000097  0.001975  0.001070  0.002966  0.003766  0.006926  6.065113e-03  0.000819  0.000007  0.001101  0.000349  0.000679  0.022085  0.007223  0.002476  0.011760  0.000738  0.004746  0.006368  0.037177  0.000486  0.000045  2.603937e-05  0.020933  0.033665  0.022215  0.046584          52    66\n",
            "9   0.001756  1.990291e-03  0.000740  0.007071  0.000387  0.000269  0.001412  0.003001  0.001433  0.001257  0.001975  0.005005  3.057166e-04  0.001834  0.001642  0.001995  0.003162  0.005253  0.006340  0.000002  0.016465  0.000535  0.001743  0.005094  0.001691  0.000533  1.204065e-03  0.006642  0.000678  0.004286  0.001832  0.001612  0.044198  0.002539  0.000922  0.011012  0.000004  0.001496  0.004029  0.000024  0.000360  0.016388  0.004152  0.009780  0.007620  0.033069  0.001269  0.002432  0.007108  0.014448  0.000439  0.008437  0.000619  0.009134  0.005018  0.002476  0.011917  0.005739  0.021363  0.000780  0.002565  0.064749  0.002132  0.007918  0.005398  0.000628  0.010043  0.040685  0.005479  0.001720  0.000235  1.521381e-05  4.216548e-04  0.000971  0.003262  0.000828  0.007225  0.001121  0.004894  1.698512e-04  0.000156  0.000002  0.003619  0.000201  0.002499  0.004600  0.069918  0.193498  0.002548  0.004135  0.002593  0.195779  0.013167  0.006867  0.002416  3.124995e-05  0.012285  0.001987  0.002588  0.004731          91    66\n",
            "10  0.006755  5.969251e-03  0.000266  0.019201  0.014308  0.013074  0.001920  0.000898  0.016268  0.001002  0.002150  0.002636  2.464576e-03  0.044413  0.003140  0.022159  0.015639  0.005712  0.040050  0.012106  0.003834  0.024726  0.003803  0.011052  0.001977  0.001074  1.085028e-02  0.003386  0.000915  0.004697  0.010997  0.023679  0.001422  0.001887  0.030248  0.125017  0.003917  0.003233  0.025131  0.016785  0.000030  0.000344  0.003244  0.018142  0.003919  0.001725  0.009690  0.000250  0.012375  0.000442  0.000489  0.076012  0.000555  0.001000  0.006077  0.000573  0.017273  0.017655  0.001818  0.007531  0.033878  0.010415  0.004680  0.024105  0.000614  0.000530  0.006709  0.001803  0.003545  0.000072  0.000148  1.217203e-05  8.779285e-04  0.003781  0.005083  0.000325  0.006187  0.000580  0.001136  3.316562e-05  0.000197  0.000243  0.001148  0.000585  0.002472  0.020687  0.005354  0.001981  0.000668  0.035161  0.006287  0.001700  0.010045  0.001318  0.000196  1.090858e-04  0.031177  0.043747  0.002814  0.011692          40    66\n",
            "11  0.000631  9.029960e-06  0.000061  0.008285  0.006378  0.002322  0.000721  0.000040  0.006551  0.002355  0.014187  0.001873  1.590171e-05  0.000817  0.118076  0.002521  0.061745  0.005088  0.008956  0.004924  0.000637  0.006895  0.001452  0.000074  0.001317  0.001043  2.030157e-03  0.000042  0.000035  0.001909  0.002247  0.008233  0.001227  0.002392  0.003075  0.000562  0.000658  0.002338  0.018749  0.001020  0.000012  0.001039  0.000172  0.004969  0.002708  0.003059  0.003431  0.000066  0.032153  0.000930  0.000124  0.017043  0.000291  0.000882  0.006771  0.000119  0.014245  0.025462  0.000993  0.005844  0.001908  0.003015  0.003636  0.015586  0.000313  0.000134  0.012516  0.001017  0.037234  0.000143  0.000215  3.063408e-05  4.621354e-05  0.000012  0.000730  0.005400  0.003704  0.005486  0.001991  4.773320e-02  0.001562  0.000010  0.000366  0.000250  0.000264  0.004531  0.002905  0.002456  0.006721  0.000074  0.003302  0.004330  0.300031  0.000812  0.000007  1.705947e-04  0.056920  0.011588  0.027933  0.013116          92    66\n",
            "12  0.034055  5.856089e-03  0.006176  0.004126  0.001590  0.001563  0.008892  0.083332  0.009626  0.000534  0.000270  0.004081  2.555846e-03  0.015545  0.000360  0.012255  0.002778  0.007501  0.013663  0.009584  0.020279  0.000157  0.004002  0.038536  0.002019  0.000603  4.532126e-04  0.002563  0.001842  0.000559  0.004944  0.004047  0.000745  0.004966  0.001577  0.240534  0.001226  0.002767  0.007106  0.007167  0.000994  0.001462  0.001105  0.048980  0.003385  0.001295  0.002995  0.005116  0.000502  0.000017  0.000490  0.005094  0.000875  0.005790  0.004359  0.021158  0.028070  0.002081  0.000289  0.002859  0.002239  0.002291  0.001090  0.014187  0.010309  0.002239  0.031869  0.000977  0.001861  0.002462  0.000582  1.359025e-04  3.122030e-03  0.037760  0.007853  0.000050  0.001060  0.000032  0.000234  6.958351e-07  0.000365  0.002921  0.003238  0.000528  0.007986  0.009911  0.001340  0.003551  0.000093  0.096912  0.002563  0.002563  0.003397  0.008826  0.013095  4.836631e-04  0.007287  0.002844  0.000828  0.003562          40    66\n",
            "13  0.006830  2.006184e-02  0.006786  0.003022  0.004227  0.002177  0.013670  0.053569  0.005885  0.022200  0.000819  0.006938  1.146742e-02  0.014236  0.000663  0.000739  0.001928  0.010043  0.009914  0.000307  0.010824  0.000236  0.003603  0.017780  0.002058  0.000240  2.799967e-04  0.001274  0.006419  0.000408  0.002238  0.001065  0.012156  0.019131  0.000608  0.074336  0.000142  0.002627  0.007952  0.000521  0.002853  0.037189  0.003858  0.027644  0.007187  0.006318  0.001222  0.010503  0.001186  0.000083  0.001583  0.030598  0.005980  0.114755  0.002355  0.029811  0.030616  0.000583  0.006411  0.001045  0.006525  0.004403  0.001159  0.005159  0.019191  0.003798  0.051405  0.004853  0.003376  0.004292  0.002526  1.115344e-03  1.273098e-02  0.010869  0.008086  0.001955  0.007954  0.000714  0.002417  2.625306e-05  0.000711  0.001785  0.003956  0.005457  0.008445  0.002962  0.013917  0.039888  0.000976  0.017691  0.002815  0.018480  0.008911  0.014537  0.005094  2.899676e-03  0.005846  0.009283  0.001288  0.001344          57    66\n",
            "14  0.035692  2.522934e-05  0.000394  0.010003  0.005249  0.004468  0.001525  0.003796  0.024275  0.000060  0.000762  0.003798  4.453026e-06  0.003591  0.009393  0.087814  0.016969  0.006736  0.029789  0.006570  0.006648  0.002397  0.000947  0.002507  0.000858  0.000649  1.531891e-02  0.002207  0.000012  0.008365  0.008162  0.013572  0.000857  0.000707  0.002911  0.050369  0.000241  0.003701  0.022056  0.000850  0.000005  0.000587  0.000127  0.040446  0.003468  0.001323  0.004910  0.000387  0.004170  0.000714  0.000033  0.004809  0.000023  0.000854  0.012964  0.001264  0.027567  0.078683  0.000048  0.018059  0.000452  0.006367  0.001742  0.119589  0.001179  0.000106  0.014702  0.000568  0.026024  0.000631  0.000029  1.889277e-06  1.293817e-05  0.000827  0.000891  0.000106  0.005228  0.000017  0.000099  4.183351e-04  0.006715  0.000006  0.000371  0.000008  0.000302  0.028311  0.000818  0.002888  0.000062  0.002007  0.007868  0.008416  0.089823  0.004128  0.000507  1.944133e-06  0.040492  0.003415  0.007824  0.022361          66    66\n",
            "15  0.000303  8.996575e-05  0.000026  0.012519  0.000886  0.000699  0.000282  0.000136  0.002809  0.000341  0.001893  0.001416  7.535603e-05  0.003085  0.015395  0.013427  0.037183  0.006918  0.021184  0.000621  0.004623  0.019385  0.000621  0.002975  0.000353  0.000115  3.818829e-03  0.000959  0.000028  0.002281  0.007319  0.016031  0.000234  0.000067  0.010748  0.016951  0.000033  0.000996  0.023205  0.001720  0.000003  0.000184  0.000153  0.025813  0.001840  0.005184  0.005481  0.000233  0.014295  0.001916  0.000005  0.005917  0.000041  0.000169  0.010481  0.000679  0.052929  0.119342  0.001530  0.005821  0.003094  0.013089  0.003905  0.089188  0.000500  0.000026  0.001511  0.000950  0.008244  0.000004  0.000007  1.196199e-07  2.275962e-05  0.000834  0.001068  0.000358  0.015956  0.000662  0.000221  2.998002e-04  0.000034  0.000007  0.000384  0.000017  0.000532  0.006230  0.010917  0.006219  0.000173  0.017911  0.007378  0.003780  0.021719  0.001464  0.000057  2.256769e-05  0.290180  0.002160  0.001690  0.005421          96    66\n",
            "16  0.000827  2.735442e-03  0.000042  0.004660  0.000017  0.000005  0.000175  0.000571  0.001460  0.002342  0.000645  0.000473  4.899091e-04  0.000687  0.000120  0.000394  0.003388  0.000841  0.006017  0.000101  0.011679  0.000003  0.137313  0.002994  0.056222  0.010355  7.712893e-07  0.000051  0.002117  0.000015  0.000670  0.002370  0.003420  0.122257  0.001068  0.005266  0.000496  0.000297  0.001224  0.001333  0.053161  0.000411  0.000675  0.001879  0.000354  0.000942  0.001492  0.003592  0.001919  0.000001  0.000127  0.003417  0.000670  0.001270  0.001782  0.007344  0.002529  0.000126  0.001324  0.000442  0.004553  0.001667  0.001323  0.000930  0.022096  0.022435  0.059242  0.006682  0.000466  0.000132  0.029186  3.219941e-03  1.689972e-03  0.000246  0.092153  0.000173  0.000066  0.004478  0.000665  1.471811e-09  0.000002  0.004581  0.016475  0.000292  0.208268  0.006816  0.001078  0.001890  0.000990  0.008222  0.000171  0.001498  0.009574  0.008280  0.002266  1.014649e-03  0.005092  0.000803  0.000764  0.001920          85    66\n",
            "17  0.024410  5.491932e-04  0.002045  0.017530  0.003764  0.002170  0.006333  0.004647  0.019893  0.001350  0.005858  0.006757  3.011975e-04  0.005678  0.010435  0.015921  0.029603  0.011217  0.022129  0.013643  0.012110  0.000609  0.014626  0.002978  0.010780  0.008258  1.042572e-03  0.000702  0.000997  0.002512  0.005998  0.014586  0.004602  0.031719  0.004372  0.019251  0.004410  0.006856  0.017098  0.006122  0.000913  0.002715  0.001758  0.024685  0.007777  0.004583  0.007940  0.001198  0.010440  0.000195  0.001815  0.019404  0.001683  0.004656  0.014186  0.002556  0.026068  0.010099  0.001106  0.007528  0.004400  0.007674  0.004917  0.019718  0.005612  0.003695  0.113658  0.005085  0.017118  0.006042  0.002600  4.919142e-04  1.271067e-03  0.000801  0.010672  0.000559  0.001031  0.000927  0.002870  8.272281e-05  0.001422  0.000323  0.005632  0.001045  0.007063  0.026649  0.003356  0.006355  0.004530  0.003786  0.003726  0.011107  0.092024  0.006526  0.001313  5.458946e-04  0.025102  0.012909  0.019278  0.032923          69    66\n",
            "18  0.081611  1.375244e-04  0.003759  0.005384  0.007062  0.005801  0.009161  0.020086  0.029769  0.000184  0.000696  0.004064  9.791826e-05  0.007343  0.003814  0.035855  0.011647  0.008388  0.016810  0.251858  0.005986  0.000340  0.002600  0.003563  0.001693  0.001299  1.593869e-03  0.000452  0.000182  0.001223  0.005596  0.009105  0.000276  0.005547  0.001761  0.060465  0.008400  0.005351  0.014715  0.014283  0.000092  0.000603  0.000233  0.045430  0.003472  0.000526  0.004601  0.000660  0.001093  0.000014  0.000396  0.005501  0.000321  0.002120  0.007478  0.003125  0.028864  0.008136  0.000032  0.009796  0.000750  0.000957  0.001230  0.029813  0.002407  0.000810  0.062136  0.000246  0.009665  0.004433  0.000332  9.506071e-05  3.964941e-04  0.002684  0.002352  0.000057  0.000557  0.000017  0.000156  2.765420e-05  0.004536  0.000627  0.000970  0.000217  0.001258  0.017625  0.000246  0.000725  0.000150  0.005092  0.003246  0.001348  0.031493  0.003617  0.001255  1.516012e-04  0.011694  0.005815  0.005818  0.014544          26    66\n",
            "19  0.000110  3.497732e-04  0.000013  0.023031  0.000487  0.000318  0.000137  0.000027  0.001826  0.001330  0.008295  0.001242  2.520653e-04  0.002170  0.020196  0.006550  0.051887  0.004424  0.017917  0.000187  0.004701  0.030019  0.003467  0.002064  0.002183  0.001015  2.195687e-03  0.001141  0.000148  0.002932  0.006702  0.023452  0.001217  0.000294  0.028713  0.004065  0.000093  0.000984  0.015383  0.002167  0.000034  0.000241  0.000720  0.006782  0.001812  0.011172  0.008741  0.000327  0.059889  0.008391  0.000023  0.009644  0.000156  0.000146  0.011386  0.000440  0.018036  0.078420  0.013407  0.004866  0.012738  0.030238  0.010736  0.031934  0.000729  0.000148  0.001324  0.006039  0.006522  0.000004  0.000072  1.675090e-06  7.334967e-05  0.000313  0.003971  0.001965  0.012651  0.018844  0.001645  3.990712e-04  0.000015  0.000020  0.001522  0.000075  0.002698  0.007704  0.029240  0.008598  0.002156  0.011593  0.005562  0.005431  0.023048  0.001557  0.000064  1.076639e-04  0.237530  0.003340  0.003225  0.007852          96    66\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.32653374233128835,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.14137924195928686,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168329',\n",
            "  'info': None,\n",
            "  'logloss': 2.830913477458998,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.1152489185333252,\n",
            "  'result': 2.830913477458998,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Helena',\n",
            "  'training_duration': 222.21997165679932,\n",
            "  'utc': '2021-02-04T16:51:35',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Helena.0.TabNet executed in 247.341 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Helena.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Helena.\n",
            "Assigning 7279 MB (total=13021 MB) for new Helena task.\n",
            "Running task Helena on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Helena', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7279, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 4.28534 | val_0_accuracy: 0.14526 | val_1_accuracy: 0.14509 |  0:00:03s\n",
            "epoch 1  | loss: 3.54237 | val_0_accuracy: 0.17891 | val_1_accuracy: 0.17684 |  0:00:07s\n",
            "epoch 2  | loss: 3.35646 | val_0_accuracy: 0.18655 | val_1_accuracy: 0.19049 |  0:00:11s\n",
            "epoch 3  | loss: 3.26637 | val_0_accuracy: 0.22002 | val_1_accuracy: 0.22239 |  0:00:15s\n",
            "epoch 4  | loss: 3.19494 | val_0_accuracy: 0.24371 | val_1_accuracy: 0.24417 |  0:00:18s\n",
            "epoch 5  | loss: 3.12692 | val_0_accuracy: 0.26605 | val_1_accuracy: 0.2684  |  0:00:22s\n",
            "epoch 6  | loss: 3.07493 | val_0_accuracy: 0.27568 | val_1_accuracy: 0.28206 |  0:00:26s\n",
            "epoch 7  | loss: 3.04441 | val_0_accuracy: 0.28199 | val_1_accuracy: 0.28819 |  0:00:30s\n",
            "epoch 8  | loss: 3.02531 | val_0_accuracy: 0.28671 | val_1_accuracy: 0.29402 |  0:00:34s\n",
            "epoch 9  | loss: 3.01342 | val_0_accuracy: 0.28709 | val_1_accuracy: 0.29126 |  0:00:37s\n",
            "epoch 10 | loss: 2.99539 | val_0_accuracy: 0.28882 | val_1_accuracy: 0.29693 |  0:00:41s\n",
            "epoch 11 | loss: 2.97791 | val_0_accuracy: 0.29201 | val_1_accuracy: 0.3     |  0:00:45s\n",
            "epoch 12 | loss: 2.96797 | val_0_accuracy: 0.29786 | val_1_accuracy: 0.30184 |  0:00:49s\n",
            "epoch 13 | loss: 2.95891 | val_0_accuracy: 0.29648 | val_1_accuracy: 0.30429 |  0:00:53s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 28.8%\n",
            "[499] Disk Usage: 25.2%\n",
            "epoch 14 | loss: 2.95103 | val_0_accuracy: 0.29719 | val_1_accuracy: 0.30153 |  0:00:56s\n",
            "epoch 15 | loss: 2.94153 | val_0_accuracy: 0.30193 | val_1_accuracy: 0.30798 |  0:01:00s\n",
            "epoch 16 | loss: 2.93558 | val_0_accuracy: 0.30026 | val_1_accuracy: 0.30767 |  0:01:04s\n",
            "epoch 17 | loss: 2.92832 | val_0_accuracy: 0.30213 | val_1_accuracy: 0.31058 |  0:01:08s\n",
            "epoch 18 | loss: 2.92565 | val_0_accuracy: 0.30694 | val_1_accuracy: 0.31304 |  0:01:12s\n",
            "epoch 19 | loss: 2.92038 | val_0_accuracy: 0.30701 | val_1_accuracy: 0.31365 |  0:01:15s\n",
            "epoch 20 | loss: 2.91147 | val_0_accuracy: 0.30757 | val_1_accuracy: 0.3138  |  0:01:19s\n",
            "epoch 21 | loss: 2.90624 | val_0_accuracy: 0.30476 | val_1_accuracy: 0.31564 |  0:01:23s\n",
            "epoch 22 | loss: 2.90487 | val_0_accuracy: 0.30943 | val_1_accuracy: 0.31764 |  0:01:27s\n",
            "epoch 23 | loss: 2.89985 | val_0_accuracy: 0.30924 | val_1_accuracy: 0.3135  |  0:01:30s\n",
            "epoch 24 | loss: 2.8928  | val_0_accuracy: 0.31321 | val_1_accuracy: 0.32301 |  0:01:34s\n",
            "epoch 25 | loss: 2.88445 | val_0_accuracy: 0.31289 | val_1_accuracy: 0.31442 |  0:01:38s\n",
            "epoch 26 | loss: 2.87964 | val_0_accuracy: 0.30597 | val_1_accuracy: 0.30736 |  0:01:42s\n",
            "epoch 27 | loss: 2.88271 | val_0_accuracy: 0.31415 | val_1_accuracy: 0.32485 |  0:01:46s\n",
            "epoch 28 | loss: 2.87931 | val_0_accuracy: 0.31735 | val_1_accuracy: 0.32577 |  0:01:49s\n",
            "epoch 29 | loss: 2.86999 | val_0_accuracy: 0.31454 | val_1_accuracy: 0.31963 |  0:01:53s\n",
            "epoch 30 | loss: 2.86986 | val_0_accuracy: 0.31573 | val_1_accuracy: 0.32147 |  0:01:57s\n",
            "epoch 31 | loss: 2.87162 | val_0_accuracy: 0.31856 | val_1_accuracy: 0.32531 |  0:02:01s\n",
            "epoch 32 | loss: 2.86631 | val_0_accuracy: 0.31659 | val_1_accuracy: 0.31871 |  0:02:04s\n",
            "epoch 33 | loss: 2.85502 | val_0_accuracy: 0.31798 | val_1_accuracy: 0.32393 |  0:02:08s\n",
            "epoch 34 | loss: 2.85787 | val_0_accuracy: 0.31331 | val_1_accuracy: 0.31963 |  0:02:12s\n",
            "epoch 35 | loss: 2.85664 | val_0_accuracy: 0.31544 | val_1_accuracy: 0.32193 |  0:02:16s\n",
            "epoch 36 | loss: 2.85284 | val_0_accuracy: 0.3188  | val_1_accuracy: 0.32025 |  0:02:20s\n",
            "epoch 37 | loss: 2.84931 | val_0_accuracy: 0.31841 | val_1_accuracy: 0.31794 |  0:02:23s\n",
            "epoch 38 | loss: 2.84721 | val_0_accuracy: 0.31901 | val_1_accuracy: 0.32991 |  0:02:27s\n",
            "epoch 39 | loss: 2.85253 | val_0_accuracy: 0.31444 | val_1_accuracy: 0.32163 |  0:02:31s\n",
            "epoch 40 | loss: 2.85539 | val_0_accuracy: 0.32265 | val_1_accuracy: 0.32653 |  0:02:35s\n",
            "epoch 41 | loss: 2.84148 | val_0_accuracy: 0.3189  | val_1_accuracy: 0.32285 |  0:02:38s\n",
            "epoch 42 | loss: 2.8416  | val_0_accuracy: 0.31771 | val_1_accuracy: 0.32055 |  0:02:42s\n",
            "epoch 43 | loss: 2.83652 | val_0_accuracy: 0.31945 | val_1_accuracy: 0.32316 |  0:02:46s\n",
            "epoch 44 | loss: 2.83768 | val_0_accuracy: 0.31947 | val_1_accuracy: 0.31687 |  0:02:50s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 28.8%\n",
            "[499] Disk Usage: 25.2%\n",
            "epoch 45 | loss: 2.82844 | val_0_accuracy: 0.32107 | val_1_accuracy: 0.3227  |  0:02:54s\n",
            "epoch 46 | loss: 2.83776 | val_0_accuracy: 0.31797 | val_1_accuracy: 0.32469 |  0:02:57s\n",
            "epoch 47 | loss: 2.82907 | val_0_accuracy: 0.32349 | val_1_accuracy: 0.32914 |  0:03:01s\n",
            "epoch 48 | loss: 2.83403 | val_0_accuracy: 0.32628 | val_1_accuracy: 0.32454 |  0:03:05s\n",
            "\n",
            "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_1_accuracy = 0.32991\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1        10        11        12        13        14        15        16        17        18        19         2        20        21        22        23        24        25        26        27        28        29         3        30        31        32        33        34        35        36        37        38        39         4        40        41        42        43        44            45        46        47        48        49         5        50        51        52        53        54        55        56        57        58        59         6        60        61        62        63        64        65        66        67        68        69         7        70        71        72        73        74        75        76        77        78        79         8            80        81        82        83        84        85        86        87        88        89         9        90        91        92        93        94        95        96        97        98        99 predictions truth\n",
            "0   0.006039  0.006478  0.000189  0.015033  0.051561  0.045766  0.001739  0.000459  0.027916  0.001027  0.001546  0.001747  0.001890  0.063557  0.003082  0.011259  0.006384  0.002296  0.037607  0.012093  0.000797  0.027146  0.004007  0.004199  0.002656  0.001064  0.013924  0.001401  0.000226  0.003539  0.005868  0.008450  0.002362  0.001924  0.019747  0.086973  0.004887  0.003272  0.018192  0.008411  2.110263e-05  0.000304  0.001928  0.008584  0.002314  0.000505  0.006094  0.000616  0.010435  0.000422  0.000775  0.149138  0.000356  0.001201  0.003847  0.001818  0.008431  0.007545  0.000383  0.012756  0.030473  0.003818  0.002356  0.010233  0.000710  0.000445  0.003209  0.000823  0.001800  0.000028  0.000288  0.000012  0.000250  0.001673  0.001677  0.000266  0.004607  0.000414  0.001102  1.295694e-05  0.000054  0.000638  0.000548  0.001450  0.001037  0.012435  0.002117  0.000618  0.000317  0.005630  0.005424  0.000942  0.019398  0.001682  0.000188  0.000069  0.016550  0.124236  0.002590  0.005692          55    66\n",
            "1   0.000901  0.009556  0.000289  0.023906  0.000933  0.000373  0.000866  0.000853  0.003142  0.003872  0.006193  0.004372  0.000688  0.006795  0.002325  0.002243  0.005609  0.003326  0.017082  0.000011  0.009436  0.002992  0.006217  0.010124  0.007226  0.002450  0.001600  0.008811  0.001274  0.007381  0.006101  0.005431  0.064052  0.006635  0.010498  0.019695  0.000033  0.002949  0.008031  0.000575  4.377398e-04  0.002958  0.010979  0.007843  0.005869  0.023624  0.004628  0.003003  0.022824  0.013698  0.001757  0.026265  0.000520  0.002041  0.006305  0.004758  0.009529  0.004902  0.039003  0.002065  0.014411  0.079237  0.005253  0.009164  0.003820  0.001572  0.007003  0.045442  0.004851  0.000351  0.001073  0.000049  0.000373  0.001398  0.008006  0.003348  0.010742  0.010865  0.007792  3.885608e-04  0.000021  0.000078  0.005723  0.000779  0.006148  0.010287  0.074903  0.058164  0.005359  0.010013  0.006133  0.071888  0.017605  0.008290  0.001522  0.000049  0.018567  0.011826  0.003905  0.005746          64    66\n",
            "2   0.006769  0.007482  0.005307  0.005228  0.001702  0.001186  0.011142  0.055342  0.007573  0.024064  0.001805  0.006558  0.003872  0.010214  0.000713  0.001559  0.004438  0.009095  0.012348  0.000519  0.019341  0.000094  0.019654  0.013035  0.009848  0.001620  0.000046  0.001080  0.005351  0.000238  0.003524  0.002117  0.007157  0.061102  0.001386  0.048597  0.000830  0.003020  0.004223  0.004269  7.970597e-03  0.007611  0.001812  0.028091  0.002807  0.003405  0.002197  0.013579  0.002037  0.000019  0.001687  0.009837  0.005082  0.027554  0.004578  0.037946  0.035314  0.000501  0.002575  0.002356  0.005551  0.003410  0.002094  0.004656  0.029784  0.011917  0.085755  0.003299  0.002348  0.007938  0.011089  0.003620  0.004383  0.010253  0.027482  0.001628  0.001344  0.004238  0.002030  1.106251e-05  0.000347  0.011536  0.011557  0.006848  0.031063  0.005929  0.004019  0.010008  0.001753  0.031215  0.001641  0.006967  0.009456  0.015189  0.014040  0.014851  0.010576  0.005969  0.001659  0.002146          69    66\n",
            "3   0.001678  0.000413  0.000560  0.005710  0.012291  0.011235  0.006777  0.001241  0.017090  0.010408  0.003592  0.004347  0.001070  0.012368  0.019379  0.011800  0.024126  0.007249  0.018035  0.296724  0.001363  0.001320  0.002622  0.001448  0.001119  0.000512  0.000899  0.000125  0.000170  0.000896  0.003233  0.007904  0.000370  0.009734  0.003743  0.021322  0.018503  0.003970  0.022152  0.040918  8.929000e-06  0.000488  0.000194  0.031682  0.003091  0.000529  0.005386  0.000149  0.007473  0.000007  0.000327  0.017246  0.001184  0.004611  0.006922  0.000484  0.046072  0.011160  0.000153  0.013601  0.004730  0.000710  0.002646  0.012441  0.000453  0.000601  0.033324  0.000197  0.007306  0.000198  0.000754  0.000251  0.000595  0.001161  0.002202  0.001453  0.001613  0.001416  0.000660  3.980268e-05  0.001378  0.002924  0.000671  0.002915  0.000582  0.004869  0.000801  0.000469  0.001073  0.005178  0.002667  0.000386  0.048433  0.000452  0.000049  0.003730  0.060307  0.019464  0.005306  0.006409          26    66\n",
            "4   0.001291  0.021796  0.000575  0.022354  0.003009  0.001558  0.002415  0.002539  0.006885  0.006733  0.004849  0.005216  0.004028  0.024849  0.002238  0.002330  0.008028  0.005738  0.028395  0.000144  0.010095  0.004188  0.010947  0.015713  0.007754  0.001572  0.000814  0.003202  0.002806  0.002156  0.008564  0.006415  0.016398  0.008767  0.013294  0.063009  0.000245  0.003275  0.015097  0.002903  6.229657e-04  0.002961  0.009351  0.017868  0.005354  0.011687  0.005432  0.003685  0.018539  0.001111  0.001886  0.063703  0.001553  0.005055  0.006551  0.009877  0.026738  0.003405  0.023093  0.003133  0.035126  0.029242  0.004944  0.011006  0.005618  0.002001  0.015157  0.012759  0.003637  0.000293  0.001162  0.000051  0.001544  0.004701  0.014172  0.001567  0.011867  0.005456  0.005881  6.869381e-05  0.000012  0.000648  0.006218  0.002855  0.013322  0.010353  0.041422  0.026870  0.004482  0.032839  0.006468  0.020813  0.015468  0.009611  0.001694  0.000523  0.029647  0.029030  0.002735  0.004951          55    66\n",
            "5   0.010267  0.000101  0.032193  0.000718  0.003342  0.001643  0.081151  0.023362  0.003164  0.001576  0.000998  0.005049  0.000641  0.001552  0.001885  0.000587  0.001622  0.007492  0.001209  0.004745  0.001066  0.000001  0.000577  0.000203  0.000282  0.000168  0.000052  0.000050  0.000553  0.000422  0.000181  0.000173  0.002477  0.038263  0.000031  0.002250  0.000467  0.003699  0.001786  0.001240  1.363765e-04  0.032075  0.000369  0.025447  0.008391  0.001372  0.000330  0.000321  0.000222  0.000011  0.008379  0.006732  0.008433  0.151942  0.001288  0.000870  0.036637  0.000211  0.000103  0.000600  0.000301  0.000442  0.000151  0.000910  0.001346  0.000898  0.300001  0.001304  0.005954  0.058025  0.000984  0.000680  0.006527  0.000123  0.000272  0.000145  0.000042  0.000011  0.002224  3.377860e-05  0.002612  0.000030  0.001238  0.021181  0.000153  0.000800  0.001573  0.008132  0.002365  0.000198  0.000276  0.008736  0.031363  0.000673  0.000218  0.002711  0.001470  0.009289  0.003767  0.001730          69    66\n",
            "6   0.004487  0.004084  0.021827  0.001513  0.002670  0.001377  0.038868  0.076823  0.003186  0.005593  0.000890  0.005173  0.008093  0.007479  0.000431  0.000221  0.001301  0.008160  0.003107  0.000409  0.005305  0.000013  0.003647  0.002571  0.001462  0.000228  0.000021  0.000170  0.006323  0.000115  0.000780  0.000281  0.003744  0.028124  0.000179  0.015137  0.000272  0.002220  0.002729  0.001407  4.326652e-03  0.040146  0.002003  0.026291  0.004707  0.003520  0.000485  0.005191  0.000473  0.000015  0.006563  0.017934  0.016325  0.161725  0.001363  0.020005  0.048194  0.000091  0.002000  0.000505  0.003162  0.001365  0.000351  0.001290  0.012977  0.003081  0.139622  0.002550  0.002011  0.019300  0.002019  0.000526  0.024226  0.002553  0.003482  0.000235  0.000553  0.000091  0.003265  1.252971e-05  0.000091  0.000767  0.005307  0.031450  0.005417  0.001211  0.006460  0.023400  0.002996  0.004836  0.000669  0.012230  0.006972  0.007046  0.003597  0.016873  0.002320  0.011629  0.001002  0.000769          57    66\n",
            "7   0.004156  0.003996  0.002314  0.009635  0.010474  0.008761  0.013698  0.009968  0.017622  0.017929  0.003362  0.007936  0.004485  0.030274  0.006163  0.007713  0.016199  0.013079  0.026422  0.023474  0.006560  0.001228  0.006934  0.008318  0.003156  0.000830  0.000603  0.000642  0.001336  0.001025  0.006171  0.006868  0.001835  0.017662  0.005294  0.082546  0.004835  0.005213  0.019998  0.023145  1.500822e-04  0.002195  0.001254  0.055378  0.005534  0.002204  0.005768  0.001405  0.006972  0.000025  0.001125  0.033665  0.003113  0.012711  0.008223  0.004920  0.074364  0.005484  0.001075  0.008839  0.011757  0.003052  0.003534  0.015619  0.003454  0.002028  0.054762  0.001062  0.005754  0.000925  0.001714  0.000347  0.002309  0.007015  0.008201  0.001691  0.003163  0.002529  0.001788  2.097971e-05  0.000524  0.004933  0.003001  0.006609  0.004143  0.007984  0.003855  0.003474  0.001719  0.026530  0.004249  0.002432  0.027466  0.003065  0.000796  0.007185  0.049127  0.026312  0.003715  0.005890          40    66\n",
            "8   0.001090  0.010763  0.000131  0.021905  0.018723  0.011661  0.001216  0.000298  0.015446  0.002315  0.004719  0.002442  0.003558  0.040575  0.005504  0.004106  0.010410  0.002799  0.038338  0.003294  0.001526  0.035336  0.007565  0.004603  0.004764  0.001369  0.004794  0.001016  0.000619  0.002343  0.008005  0.010364  0.003956  0.002943  0.026699  0.040792  0.002670  0.003025  0.029134  0.007414  7.763071e-05  0.000717  0.003594  0.008487  0.002950  0.002113  0.007247  0.000901  0.029179  0.000779  0.000993  0.157797  0.000813  0.002178  0.005244  0.002601  0.013901  0.006604  0.004437  0.008356  0.060520  0.008280  0.004287  0.009906  0.001119  0.000684  0.005013  0.002449  0.003231  0.000026  0.000452  0.000016  0.000730  0.001498  0.004500  0.000693  0.017156  0.001488  0.002996  1.091253e-04  0.000011  0.000843  0.001370  0.002388  0.003545  0.010303  0.010571  0.002780  0.002273  0.009250  0.007444  0.002629  0.024709  0.002969  0.000170  0.000221  0.030123  0.096958  0.003527  0.005570          55    66\n",
            "9   0.000911  0.000472  0.000140  0.017273  0.002243  0.001014  0.000923  0.000522  0.006550  0.024647  0.006556  0.007004  0.000041  0.003448  0.022273  0.017611  0.016946  0.005104  0.023641  0.000256  0.004661  0.003601  0.001468  0.004626  0.001688  0.000849  0.007964  0.004616  0.000041  0.019780  0.005577  0.009887  0.023030  0.005774  0.007806  0.017488  0.000056  0.004404  0.016501  0.001032  5.251165e-06  0.001057  0.000466  0.018544  0.006239  0.006602  0.006798  0.000681  0.029474  0.003220  0.000148  0.009113  0.000087  0.001446  0.012851  0.001048  0.016139  0.054329  0.001667  0.013549  0.002554  0.025876  0.006227  0.038451  0.000966  0.000536  0.006797  0.005611  0.021293  0.000204  0.000768  0.000138  0.000018  0.000780  0.002044  0.049361  0.018954  0.043289  0.001355  1.033321e-03  0.004273  0.000111  0.000996  0.000154  0.000342  0.010189  0.010582  0.010390  0.000962  0.002671  0.009009  0.020210  0.109599  0.001915  0.000211  0.000026  0.088042  0.005893  0.008890  0.007401          92    66\n",
            "10  0.006646  0.000073  0.000290  0.007145  0.012978  0.008940  0.002340  0.000695  0.016948  0.012006  0.002494  0.005224  0.000016  0.003569  0.030010  0.060404  0.013477  0.004583  0.017420  0.010930  0.001105  0.001609  0.000557  0.001364  0.000583  0.000573  0.026541  0.001931  0.000007  0.023419  0.002549  0.007031  0.005933  0.005182  0.002884  0.015704  0.000487  0.005985  0.011902  0.002183  7.389322e-07  0.000529  0.000080  0.019340  0.004864  0.000691  0.005144  0.000233  0.007791  0.000557  0.000112  0.006717  0.000057  0.001527  0.009297  0.000357  0.010983  0.068396  0.000035  0.032996  0.000674  0.003406  0.002550  0.032185  0.000354  0.000317  0.007105  0.000686  0.019787  0.000344  0.000623  0.000312  0.000008  0.000372  0.000372  0.020981  0.003202  0.005468  0.000364  3.047344e-04  0.137193  0.000130  0.000228  0.000154  0.000038  0.008931  0.000709  0.000865  0.000140  0.000484  0.004917  0.002893  0.169050  0.000529  0.000083  0.000019  0.043548  0.008270  0.011023  0.007956          92    66\n",
            "11  0.003568  0.008564  0.000083  0.038188  0.003007  0.002763  0.000454  0.000355  0.014683  0.002845  0.004850  0.002415  0.000743  0.018948  0.003112  0.023990  0.014787  0.002421  0.049787  0.001027  0.006015  0.022474  0.018686  0.015343  0.019538  0.010942  0.005411  0.010640  0.000632  0.006833  0.014636  0.032904  0.010434  0.006878  0.057041  0.064153  0.002399  0.003481  0.010742  0.008627  1.843521e-04  0.000137  0.004393  0.006153  0.001907  0.002211  0.016401  0.001407  0.032861  0.001473  0.000532  0.021883  0.000208  0.000215  0.010545  0.002104  0.004838  0.017639  0.003033  0.012041  0.022881  0.021299  0.012800  0.016129  0.001927  0.002489  0.003333  0.005541  0.002191  0.000058  0.002179  0.000143  0.000114  0.003213  0.017555  0.001600  0.003688  0.025798  0.001830  3.569256e-05  0.000073  0.001774  0.003272  0.000350  0.009876  0.034943  0.004812  0.001504  0.000946  0.030581  0.006921  0.002538  0.013700  0.003543  0.001144  0.000074  0.038456  0.015612  0.004511  0.016001          40    66\n",
            "12  0.003411  0.005985  0.000314  0.022476  0.003907  0.003857  0.002646  0.001490  0.015969  0.004142  0.003095  0.003689  0.002147  0.037027  0.003204  0.017219  0.019286  0.005926  0.044261  0.007711  0.006442  0.003280  0.010414  0.013117  0.006309  0.002278  0.000934  0.001842  0.000892  0.002006  0.009448  0.018122  0.002257  0.010635  0.020775  0.149402  0.003921  0.003672  0.014860  0.027211  5.223079e-05  0.000204  0.002631  0.027409  0.003046  0.001687  0.010517  0.000491  0.014016  0.000050  0.000662  0.032833  0.000622  0.000821  0.009169  0.001450  0.027877  0.010353  0.001249  0.007773  0.019258  0.007761  0.006189  0.017227  0.001326  0.001329  0.018716  0.001680  0.002245  0.000116  0.000914  0.000055  0.000450  0.004976  0.012809  0.000470  0.001139  0.004897  0.001402  2.733205e-06  0.000044  0.001575  0.002719  0.001334  0.005810  0.018917  0.003862  0.001545  0.000956  0.062467  0.004030  0.001500  0.015226  0.001657  0.000467  0.000565  0.064686  0.024792  0.003086  0.013309          40    66\n",
            "13  0.004069  0.000823  0.010979  0.003714  0.005209  0.003178  0.044731  0.013702  0.007459  0.007157  0.004124  0.009151  0.003623  0.007324  0.006996  0.002100  0.009513  0.014606  0.006534  0.019840  0.003776  0.000053  0.002952  0.001385  0.001322  0.000563  0.000153  0.000157  0.001890  0.000744  0.001467  0.001701  0.002154  0.037357  0.000596  0.010827  0.002884  0.005849  0.009669  0.010488  2.424918e-04  0.012359  0.001178  0.049403  0.010506  0.003616  0.002081  0.000595  0.002382  0.000021  0.005436  0.018357  0.011707  0.062659  0.004828  0.001791  0.087236  0.001521  0.000992  0.002443  0.003078  0.001636  0.001231  0.004499  0.002242  0.001787  0.218500  0.001924  0.009742  0.009293  0.001702  0.000656  0.010776  0.000996  0.002498  0.000652  0.000525  0.000269  0.004097  8.183764e-05  0.000779  0.000516  0.003360  0.023445  0.001389  0.002843  0.005313  0.009579  0.007247  0.003572  0.001456  0.006438  0.038595  0.001521  0.000335  0.012632  0.014385  0.018948  0.006188  0.005099          69    66\n",
            "14  0.001700  0.000163  0.000074  0.005438  0.000281  0.000132  0.000573  0.000089  0.005823  0.000377  0.008054  0.000664  0.000260  0.000493  0.001229  0.000505  0.006614  0.000633  0.005753  0.002135  0.000860  0.000010  0.086281  0.000103  0.049215  0.034370  0.000005  0.000030  0.000772  0.000053  0.000518  0.003093  0.004674  0.364771  0.000624  0.000369  0.029223  0.001440  0.001550  0.006127  5.961233e-03  0.000510  0.000461  0.000973  0.000371  0.000370  0.001887  0.000295  0.004795  0.000003  0.002098  0.004915  0.002231  0.002676  0.002529  0.000393  0.002320  0.000096  0.000640  0.001042  0.002792  0.000481  0.001444  0.000217  0.001468  0.013498  0.130561  0.003338  0.001423  0.000561  0.032787  0.007020  0.001649  0.000010  0.016428  0.000039  0.000020  0.000457  0.002509  4.048192e-05  0.000006  0.001058  0.005941  0.003332  0.022460  0.006655  0.000534  0.000425  0.014268  0.000448  0.000146  0.000619  0.039670  0.001011  0.000090  0.000990  0.002384  0.006423  0.009635  0.007514          39    66\n",
            "15  0.014976  0.007286  0.000280  0.010718  0.037759  0.031688  0.002441  0.000456  0.020874  0.000101  0.000611  0.000873  0.002391  0.071856  0.000547  0.004424  0.002186  0.001331  0.022070  0.003755  0.000432  0.003151  0.003435  0.002124  0.002196  0.000942  0.004194  0.000814  0.000346  0.001890  0.002175  0.002935  0.002746  0.002321  0.007024  0.089212  0.002799  0.002351  0.006778  0.004444  2.674136e-05  0.000284  0.004292  0.005809  0.001965  0.000306  0.002579  0.000311  0.003043  0.000206  0.002693  0.258578  0.000426  0.001153  0.001579  0.001084  0.005469  0.001257  0.000204  0.003210  0.026074  0.002986  0.000712  0.002869  0.000487  0.000316  0.005266  0.001173  0.000553  0.000039  0.000139  0.000002  0.000463  0.000543  0.000858  0.000011  0.000347  0.000021  0.001351  6.514211e-07  0.000003  0.000063  0.000511  0.002419  0.000841  0.010098  0.001886  0.000604  0.000235  0.003151  0.001657  0.001092  0.010184  0.001105  0.000148  0.000018  0.003793  0.237979  0.001492  0.005101          55    66\n",
            "16  0.000556  0.002051  0.000161  0.013485  0.001426  0.001391  0.001456  0.000942  0.004640  0.009155  0.001718  0.004149  0.000428  0.019806  0.005782  0.025719  0.017642  0.006553  0.024779  0.002302  0.006214  0.005454  0.000857  0.017395  0.000632  0.000233  0.002342  0.002899  0.000148  0.005992  0.008428  0.013359  0.001036  0.001279  0.018085  0.171459  0.000186  0.002225  0.014728  0.009592  1.056177e-06  0.000085  0.000959  0.043411  0.004064  0.002747  0.007531  0.000116  0.012872  0.000114  0.000099  0.009581  0.000099  0.000222  0.008218  0.000362  0.034946  0.054172  0.000958  0.006099  0.005585  0.013067  0.005201  0.047874  0.000290  0.000147  0.004508  0.000822  0.003128  0.000039  0.000087  0.000006  0.000047  0.007878  0.002934  0.002608  0.003107  0.015112  0.000513  3.728589e-06  0.000160  0.000216  0.000700  0.000188  0.000493  0.007655  0.005632  0.002340  0.000287  0.066175  0.005997  0.002038  0.009298  0.000468  0.000134  0.000120  0.157050  0.005882  0.001488  0.007381          40    66\n",
            "17  0.002540  0.019189  0.000182  0.024907  0.012087  0.009918  0.001075  0.000726  0.015586  0.003077  0.003031  0.002664  0.002980  0.048400  0.002822  0.009102  0.008928  0.003099  0.043937  0.001596  0.003477  0.041908  0.009127  0.014286  0.007004  0.002206  0.006870  0.004465  0.000855  0.003895  0.012339  0.014231  0.005549  0.002748  0.040273  0.099196  0.001779  0.003138  0.018275  0.007071  1.366178e-04  0.000427  0.005055  0.009327  0.002656  0.002216  0.009346  0.001891  0.022033  0.001238  0.000773  0.078699  0.000480  0.000936  0.006257  0.004591  0.009875  0.009588  0.003753  0.009731  0.046087  0.013693  0.006100  0.014950  0.002064  0.001123  0.003120  0.002994  0.002106  0.000044  0.000693  0.000031  0.000385  0.005338  0.007878  0.001049  0.012710  0.004658  0.002107  3.759856e-05  0.000030  0.001640  0.001959  0.001145  0.005931  0.016351  0.007951  0.002484  0.000909  0.026018  0.008788  0.002798  0.011806  0.004545  0.000830  0.000170  0.029860  0.047104  0.002492  0.006476          40    66\n",
            "18  0.000965  0.011106  0.000044  0.032090  0.010638  0.007189  0.000356  0.000056  0.012051  0.000634  0.006603  0.001371  0.002271  0.025532  0.005008  0.005648  0.009955  0.001309  0.034660  0.001806  0.001095  0.094553  0.009966  0.003556  0.008943  0.004816  0.011680  0.002313  0.000612  0.005250  0.009061  0.018165  0.005952  0.001917  0.057318  0.019177  0.003771  0.002691  0.019944  0.006231  1.041120e-04  0.000247  0.007178  0.002693  0.002085  0.002104  0.010596  0.000569  0.049147  0.004698  0.001248  0.111995  0.000422  0.000415  0.005202  0.001037  0.003828  0.009484  0.007059  0.007604  0.069549  0.014113  0.006730  0.007006  0.000608  0.000709  0.001699  0.004915  0.002246  0.000011  0.000479  0.000013  0.000395  0.000685  0.004743  0.000424  0.010956  0.002167  0.003988  2.499336e-04  0.000005  0.000416  0.001426  0.001068  0.004201  0.015500  0.011054  0.001730  0.003026  0.006522  0.007447  0.002248  0.016207  0.002132  0.000131  0.000047  0.019684  0.076911  0.004678  0.009862          55    66\n",
            "19  0.001906  0.000229  0.000036  0.028001  0.007412  0.004786  0.000443  0.000011  0.012624  0.000306  0.013352  0.001771  0.000082  0.004162  0.041159  0.036940  0.024086  0.001401  0.020490  0.014129  0.000398  0.014883  0.002033  0.000457  0.002779  0.007241  0.052609  0.001765  0.000039  0.048995  0.003586  0.026148  0.007312  0.003342  0.021100  0.003291  0.004839  0.005740  0.016191  0.006347  2.114970e-06  0.000116  0.001445  0.002984  0.004470  0.001406  0.013883  0.000032  0.052585  0.008455  0.001042  0.027194  0.000114  0.000169  0.009349  0.000032  0.002839  0.069091  0.000566  0.014670  0.006184  0.010811  0.006555  0.009842  0.000060  0.000257  0.003245  0.004611  0.010791  0.000028  0.000337  0.000026  0.000041  0.000037  0.000624  0.000802  0.001155  0.001548  0.002991  1.313351e-03  0.000279  0.000016  0.000445  0.000308  0.000139  0.018738  0.003826  0.000764  0.002879  0.000428  0.004840  0.002448  0.109652  0.000207  0.000009  0.000004  0.028304  0.039063  0.029598  0.043932          92    66\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Helena/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.3299079754601227,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.136954223214467,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168329',\n",
            "  'info': None,\n",
            "  'logloss': 2.8541727346584054,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.11791753768920898,\n",
            "  'result': 2.8541727346584054,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Helena',\n",
            "  'training_duration': 186.59800815582275,\n",
            "  'utc': '2021-02-04T16:54:48',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Helena.1.TabNet executed in 193.813 seconds.\n",
            "\n",
            "-----------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.higgs.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task higgs.\n",
            "Assigning 7223 MB (total=13021 MB) for new higgs task.\n",
            "Running task higgs on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='higgs', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7223, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.68978 | val_0_auc: 0.55312 | val_1_auc: 0.55425 |  0:00:05s\n",
            "epoch 1  | loss: 0.65018 | val_0_auc: 0.62668 | val_1_auc: 0.62378 |  0:00:11s\n",
            "epoch 2  | loss: 0.63253 | val_0_auc: 0.68438 | val_1_auc: 0.68254 |  0:00:16s\n",
            "epoch 3  | loss: 0.62569 | val_0_auc: 0.70933 | val_1_auc: 0.70583 |  0:00:22s\n",
            "epoch 4  | loss: 0.62464 | val_0_auc: 0.7115  | val_1_auc: 0.70953 |  0:00:28s\n",
            "epoch 5  | loss: 0.62137 | val_0_auc: 0.72198 | val_1_auc: 0.71815 |  0:00:33s\n",
            "epoch 6  | loss: 0.61558 | val_0_auc: 0.72661 | val_1_auc: 0.72365 |  0:00:39s\n",
            "epoch 7  | loss: 0.60999 | val_0_auc: 0.73387 | val_1_auc: 0.73375 |  0:00:45s\n",
            "epoch 8  | loss: 0.60465 | val_0_auc: 0.74287 | val_1_auc: 0.74741 |  0:00:50s\n",
            "epoch 9  | loss: 0.60219 | val_0_auc: 0.74088 | val_1_auc: 0.74358 |  0:00:56s\n",
            "epoch 10 | loss: 0.60019 | val_0_auc: 0.74863 | val_1_auc: 0.75343 |  0:01:01s\n",
            "epoch 11 | loss: 0.59887 | val_0_auc: 0.74976 | val_1_auc: 0.75185 |  0:01:07s\n",
            "epoch 12 | loss: 0.59522 | val_0_auc: 0.75095 | val_1_auc: 0.75145 |  0:01:13s\n",
            "[499] CPU Utilization: 45.3%\n",
            "[499] Memory Usage: 29.7%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 13 | loss: 0.59352 | val_0_auc: 0.75516 | val_1_auc: 0.75717 |  0:01:18s\n",
            "epoch 14 | loss: 0.59176 | val_0_auc: 0.74109 | val_1_auc: 0.74185 |  0:01:24s\n",
            "epoch 15 | loss: 0.59069 | val_0_auc: 0.75583 | val_1_auc: 0.76027 |  0:01:29s\n",
            "epoch 16 | loss: 0.5878  | val_0_auc: 0.75933 | val_1_auc: 0.76034 |  0:01:35s\n",
            "epoch 17 | loss: 0.58572 | val_0_auc: 0.76047 | val_1_auc: 0.7635  |  0:01:41s\n",
            "epoch 18 | loss: 0.58349 | val_0_auc: 0.76255 | val_1_auc: 0.76369 |  0:01:46s\n",
            "epoch 19 | loss: 0.58458 | val_0_auc: 0.76397 | val_1_auc: 0.76625 |  0:01:52s\n",
            "epoch 20 | loss: 0.58146 | val_0_auc: 0.76356 | val_1_auc: 0.76735 |  0:01:57s\n",
            "epoch 21 | loss: 0.58067 | val_0_auc: 0.76444 | val_1_auc: 0.76287 |  0:02:03s\n",
            "epoch 22 | loss: 0.58184 | val_0_auc: 0.76606 | val_1_auc: 0.76676 |  0:02:09s\n",
            "epoch 23 | loss: 0.58068 | val_0_auc: 0.76686 | val_1_auc: 0.76871 |  0:02:14s\n",
            "epoch 24 | loss: 0.57976 | val_0_auc: 0.77096 | val_1_auc: 0.77076 |  0:02:20s\n",
            "epoch 25 | loss: 0.57794 | val_0_auc: 0.77237 | val_1_auc: 0.77289 |  0:02:25s\n",
            "epoch 26 | loss: 0.5753  | val_0_auc: 0.77403 | val_1_auc: 0.77426 |  0:02:31s\n",
            "epoch 27 | loss: 0.57417 | val_0_auc: 0.77231 | val_1_auc: 0.77155 |  0:02:37s\n",
            "epoch 28 | loss: 0.57411 | val_0_auc: 0.7731  | val_1_auc: 0.77545 |  0:02:42s\n",
            "epoch 29 | loss: 0.57355 | val_0_auc: 0.76912 | val_1_auc: 0.7702  |  0:02:48s\n",
            "epoch 30 | loss: 0.57287 | val_0_auc: 0.77205 | val_1_auc: 0.77102 |  0:02:53s\n",
            "epoch 31 | loss: 0.57376 | val_0_auc: 0.76815 | val_1_auc: 0.76974 |  0:02:59s\n",
            "epoch 32 | loss: 0.57696 | val_0_auc: 0.76857 | val_1_auc: 0.77023 |  0:03:04s\n",
            "epoch 33 | loss: 0.57687 | val_0_auc: 0.76923 | val_1_auc: 0.77277 |  0:03:10s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 30.4%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 34 | loss: 0.57645 | val_0_auc: 0.77332 | val_1_auc: 0.77713 |  0:03:16s\n",
            "epoch 35 | loss: 0.57291 | val_0_auc: 0.76397 | val_1_auc: 0.76725 |  0:03:21s\n",
            "epoch 36 | loss: 0.57225 | val_0_auc: 0.77903 | val_1_auc: 0.78214 |  0:03:27s\n",
            "epoch 37 | loss: 0.57182 | val_0_auc: 0.77188 | val_1_auc: 0.77681 |  0:03:32s\n",
            "epoch 38 | loss: 0.57033 | val_0_auc: 0.77587 | val_1_auc: 0.77822 |  0:03:38s\n",
            "epoch 39 | loss: 0.57289 | val_0_auc: 0.77574 | val_1_auc: 0.7761  |  0:03:43s\n",
            "epoch 40 | loss: 0.56568 | val_0_auc: 0.7837  | val_1_auc: 0.78506 |  0:03:49s\n",
            "epoch 41 | loss: 0.56568 | val_0_auc: 0.78537 | val_1_auc: 0.78347 |  0:03:55s\n",
            "epoch 42 | loss: 0.56611 | val_0_auc: 0.78518 | val_1_auc: 0.78549 |  0:04:00s\n",
            "epoch 43 | loss: 0.56167 | val_0_auc: 0.78086 | val_1_auc: 0.78178 |  0:04:06s\n",
            "epoch 44 | loss: 0.56077 | val_0_auc: 0.78107 | val_1_auc: 0.77988 |  0:04:11s\n",
            "epoch 45 | loss: 0.56113 | val_0_auc: 0.78558 | val_1_auc: 0.78676 |  0:04:17s\n",
            "epoch 46 | loss: 0.55888 | val_0_auc: 0.78301 | val_1_auc: 0.78431 |  0:04:23s\n",
            "epoch 47 | loss: 0.55842 | val_0_auc: 0.78376 | val_1_auc: 0.78551 |  0:04:28s\n",
            "epoch 48 | loss: 0.55851 | val_0_auc: 0.77894 | val_1_auc: 0.77937 |  0:04:34s\n",
            "epoch 49 | loss: 0.55863 | val_0_auc: 0.79156 | val_1_auc: 0.79284 |  0:04:39s\n",
            "epoch 50 | loss: 0.55502 | val_0_auc: 0.78798 | val_1_auc: 0.78735 |  0:04:45s\n",
            "epoch 51 | loss: 0.55335 | val_0_auc: 0.79282 | val_1_auc: 0.79275 |  0:04:50s\n",
            "epoch 52 | loss: 0.55223 | val_0_auc: 0.79167 | val_1_auc: 0.79054 |  0:04:56s\n",
            "epoch 53 | loss: 0.5536  | val_0_auc: 0.79515 | val_1_auc: 0.79512 |  0:05:02s\n",
            "epoch 54 | loss: 0.55344 | val_0_auc: 0.77246 | val_1_auc: 0.77466 |  0:05:07s\n",
            "epoch 55 | loss: 0.55694 | val_0_auc: 0.79173 | val_1_auc: 0.79371 |  0:05:13s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 30.4%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 56 | loss: 0.55551 | val_0_auc: 0.79181 | val_1_auc: 0.79081 |  0:05:18s\n",
            "epoch 57 | loss: 0.55256 | val_0_auc: 0.79545 | val_1_auc: 0.79336 |  0:05:24s\n",
            "epoch 58 | loss: 0.5509  | val_0_auc: 0.79739 | val_1_auc: 0.79519 |  0:05:30s\n",
            "epoch 59 | loss: 0.55153 | val_0_auc: 0.78649 | val_1_auc: 0.78711 |  0:05:35s\n",
            "epoch 60 | loss: 0.55469 | val_0_auc: 0.79455 | val_1_auc: 0.79436 |  0:05:41s\n",
            "epoch 61 | loss: 0.55217 | val_0_auc: 0.78859 | val_1_auc: 0.78873 |  0:05:47s\n",
            "epoch 62 | loss: 0.55017 | val_0_auc: 0.79691 | val_1_auc: 0.79514 |  0:05:52s\n",
            "epoch 63 | loss: 0.55059 | val_0_auc: 0.78691 | val_1_auc: 0.78271 |  0:05:58s\n",
            "epoch 64 | loss: 0.55    | val_0_auc: 0.79911 | val_1_auc: 0.79926 |  0:06:03s\n",
            "epoch 65 | loss: 0.54891 | val_0_auc: 0.78616 | val_1_auc: 0.78479 |  0:06:09s\n",
            "epoch 66 | loss: 0.54935 | val_0_auc: 0.79193 | val_1_auc: 0.78834 |  0:06:15s\n",
            "epoch 67 | loss: 0.55661 | val_0_auc: 0.78906 | val_1_auc: 0.78536 |  0:06:20s\n",
            "epoch 68 | loss: 0.55381 | val_0_auc: 0.79518 | val_1_auc: 0.79427 |  0:06:26s\n",
            "epoch 69 | loss: 0.55026 | val_0_auc: 0.79501 | val_1_auc: 0.79317 |  0:06:31s\n",
            "epoch 70 | loss: 0.54863 | val_0_auc: 0.79813 | val_1_auc: 0.79939 |  0:06:37s\n",
            "epoch 71 | loss: 0.55038 | val_0_auc: 0.78463 | val_1_auc: 0.78547 |  0:06:43s\n",
            "epoch 72 | loss: 0.5536  | val_0_auc: 0.77843 | val_1_auc: 0.77702 |  0:06:48s\n",
            "epoch 73 | loss: 0.55132 | val_0_auc: 0.79803 | val_1_auc: 0.79813 |  0:06:54s\n",
            "epoch 74 | loss: 0.54843 | val_0_auc: 0.79916 | val_1_auc: 0.79922 |  0:06:59s\n",
            "epoch 75 | loss: 0.54681 | val_0_auc: 0.80153 | val_1_auc: 0.79826 |  0:07:05s\n",
            "epoch 76 | loss: 0.54638 | val_0_auc: 0.7932  | val_1_auc: 0.79307 |  0:07:10s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 30.4%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 77 | loss: 0.54597 | val_0_auc: 0.80287 | val_1_auc: 0.80208 |  0:07:16s\n",
            "epoch 78 | loss: 0.54666 | val_0_auc: 0.78963 | val_1_auc: 0.78807 |  0:07:22s\n",
            "epoch 79 | loss: 0.54603 | val_0_auc: 0.79119 | val_1_auc: 0.78861 |  0:07:27s\n",
            "epoch 80 | loss: 0.54596 | val_0_auc: 0.80122 | val_1_auc: 0.79742 |  0:07:33s\n",
            "epoch 81 | loss: 0.5446  | val_0_auc: 0.80139 | val_1_auc: 0.7983  |  0:07:38s\n",
            "epoch 82 | loss: 0.54905 | val_0_auc: 0.7863  | val_1_auc: 0.78429 |  0:07:44s\n",
            "epoch 83 | loss: 0.54933 | val_0_auc: 0.78741 | val_1_auc: 0.78741 |  0:07:50s\n",
            "epoch 84 | loss: 0.54744 | val_0_auc: 0.74098 | val_1_auc: 0.7413  |  0:07:55s\n",
            "epoch 85 | loss: 0.55249 | val_0_auc: 0.79929 | val_1_auc: 0.79933 |  0:08:01s\n",
            "epoch 86 | loss: 0.54875 | val_0_auc: 0.78692 | val_1_auc: 0.78199 |  0:08:07s\n",
            "epoch 87 | loss: 0.55907 | val_0_auc: 0.79193 | val_1_auc: 0.7924  |  0:08:13s\n",
            "\n",
            "Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_1_auc = 0.80208\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.675540  0.324460           0     0\n",
            "1   0.366191  0.633809           1     0\n",
            "2   0.578561  0.421439           0     0\n",
            "3   0.186458  0.813542           1     0\n",
            "4   0.331465  0.668535           1     0\n",
            "5   0.414508  0.585492           1     0\n",
            "6   0.654058  0.345942           0     0\n",
            "7   0.372116  0.627884           1     0\n",
            "8   0.859939  0.140061           0     0\n",
            "9   0.617646  0.382354           0     0\n",
            "10  0.661917  0.338083           0     0\n",
            "11  0.772972  0.227028           0     0\n",
            "12  0.804437  0.195563           0     0\n",
            "13  0.579118  0.420881           0     0\n",
            "14  0.629853  0.370147           0     0\n",
            "15  0.698239  0.301761           0     0\n",
            "16  0.956731  0.043269           0     0\n",
            "17  0.737423  0.262577           0     0\n",
            "18  0.489163  0.510837           1     0\n",
            "19  0.549567  0.450433           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.726874043855176,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.8020822923791593,\n",
            "  'balacc': 0.7233466475285546,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146606',\n",
            "  'info': None,\n",
            "  'logloss': 0.5397801553442397,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.17482829093933105,\n",
            "  'result': 0.8020822923791593,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'higgs',\n",
            "  'training_duration': 495.1221625804901,\n",
            "  'utc': '2021-02-04T17:03:35',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.higgs.0.TabNet executed in 525.801 seconds.\n",
            "\n",
            "-----------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.higgs.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task higgs.\n",
            "Assigning 7053 MB (total=13021 MB) for new higgs task.\n",
            "Running task higgs on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='higgs', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7053, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.68843 | val_0_auc: 0.56026 | val_1_auc: 0.56286 |  0:00:05s\n",
            "epoch 1  | loss: 0.6462  | val_0_auc: 0.63103 | val_1_auc: 0.63169 |  0:00:11s\n",
            "epoch 2  | loss: 0.63472 | val_0_auc: 0.692   | val_1_auc: 0.69025 |  0:00:17s\n",
            "epoch 3  | loss: 0.62476 | val_0_auc: 0.71302 | val_1_auc: 0.71141 |  0:00:23s\n",
            "epoch 4  | loss: 0.61664 | val_0_auc: 0.72343 | val_1_auc: 0.71602 |  0:00:28s\n",
            "epoch 5  | loss: 0.61155 | val_0_auc: 0.72956 | val_1_auc: 0.72263 |  0:00:34s\n",
            "epoch 6  | loss: 0.61079 | val_0_auc: 0.72005 | val_1_auc: 0.71822 |  0:00:40s\n",
            "epoch 7  | loss: 0.61297 | val_0_auc: 0.73427 | val_1_auc: 0.73199 |  0:00:45s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 30.0%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 8  | loss: 0.60925 | val_0_auc: 0.73982 | val_1_auc: 0.73542 |  0:00:51s\n",
            "epoch 9  | loss: 0.59811 | val_0_auc: 0.75658 | val_1_auc: 0.74802 |  0:00:57s\n",
            "epoch 10 | loss: 0.58772 | val_0_auc: 0.76895 | val_1_auc: 0.76028 |  0:01:02s\n",
            "epoch 11 | loss: 0.57986 | val_0_auc: 0.77341 | val_1_auc: 0.76576 |  0:01:08s\n",
            "epoch 12 | loss: 0.57637 | val_0_auc: 0.77556 | val_1_auc: 0.76958 |  0:01:14s\n",
            "epoch 13 | loss: 0.57411 | val_0_auc: 0.77148 | val_1_auc: 0.76618 |  0:01:19s\n",
            "epoch 14 | loss: 0.57169 | val_0_auc: 0.77695 | val_1_auc: 0.76852 |  0:01:25s\n",
            "epoch 15 | loss: 0.57069 | val_0_auc: 0.78089 | val_1_auc: 0.77364 |  0:01:31s\n",
            "epoch 16 | loss: 0.56874 | val_0_auc: 0.78185 | val_1_auc: 0.77187 |  0:01:36s\n",
            "epoch 17 | loss: 0.56652 | val_0_auc: 0.78368 | val_1_auc: 0.7765  |  0:01:42s\n",
            "epoch 18 | loss: 0.56629 | val_0_auc: 0.78387 | val_1_auc: 0.77431 |  0:01:48s\n",
            "epoch 19 | loss: 0.5653  | val_0_auc: 0.78641 | val_1_auc: 0.77655 |  0:01:53s\n",
            "epoch 20 | loss: 0.56145 | val_0_auc: 0.78353 | val_1_auc: 0.77428 |  0:01:59s\n",
            "epoch 21 | loss: 0.56103 | val_0_auc: 0.78944 | val_1_auc: 0.77858 |  0:02:05s\n",
            "epoch 22 | loss: 0.56089 | val_0_auc: 0.79046 | val_1_auc: 0.78048 |  0:02:10s\n",
            "epoch 23 | loss: 0.56086 | val_0_auc: 0.79175 | val_1_auc: 0.78217 |  0:02:16s\n",
            "epoch 24 | loss: 0.55844 | val_0_auc: 0.7933  | val_1_auc: 0.78473 |  0:02:22s\n",
            "epoch 25 | loss: 0.55675 | val_0_auc: 0.79357 | val_1_auc: 0.78628 |  0:02:27s\n",
            "epoch 26 | loss: 0.55361 | val_0_auc: 0.79671 | val_1_auc: 0.78778 |  0:02:33s\n",
            "epoch 27 | loss: 0.55162 | val_0_auc: 0.79636 | val_1_auc: 0.7889  |  0:02:39s\n",
            "epoch 28 | loss: 0.55529 | val_0_auc: 0.79451 | val_1_auc: 0.78552 |  0:02:44s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 30.2%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 29 | loss: 0.55043 | val_0_auc: 0.79848 | val_1_auc: 0.7891  |  0:02:50s\n",
            "epoch 30 | loss: 0.55135 | val_0_auc: 0.79766 | val_1_auc: 0.78738 |  0:02:56s\n",
            "epoch 31 | loss: 0.5503  | val_0_auc: 0.79952 | val_1_auc: 0.78726 |  0:03:01s\n",
            "epoch 32 | loss: 0.54816 | val_0_auc: 0.80133 | val_1_auc: 0.79161 |  0:03:07s\n",
            "epoch 33 | loss: 0.54523 | val_0_auc: 0.80147 | val_1_auc: 0.79086 |  0:03:13s\n",
            "epoch 34 | loss: 0.54653 | val_0_auc: 0.80263 | val_1_auc: 0.79156 |  0:03:18s\n",
            "epoch 35 | loss: 0.54521 | val_0_auc: 0.80516 | val_1_auc: 0.79356 |  0:03:24s\n",
            "epoch 36 | loss: 0.54464 | val_0_auc: 0.80461 | val_1_auc: 0.7963  |  0:03:30s\n",
            "epoch 37 | loss: 0.54298 | val_0_auc: 0.80327 | val_1_auc: 0.79215 |  0:03:35s\n",
            "epoch 38 | loss: 0.54394 | val_0_auc: 0.80747 | val_1_auc: 0.79509 |  0:03:41s\n",
            "epoch 39 | loss: 0.54107 | val_0_auc: 0.8073  | val_1_auc: 0.79633 |  0:03:47s\n",
            "epoch 40 | loss: 0.54142 | val_0_auc: 0.80684 | val_1_auc: 0.79655 |  0:03:52s\n",
            "epoch 41 | loss: 0.54052 | val_0_auc: 0.80841 | val_1_auc: 0.79791 |  0:03:58s\n",
            "epoch 42 | loss: 0.53989 | val_0_auc: 0.80821 | val_1_auc: 0.79884 |  0:04:04s\n",
            "epoch 43 | loss: 0.53854 | val_0_auc: 0.81023 | val_1_auc: 0.79612 |  0:04:09s\n",
            "epoch 44 | loss: 0.53823 | val_0_auc: 0.80858 | val_1_auc: 0.79614 |  0:04:15s\n",
            "epoch 45 | loss: 0.53791 | val_0_auc: 0.80939 | val_1_auc: 0.79882 |  0:04:21s\n",
            "epoch 46 | loss: 0.53786 | val_0_auc: 0.8092  | val_1_auc: 0.79847 |  0:04:26s\n",
            "epoch 47 | loss: 0.53585 | val_0_auc: 0.80889 | val_1_auc: 0.7953  |  0:04:32s\n",
            "epoch 48 | loss: 0.5368  | val_0_auc: 0.81137 | val_1_auc: 0.79787 |  0:04:37s\n",
            "epoch 49 | loss: 0.53784 | val_0_auc: 0.81115 | val_1_auc: 0.798   |  0:04:43s\n",
            "epoch 50 | loss: 0.5354  | val_0_auc: 0.81126 | val_1_auc: 0.79544 |  0:04:49s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 31.3%\n",
            "[499] Disk Usage: 25.3%\n",
            "epoch 51 | loss: 0.5351  | val_0_auc: 0.81088 | val_1_auc: 0.79824 |  0:04:55s\n",
            "epoch 52 | loss: 0.53622 | val_0_auc: 0.8127  | val_1_auc: 0.79971 |  0:05:00s\n",
            "epoch 53 | loss: 0.53556 | val_0_auc: 0.81409 | val_1_auc: 0.80013 |  0:05:06s\n",
            "epoch 54 | loss: 0.5335  | val_0_auc: 0.81481 | val_1_auc: 0.8021  |  0:05:12s\n",
            "epoch 55 | loss: 0.53392 | val_0_auc: 0.81206 | val_1_auc: 0.79534 |  0:05:17s\n",
            "epoch 56 | loss: 0.53191 | val_0_auc: 0.81513 | val_1_auc: 0.79947 |  0:05:23s\n",
            "epoch 57 | loss: 0.53294 | val_0_auc: 0.8163  | val_1_auc: 0.79915 |  0:05:28s\n",
            "epoch 58 | loss: 0.53141 | val_0_auc: 0.81773 | val_1_auc: 0.79917 |  0:05:34s\n",
            "epoch 59 | loss: 0.53053 | val_0_auc: 0.81276 | val_1_auc: 0.79324 |  0:05:40s\n",
            "epoch 60 | loss: 0.53114 | val_0_auc: 0.81698 | val_1_auc: 0.79996 |  0:05:45s\n",
            "epoch 61 | loss: 0.53171 | val_0_auc: 0.81533 | val_1_auc: 0.79616 |  0:05:51s\n",
            "epoch 62 | loss: 0.53097 | val_0_auc: 0.81777 | val_1_auc: 0.79959 |  0:05:57s\n",
            "epoch 63 | loss: 0.53118 | val_0_auc: 0.81757 | val_1_auc: 0.79969 |  0:06:02s\n",
            "epoch 64 | loss: 0.53184 | val_0_auc: 0.81591 | val_1_auc: 0.79866 |  0:06:08s\n",
            "\n",
            "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_1_auc = 0.8021\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.595942  0.404058           0     0\n",
            "1   0.603403  0.396597           0     0\n",
            "2   0.644314  0.355686           0     0\n",
            "3   0.609484  0.390516           0     0\n",
            "4   0.740184  0.259816           0     0\n",
            "5   0.580853  0.419147           0     0\n",
            "6   0.221918  0.778082           1     0\n",
            "7   0.112913  0.887087           1     0\n",
            "8   0.530648  0.469352           0     0\n",
            "9   0.501619  0.498381           0     0\n",
            "10  0.626702  0.373298           0     0\n",
            "11  0.494459  0.505541           1     0\n",
            "12  0.530280  0.469721           0     0\n",
            "13  0.698245  0.301755           0     0\n",
            "14  0.491983  0.508017           1     0\n",
            "15  0.742481  0.257519           0     0\n",
            "16  0.884650  0.115350           0     0\n",
            "17  0.807815  0.192185           0     0\n",
            "18  0.793811  0.206189           0     0\n",
            "19  0.990489  0.009511           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/higgs/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.7214686384497705,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.8021032471258395,\n",
            "  'balacc': 0.7176261060412034,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146606',\n",
            "  'info': None,\n",
            "  'logloss': 0.5378067450230584,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.16964101791381836,\n",
            "  'result': 0.8021032471258395,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'higgs',\n",
            "  'training_duration': 370.204110622406,\n",
            "  'utc': '2021-02-04T17:09:54',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.higgs.1.TabNet executed in 378.937 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Jannis.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Jannis.\n",
            "Assigning 7086 MB (total=13021 MB) for new Jannis task.\n",
            "Running task Jannis on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Jannis', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7086, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "[499] CPU Utilization: 44.8%\n",
            "[499] Memory Usage: 30.3%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 0  | loss: 1.02959 | val_0_accuracy: 0.54607 | val_1_accuracy: 0.54574 |  0:00:04s\n",
            "epoch 1  | loss: 0.89579 | val_0_accuracy: 0.59946 | val_1_accuracy: 0.59804 |  0:00:09s\n",
            "epoch 2  | loss: 0.86202 | val_0_accuracy: 0.62716 | val_1_accuracy: 0.62551 |  0:00:14s\n",
            "epoch 3  | loss: 0.84574 | val_0_accuracy: 0.63532 | val_1_accuracy: 0.63399 |  0:00:19s\n",
            "epoch 4  | loss: 0.83835 | val_0_accuracy: 0.63682 | val_1_accuracy: 0.63446 |  0:00:24s\n",
            "epoch 5  | loss: 0.83397 | val_0_accuracy: 0.6425  | val_1_accuracy: 0.63817 |  0:00:29s\n",
            "epoch 6  | loss: 0.82517 | val_0_accuracy: 0.64823 | val_1_accuracy: 0.64258 |  0:00:33s\n",
            "epoch 7  | loss: 0.81404 | val_0_accuracy: 0.64574 | val_1_accuracy: 0.63948 |  0:00:38s\n",
            "epoch 8  | loss: 0.80805 | val_0_accuracy: 0.65469 | val_1_accuracy: 0.64557 |  0:00:43s\n",
            "epoch 9  | loss: 0.79869 | val_0_accuracy: 0.65666 | val_1_accuracy: 0.65106 |  0:00:48s\n",
            "epoch 10 | loss: 0.793   | val_0_accuracy: 0.65759 | val_1_accuracy: 0.65154 |  0:00:53s\n",
            "epoch 11 | loss: 0.78744 | val_0_accuracy: 0.66235 | val_1_accuracy: 0.65309 |  0:00:58s\n",
            "epoch 12 | loss: 0.78237 | val_0_accuracy: 0.66613 | val_1_accuracy: 0.65453 |  0:01:03s\n",
            "epoch 13 | loss: 0.78012 | val_0_accuracy: 0.67131 | val_1_accuracy: 0.66014 |  0:01:08s\n",
            "epoch 14 | loss: 0.77429 | val_0_accuracy: 0.67206 | val_1_accuracy: 0.66408 |  0:01:13s\n",
            "epoch 15 | loss: 0.76765 | val_0_accuracy: 0.67336 | val_1_accuracy: 0.66551 |  0:01:18s\n",
            "epoch 16 | loss: 0.76181 | val_0_accuracy: 0.68106 | val_1_accuracy: 0.67399 |  0:01:23s\n",
            "epoch 17 | loss: 0.75762 | val_0_accuracy: 0.68511 | val_1_accuracy: 0.67471 |  0:01:27s\n",
            "epoch 18 | loss: 0.7538  | val_0_accuracy: 0.68515 | val_1_accuracy: 0.67757 |  0:01:32s\n",
            "epoch 19 | loss: 0.7503  | val_0_accuracy: 0.68966 | val_1_accuracy: 0.6851  |  0:01:37s\n",
            "epoch 20 | loss: 0.74714 | val_0_accuracy: 0.68746 | val_1_accuracy: 0.68199 |  0:01:42s\n",
            "epoch 21 | loss: 0.74511 | val_0_accuracy: 0.69351 | val_1_accuracy: 0.68808 |  0:01:47s\n",
            "epoch 22 | loss: 0.73951 | val_0_accuracy: 0.69344 | val_1_accuracy: 0.68963 |  0:01:52s\n",
            "epoch 23 | loss: 0.73905 | val_0_accuracy: 0.69413 | val_1_accuracy: 0.68952 |  0:01:57s\n",
            "epoch 24 | loss: 0.73614 | val_0_accuracy: 0.70146 | val_1_accuracy: 0.69489 |  0:02:02s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 31.5%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 25 | loss: 0.73406 | val_0_accuracy: 0.70257 | val_1_accuracy: 0.6888  |  0:02:06s\n",
            "epoch 26 | loss: 0.72899 | val_0_accuracy: 0.69775 | val_1_accuracy: 0.69489 |  0:02:11s\n",
            "epoch 27 | loss: 0.72817 | val_0_accuracy: 0.70475 | val_1_accuracy: 0.70134 |  0:02:16s\n",
            "epoch 28 | loss: 0.72537 | val_0_accuracy: 0.7033  | val_1_accuracy: 0.6962  |  0:02:21s\n",
            "epoch 29 | loss: 0.72523 | val_0_accuracy: 0.70631 | val_1_accuracy: 0.70002 |  0:02:26s\n",
            "epoch 30 | loss: 0.72323 | val_0_accuracy: 0.70426 | val_1_accuracy: 0.69489 |  0:02:31s\n",
            "epoch 31 | loss: 0.72718 | val_0_accuracy: 0.70642 | val_1_accuracy: 0.69764 |  0:02:36s\n",
            "epoch 32 | loss: 0.72334 | val_0_accuracy: 0.70579 | val_1_accuracy: 0.69608 |  0:02:40s\n",
            "epoch 33 | loss: 0.71993 | val_0_accuracy: 0.70712 | val_1_accuracy: 0.70074 |  0:02:45s\n",
            "epoch 34 | loss: 0.71813 | val_0_accuracy: 0.70836 | val_1_accuracy: 0.6999  |  0:02:50s\n",
            "epoch 35 | loss: 0.71738 | val_0_accuracy: 0.71332 | val_1_accuracy: 0.70456 |  0:02:55s\n",
            "epoch 36 | loss: 0.7164  | val_0_accuracy: 0.70688 | val_1_accuracy: 0.69764 |  0:03:00s\n",
            "epoch 37 | loss: 0.72764 | val_0_accuracy: 0.70579 | val_1_accuracy: 0.69799 |  0:03:04s\n",
            "epoch 38 | loss: 0.71815 | val_0_accuracy: 0.71023 | val_1_accuracy: 0.70217 |  0:03:09s\n",
            "epoch 39 | loss: 0.71726 | val_0_accuracy: 0.71142 | val_1_accuracy: 0.70444 |  0:03:14s\n",
            "epoch 40 | loss: 0.71531 | val_0_accuracy: 0.70748 | val_1_accuracy: 0.69895 |  0:03:19s\n",
            "epoch 41 | loss: 0.71144 | val_0_accuracy: 0.71017 | val_1_accuracy: 0.70444 |  0:03:24s\n",
            "epoch 42 | loss: 0.71752 | val_0_accuracy: 0.70641 | val_1_accuracy: 0.69967 |  0:03:29s\n",
            "epoch 43 | loss: 0.71082 | val_0_accuracy: 0.714   | val_1_accuracy: 0.70373 |  0:03:34s\n",
            "epoch 44 | loss: 0.70731 | val_0_accuracy: 0.71524 | val_1_accuracy: 0.7091  |  0:03:38s\n",
            "epoch 45 | loss: 0.71114 | val_0_accuracy: 0.71392 | val_1_accuracy: 0.70277 |  0:03:43s\n",
            "epoch 46 | loss: 0.71241 | val_0_accuracy: 0.7121  | val_1_accuracy: 0.70516 |  0:03:48s\n",
            "epoch 47 | loss: 0.70937 | val_0_accuracy: 0.71412 | val_1_accuracy: 0.70396 |  0:03:53s\n",
            "epoch 48 | loss: 0.70762 | val_0_accuracy: 0.71531 | val_1_accuracy: 0.70564 |  0:03:58s\n",
            "epoch 49 | loss: 0.70583 | val_0_accuracy: 0.71571 | val_1_accuracy: 0.70492 |  0:04:03s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 32.9%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 50 | loss: 0.70384 | val_0_accuracy: 0.71816 | val_1_accuracy: 0.70767 |  0:04:08s\n",
            "epoch 51 | loss: 0.70344 | val_0_accuracy: 0.70761 | val_1_accuracy: 0.69823 |  0:04:12s\n",
            "epoch 52 | loss: 0.70371 | val_0_accuracy: 0.7177  | val_1_accuracy: 0.70719 |  0:04:17s\n",
            "epoch 53 | loss: 0.70322 | val_0_accuracy: 0.7186  | val_1_accuracy: 0.70826 |  0:04:22s\n",
            "epoch 54 | loss: 0.70169 | val_0_accuracy: 0.71954 | val_1_accuracy: 0.70886 |  0:04:27s\n",
            "\n",
            "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_1_accuracy = 0.7091\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3 predictions truth\n",
            "0   0.002820  0.152606  0.810306  0.034268           2     2\n",
            "1   0.036597  0.587021  0.254099  0.122283           1     2\n",
            "2   0.048516  0.190888  0.027549  0.733048           3     2\n",
            "3   0.098974  0.155670  0.668528  0.076828           2     2\n",
            "4   0.007267  0.216361  0.749248  0.027124           2     2\n",
            "5   0.002586  0.058289  0.926844  0.012281           2     2\n",
            "6   0.018046  0.146599  0.804274  0.031081           2     2\n",
            "7   0.007013  0.686224  0.062792  0.243971           1     2\n",
            "8   0.117437  0.205165  0.566358  0.111041           2     2\n",
            "9   0.031058  0.323044  0.573729  0.072169           2     2\n",
            "10  0.002891  0.180868  0.780180  0.036062           2     2\n",
            "11  0.107003  0.299811  0.488959  0.104227           2     2\n",
            "12  0.015167  0.590619  0.299362  0.094853           1     2\n",
            "13  0.043389  0.359271  0.492757  0.104583           2     2\n",
            "14  0.010173  0.526525  0.383987  0.079315           1     2\n",
            "15  0.009045  0.481206  0.356631  0.153118           1     2\n",
            "16  0.005430  0.731501  0.211638  0.051431           1     2\n",
            "17  0.030489  0.361756  0.436387  0.171368           2     2\n",
            "18  0.027005  0.252653  0.601543  0.118799           2     2\n",
            "19  0.011506  0.115421  0.850929  0.022144           2     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.7090995939813709,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.524639158847596,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168330',\n",
            "  'info': None,\n",
            "  'logloss': 0.711791164723046,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.15030264854431152,\n",
            "  'result': 0.711791164723046,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Jannis',\n",
            "  'training_duration': 268.96985268592834,\n",
            "  'utc': '2021-02-04T17:14:59',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Jannis.0.TabNet executed in 305.092 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Jannis.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Jannis.\n",
            "Assigning 6721 MB (total=13021 MB) for new Jannis task.\n",
            "Running task Jannis on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Jannis', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6721, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.02504 | val_0_accuracy: 0.54696 | val_1_accuracy: 0.55266 |  0:00:04s\n",
            "epoch 1  | loss: 0.89773 | val_0_accuracy: 0.59324 | val_1_accuracy: 0.58885 |  0:00:09s\n",
            "epoch 2  | loss: 0.86903 | val_0_accuracy: 0.62554 | val_1_accuracy: 0.63172 |  0:00:14s\n",
            "epoch 3  | loss: 0.84122 | val_0_accuracy: 0.64527 | val_1_accuracy: 0.65429 |  0:00:19s\n",
            "epoch 4  | loss: 0.82361 | val_0_accuracy: 0.65396 | val_1_accuracy: 0.66109 |  0:00:24s\n",
            "epoch 5  | loss: 0.80682 | val_0_accuracy: 0.6648  | val_1_accuracy: 0.66778 |  0:00:29s\n",
            "epoch 6  | loss: 0.79393 | val_0_accuracy: 0.66879 | val_1_accuracy: 0.66766 |  0:00:34s\n",
            "epoch 7  | loss: 0.78241 | val_0_accuracy: 0.66686 | val_1_accuracy: 0.67256 |  0:00:39s\n",
            "epoch 8  | loss: 0.77532 | val_0_accuracy: 0.67679 | val_1_accuracy: 0.67483 |  0:00:44s\n",
            "epoch 9  | loss: 0.76581 | val_0_accuracy: 0.68141 | val_1_accuracy: 0.68354 |  0:00:48s\n",
            "epoch 10 | loss: 0.76014 | val_0_accuracy: 0.6857  | val_1_accuracy: 0.68689 |  0:00:53s\n",
            "epoch 11 | loss: 0.75431 | val_0_accuracy: 0.68793 | val_1_accuracy: 0.69465 |  0:00:58s\n",
            "epoch 12 | loss: 0.7479  | val_0_accuracy: 0.69324 | val_1_accuracy: 0.69286 |  0:01:03s\n",
            "epoch 13 | loss: 0.74372 | val_0_accuracy: 0.69566 | val_1_accuracy: 0.69274 |  0:01:08s\n",
            "epoch 14 | loss: 0.74102 | val_0_accuracy: 0.69647 | val_1_accuracy: 0.69537 |  0:01:13s\n",
            "epoch 15 | loss: 0.7365  | val_0_accuracy: 0.69878 | val_1_accuracy: 0.69823 |  0:01:18s\n",
            "[499] CPU Utilization: 51.7%\n",
            "[499] Memory Usage: 34.2%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 16 | loss: 0.73397 | val_0_accuracy: 0.70357 | val_1_accuracy: 0.70588 |  0:01:23s\n",
            "epoch 17 | loss: 0.73214 | val_0_accuracy: 0.70248 | val_1_accuracy: 0.70205 |  0:01:28s\n",
            "epoch 18 | loss: 0.72957 | val_0_accuracy: 0.70411 | val_1_accuracy: 0.70205 |  0:01:33s\n",
            "epoch 19 | loss: 0.72704 | val_0_accuracy: 0.70741 | val_1_accuracy: 0.70838 |  0:01:38s\n",
            "epoch 20 | loss: 0.72414 | val_0_accuracy: 0.70427 | val_1_accuracy: 0.70349 |  0:01:42s\n",
            "epoch 21 | loss: 0.72143 | val_0_accuracy: 0.70755 | val_1_accuracy: 0.70528 |  0:01:47s\n",
            "epoch 22 | loss: 0.72199 | val_0_accuracy: 0.7085  | val_1_accuracy: 0.70564 |  0:01:52s\n",
            "epoch 23 | loss: 0.71947 | val_0_accuracy: 0.7102  | val_1_accuracy: 0.70731 |  0:01:57s\n",
            "epoch 24 | loss: 0.71872 | val_0_accuracy: 0.71311 | val_1_accuracy: 0.7097  |  0:02:02s\n",
            "epoch 25 | loss: 0.71686 | val_0_accuracy: 0.71185 | val_1_accuracy: 0.70767 |  0:02:07s\n",
            "epoch 26 | loss: 0.71266 | val_0_accuracy: 0.71138 | val_1_accuracy: 0.70802 |  0:02:11s\n",
            "epoch 27 | loss: 0.71424 | val_0_accuracy: 0.71197 | val_1_accuracy: 0.71292 |  0:02:16s\n",
            "epoch 28 | loss: 0.71222 | val_0_accuracy: 0.71719 | val_1_accuracy: 0.7128  |  0:02:21s\n",
            "epoch 29 | loss: 0.71013 | val_0_accuracy: 0.7139  | val_1_accuracy: 0.71077 |  0:02:26s\n",
            "epoch 30 | loss: 0.70971 | val_0_accuracy: 0.7156  | val_1_accuracy: 0.71435 |  0:02:31s\n",
            "epoch 31 | loss: 0.70827 | val_0_accuracy: 0.71726 | val_1_accuracy: 0.71232 |  0:02:36s\n",
            "epoch 32 | loss: 0.70818 | val_0_accuracy: 0.71831 | val_1_accuracy: 0.71459 |  0:02:40s\n",
            "epoch 33 | loss: 0.70659 | val_0_accuracy: 0.71899 | val_1_accuracy: 0.71794 |  0:02:45s\n",
            "epoch 34 | loss: 0.7057  | val_0_accuracy: 0.71721 | val_1_accuracy: 0.71698 |  0:02:50s\n",
            "epoch 35 | loss: 0.70301 | val_0_accuracy: 0.7167  | val_1_accuracy: 0.71507 |  0:02:55s\n",
            "epoch 36 | loss: 0.70376 | val_0_accuracy: 0.72255 | val_1_accuracy: 0.71638 |  0:03:00s\n",
            "epoch 37 | loss: 0.70174 | val_0_accuracy: 0.71936 | val_1_accuracy: 0.71185 |  0:03:05s\n",
            "epoch 38 | loss: 0.70012 | val_0_accuracy: 0.72141 | val_1_accuracy: 0.71579 |  0:03:10s\n",
            "epoch 39 | loss: 0.70002 | val_0_accuracy: 0.72123 | val_1_accuracy: 0.71925 |  0:03:14s\n",
            "epoch 40 | loss: 0.69998 | val_0_accuracy: 0.71783 | val_1_accuracy: 0.71041 |  0:03:19s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 34.2%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 41 | loss: 0.69691 | val_0_accuracy: 0.72306 | val_1_accuracy: 0.7214  |  0:03:24s\n",
            "epoch 42 | loss: 0.69641 | val_0_accuracy: 0.72457 | val_1_accuracy: 0.71674 |  0:03:29s\n",
            "epoch 43 | loss: 0.69418 | val_0_accuracy: 0.72469 | val_1_accuracy: 0.7134  |  0:03:34s\n",
            "epoch 44 | loss: 0.69239 | val_0_accuracy: 0.72452 | val_1_accuracy: 0.72044 |  0:03:39s\n",
            "epoch 45 | loss: 0.69096 | val_0_accuracy: 0.72537 | val_1_accuracy: 0.72021 |  0:03:44s\n",
            "epoch 46 | loss: 0.69178 | val_0_accuracy: 0.7246  | val_1_accuracy: 0.71877 |  0:03:48s\n",
            "epoch 47 | loss: 0.68744 | val_0_accuracy: 0.72431 | val_1_accuracy: 0.71591 |  0:03:53s\n",
            "epoch 48 | loss: 0.68708 | val_0_accuracy: 0.72806 | val_1_accuracy: 0.72188 |  0:03:58s\n",
            "epoch 49 | loss: 0.68783 | val_0_accuracy: 0.72796 | val_1_accuracy: 0.71829 |  0:04:03s\n",
            "epoch 50 | loss: 0.6875  | val_0_accuracy: 0.72859 | val_1_accuracy: 0.71925 |  0:04:08s\n",
            "epoch 51 | loss: 0.68373 | val_0_accuracy: 0.72975 | val_1_accuracy: 0.72044 |  0:04:12s\n",
            "epoch 52 | loss: 0.68487 | val_0_accuracy: 0.72786 | val_1_accuracy: 0.72032 |  0:04:17s\n",
            "epoch 53 | loss: 0.68485 | val_0_accuracy: 0.73021 | val_1_accuracy: 0.72403 |  0:04:22s\n",
            "epoch 54 | loss: 0.68293 | val_0_accuracy: 0.73279 | val_1_accuracy: 0.72558 |  0:04:27s\n",
            "epoch 55 | loss: 0.68277 | val_0_accuracy: 0.73008 | val_1_accuracy: 0.72247 |  0:04:32s\n",
            "epoch 56 | loss: 0.68122 | val_0_accuracy: 0.7322  | val_1_accuracy: 0.71949 |  0:04:37s\n",
            "epoch 57 | loss: 0.68173 | val_0_accuracy: 0.73204 | val_1_accuracy: 0.722   |  0:04:41s\n",
            "epoch 58 | loss: 0.68031 | val_0_accuracy: 0.72989 | val_1_accuracy: 0.72247 |  0:04:46s\n",
            "epoch 59 | loss: 0.67921 | val_0_accuracy: 0.73245 | val_1_accuracy: 0.72152 |  0:04:51s\n",
            "epoch 60 | loss: 0.67985 | val_0_accuracy: 0.73251 | val_1_accuracy: 0.72152 |  0:04:56s\n",
            "epoch 61 | loss: 0.6792  | val_0_accuracy: 0.72996 | val_1_accuracy: 0.71997 |  0:05:01s\n",
            "epoch 62 | loss: 0.67955 | val_0_accuracy: 0.72984 | val_1_accuracy: 0.72009 |  0:05:05s\n",
            "epoch 63 | loss: 0.67845 | val_0_accuracy: 0.72891 | val_1_accuracy: 0.71531 |  0:05:10s\n",
            "epoch 64 | loss: 0.67795 | val_0_accuracy: 0.73505 | val_1_accuracy: 0.7214  |  0:05:15s\n",
            "\n",
            "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_1_accuracy = 0.72558\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3 predictions truth\n",
            "0   0.008869  0.676660  0.023409  0.291062           1     2\n",
            "1   0.060763  0.337413  0.210264  0.391559           3     2\n",
            "2   0.010243  0.233214  0.702542  0.054001           2     2\n",
            "3   0.009816  0.180851  0.773373  0.035960           2     2\n",
            "4   0.007795  0.665917  0.225273  0.101015           1     2\n",
            "5   0.040211  0.423041  0.045750  0.490998           3     2\n",
            "6   0.012674  0.126051  0.808735  0.052539           2     2\n",
            "7   0.007032  0.327590  0.582800  0.082577           2     2\n",
            "8   0.003835  0.495974  0.427380  0.072811           1     2\n",
            "9   0.010034  0.184750  0.757384  0.047832           2     2\n",
            "10  0.000245  0.218324  0.742803  0.038627           2     2\n",
            "11  0.005864  0.062430  0.909254  0.022451           2     2\n",
            "12  0.007612  0.669738  0.212348  0.110302           1     2\n",
            "13  0.003731  0.038910  0.946644  0.010715           2     2\n",
            "14  0.009338  0.373483  0.573639  0.043541           2     2\n",
            "15  0.010517  0.154943  0.791660  0.042879           2     2\n",
            "16  0.030226  0.114087  0.817196  0.038491           2     2\n",
            "17  0.083919  0.253811  0.531698  0.130571           2     2\n",
            "18  0.038144  0.492641  0.121075  0.348141           1     2\n",
            "19  0.007756  0.158628  0.786471  0.047145           2     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Jannis/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.7255791736326725,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.5456499716641279,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168330',\n",
            "  'info': None,\n",
            "  'logloss': 0.6891998771404615,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.15430426597595215,\n",
            "  'result': 0.6891998771404615,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Jannis',\n",
            "  'training_duration': 317.2645962238312,\n",
            "  'utc': '2021-02-04T17:20:28',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Jannis.1.TabNet executed in 329.387 seconds.\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.jungle_chess_2pcs_raw_endgame_complete.0.TabNet.\n",
            "[499] CPU Utilization: 49.1%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 25.4%\n",
            "Assigning 2 cores (total=2) for new task jungle_chess_2pcs_raw_endgame_complete.\n",
            "Assigning 6571 MB (total=13021 MB) for new jungle_chess_2pcs_raw_endgame_complete task.\n",
            "Running task jungle_chess_2pcs_raw_endgame_complete on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='jungle_chess_2pcs_raw_endgame_complete', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6571, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.73499 | val_0_accuracy: 0.52956 | val_1_accuracy: 0.5241  |  0:00:02s\n",
            "epoch 1  | loss: 0.57228 | val_0_accuracy: 0.61477 | val_1_accuracy: 0.6158  |  0:00:05s\n",
            "epoch 2  | loss: 0.51102 | val_0_accuracy: 0.65258 | val_1_accuracy: 0.6544  |  0:00:07s\n",
            "epoch 3  | loss: 0.46659 | val_0_accuracy: 0.69442 | val_1_accuracy: 0.7008  |  0:00:10s\n",
            "epoch 4  | loss: 0.44607 | val_0_accuracy: 0.75975 | val_1_accuracy: 0.76417 |  0:00:13s\n",
            "epoch 5  | loss: 0.42713 | val_0_accuracy: 0.78243 | val_1_accuracy: 0.77867 |  0:00:15s\n",
            "epoch 6  | loss: 0.41213 | val_0_accuracy: 0.79738 | val_1_accuracy: 0.7934  |  0:00:18s\n",
            "epoch 7  | loss: 0.40605 | val_0_accuracy: 0.80928 | val_1_accuracy: 0.80901 |  0:00:20s\n",
            "epoch 8  | loss: 0.40029 | val_0_accuracy: 0.82574 | val_1_accuracy: 0.81392 |  0:00:23s\n",
            "epoch 9  | loss: 0.39194 | val_0_accuracy: 0.8399  | val_1_accuracy: 0.82597 |  0:00:25s\n",
            "epoch 10 | loss: 0.3857  | val_0_accuracy: 0.81898 | val_1_accuracy: 0.81437 |  0:00:28s\n",
            "epoch 11 | loss: 0.38921 | val_0_accuracy: 0.84446 | val_1_accuracy: 0.83378 |  0:00:31s\n",
            "epoch 12 | loss: 0.37936 | val_0_accuracy: 0.84508 | val_1_accuracy: 0.83824 |  0:00:33s\n",
            "epoch 13 | loss: 0.38143 | val_0_accuracy: 0.84414 | val_1_accuracy: 0.83311 |  0:00:36s\n",
            "epoch 14 | loss: 0.37143 | val_0_accuracy: 0.84463 | val_1_accuracy: 0.83713 |  0:00:38s\n",
            "epoch 15 | loss: 0.37268 | val_0_accuracy: 0.82946 | val_1_accuracy: 0.82485 |  0:00:41s\n",
            "epoch 16 | loss: 0.37143 | val_0_accuracy: 0.85108 | val_1_accuracy: 0.8465  |  0:00:43s\n",
            "epoch 17 | loss: 0.36506 | val_0_accuracy: 0.85534 | val_1_accuracy: 0.85007 |  0:00:46s\n",
            "epoch 18 | loss: 0.35682 | val_0_accuracy: 0.84691 | val_1_accuracy: 0.84494 |  0:00:49s\n",
            "epoch 19 | loss: 0.35352 | val_0_accuracy: 0.82572 | val_1_accuracy: 0.81816 |  0:00:51s\n",
            "epoch 20 | loss: 0.3545  | val_0_accuracy: 0.85936 | val_1_accuracy: 0.85676 |  0:00:54s\n",
            "epoch 21 | loss: 0.34456 | val_0_accuracy: 0.84947 | val_1_accuracy: 0.84694 |  0:00:56s\n",
            "epoch 22 | loss: 0.34535 | val_0_accuracy: 0.8605  | val_1_accuracy: 0.85788 |  0:00:59s\n",
            "epoch 23 | loss: 0.33982 | val_0_accuracy: 0.85958 | val_1_accuracy: 0.85966 |  0:01:02s\n",
            "epoch 24 | loss: 0.33908 | val_0_accuracy: 0.85978 | val_1_accuracy: 0.85341 |  0:01:04s\n",
            "epoch 25 | loss: 0.32647 | val_0_accuracy: 0.85599 | val_1_accuracy: 0.85498 |  0:01:07s\n",
            "epoch 26 | loss: 0.33259 | val_0_accuracy: 0.85904 | val_1_accuracy: 0.85654 |  0:01:09s\n",
            "epoch 27 | loss: 0.33135 | val_0_accuracy: 0.85277 | val_1_accuracy: 0.84761 |  0:01:12s\n",
            "epoch 28 | loss: 0.33175 | val_0_accuracy: 0.8632  | val_1_accuracy: 0.85453 |  0:01:15s\n",
            "epoch 29 | loss: 0.32396 | val_0_accuracy: 0.86568 | val_1_accuracy: 0.85609 |  0:01:17s\n",
            "epoch 30 | loss: 0.31928 | val_0_accuracy: 0.86229 | val_1_accuracy: 0.85564 |  0:01:20s\n",
            "epoch 31 | loss: 0.32492 | val_0_accuracy: 0.86075 | val_1_accuracy: 0.85207 |  0:01:22s\n",
            "epoch 32 | loss: 0.32475 | val_0_accuracy: 0.86045 | val_1_accuracy: 0.85431 |  0:01:25s\n",
            "epoch 33 | loss: 0.31962 | val_0_accuracy: 0.86474 | val_1_accuracy: 0.84984 |  0:01:27s\n",
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_1_accuracy = 0.85966\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "                b             d         w predictions truth\n",
            "0   2.825918e-01  1.643629e-01  0.553045           w     w\n",
            "1   2.783199e-01  5.642448e-02  0.665256           w     w\n",
            "2   2.111101e-02  2.464227e-03  0.976425           w     w\n",
            "3   6.877590e-02  1.342858e-02  0.917796           w     w\n",
            "4   1.949230e-02  2.131797e-01  0.767328           w     w\n",
            "5   5.839175e-01  4.904983e-02  0.367033           b     w\n",
            "6   5.235563e-07  7.109339e-09  1.000000           w     w\n",
            "7   4.207361e-01  1.461426e-04  0.579118           w     w\n",
            "8   5.374447e-08  2.644916e-11  1.000000           w     w\n",
            "9   1.236730e-03  4.109534e-05  0.998722           w     w\n",
            "10  1.362370e-04  1.149134e-07  0.999864           w     w\n",
            "11  6.110619e-05  1.418827e-07  0.999939           w     w\n",
            "12  3.372369e-01  8.131322e-04  0.661950           w     w\n",
            "13  3.903901e-06  9.505364e-10  0.999996           w     w\n",
            "14  8.546829e-01  2.855364e-02  0.116763           b     w\n",
            "15  2.323797e-03  1.015027e-05  0.997666           w     w\n",
            "16  1.085338e-01  1.077316e-04  0.891358           w     w\n",
            "17  9.808939e-01  3.900840e-05  0.019067           b     w\n",
            "18  3.641435e-05  3.384573e-09  0.999964           w     w\n",
            "19  2.359898e-02  3.649095e-07  0.976401           w     w\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.859660865684962,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.8007219154704623,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/167119',\n",
            "  'info': None,\n",
            "  'logloss': 0.32744936861245655,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.08762288093566895,\n",
            "  'result': 0.32744936861245655,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'jungle_chess_2pcs_raw_endgame_complete',\n",
            "  'training_duration': 88.77503275871277,\n",
            "  'utc': '2021-02-04T17:22:11',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.jungle_chess_2pcs_raw_endgame_complete.0.TabNet executed in 103.018 seconds.\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.jungle_chess_2pcs_raw_endgame_complete.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task jungle_chess_2pcs_raw_endgame_complete.\n",
            "Assigning 6571 MB (total=13021 MB) for new jungle_chess_2pcs_raw_endgame_complete task.\n",
            "Running task jungle_chess_2pcs_raw_endgame_complete on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='jungle_chess_2pcs_raw_endgame_complete', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6571, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.74413 | val_0_accuracy: 0.55582 | val_1_accuracy: 0.55176 |  0:00:02s\n",
            "epoch 1  | loss: 0.57781 | val_0_accuracy: 0.64764 | val_1_accuracy: 0.64569 |  0:00:05s\n",
            "epoch 2  | loss: 0.52841 | val_0_accuracy: 0.67102 | val_1_accuracy: 0.66488 |  0:00:07s\n",
            "epoch 3  | loss: 0.48338 | val_0_accuracy: 0.71051 | val_1_accuracy: 0.71307 |  0:00:10s\n",
            "epoch 4  | loss: 0.47102 | val_0_accuracy: 0.76101 | val_1_accuracy: 0.76439 |  0:00:12s\n",
            "epoch 5  | loss: 0.45338 | val_0_accuracy: 0.78598 | val_1_accuracy: 0.78179 |  0:00:15s\n",
            "epoch 6  | loss: 0.43229 | val_0_accuracy: 0.8131  | val_1_accuracy: 0.80723 |  0:00:18s\n",
            "epoch 7  | loss: 0.42084 | val_0_accuracy: 0.82101 | val_1_accuracy: 0.81258 |  0:00:20s\n",
            "[499] CPU Utilization: 49.4%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 8  | loss: 0.41087 | val_0_accuracy: 0.80435 | val_1_accuracy: 0.80143 |  0:00:23s\n",
            "epoch 9  | loss: 0.39977 | val_0_accuracy: 0.84714 | val_1_accuracy: 0.83445 |  0:00:25s\n",
            "epoch 10 | loss: 0.38559 | val_0_accuracy: 0.83568 | val_1_accuracy: 0.83043 |  0:00:28s\n",
            "epoch 11 | loss: 0.37887 | val_0_accuracy: 0.83839 | val_1_accuracy: 0.82686 |  0:00:30s\n",
            "epoch 12 | loss: 0.36655 | val_0_accuracy: 0.84426 | val_1_accuracy: 0.83088 |  0:00:33s\n",
            "epoch 13 | loss: 0.36653 | val_0_accuracy: 0.85088 | val_1_accuracy: 0.83802 |  0:00:36s\n",
            "epoch 14 | loss: 0.36382 | val_0_accuracy: 0.84724 | val_1_accuracy: 0.8378  |  0:00:38s\n",
            "epoch 15 | loss: 0.36872 | val_0_accuracy: 0.85532 | val_1_accuracy: 0.84761 |  0:00:41s\n",
            "epoch 16 | loss: 0.3553  | val_0_accuracy: 0.85108 | val_1_accuracy: 0.83668 |  0:00:43s\n",
            "epoch 17 | loss: 0.35076 | val_0_accuracy: 0.85376 | val_1_accuracy: 0.8456  |  0:00:46s\n",
            "epoch 18 | loss: 0.35318 | val_0_accuracy: 0.85081 | val_1_accuracy: 0.83735 |  0:00:48s\n",
            "epoch 19 | loss: 0.34631 | val_0_accuracy: 0.82944 | val_1_accuracy: 0.82798 |  0:00:51s\n",
            "epoch 20 | loss: 0.34553 | val_0_accuracy: 0.86243 | val_1_accuracy: 0.84851 |  0:00:53s\n",
            "epoch 21 | loss: 0.33933 | val_0_accuracy: 0.85591 | val_1_accuracy: 0.84828 |  0:00:56s\n",
            "epoch 22 | loss: 0.3413  | val_0_accuracy: 0.85549 | val_1_accuracy: 0.84003 |  0:00:59s\n",
            "epoch 23 | loss: 0.34168 | val_0_accuracy: 0.86261 | val_1_accuracy: 0.84806 |  0:01:01s\n",
            "epoch 24 | loss: 0.33254 | val_0_accuracy: 0.85733 | val_1_accuracy: 0.85141 |  0:01:04s\n",
            "epoch 25 | loss: 0.32705 | val_0_accuracy: 0.85668 | val_1_accuracy: 0.84917 |  0:01:06s\n",
            "epoch 26 | loss: 0.33207 | val_0_accuracy: 0.8578  | val_1_accuracy: 0.8427  |  0:01:09s\n",
            "epoch 27 | loss: 0.33745 | val_0_accuracy: 0.85988 | val_1_accuracy: 0.85185 |  0:01:11s\n",
            "epoch 28 | loss: 0.32806 | val_0_accuracy: 0.86526 | val_1_accuracy: 0.85185 |  0:01:14s\n",
            "epoch 29 | loss: 0.3221  | val_0_accuracy: 0.86087 | val_1_accuracy: 0.84873 |  0:01:17s\n",
            "epoch 30 | loss: 0.32287 | val_0_accuracy: 0.86499 | val_1_accuracy: 0.85274 |  0:01:19s\n",
            "epoch 31 | loss: 0.33121 | val_0_accuracy: 0.85881 | val_1_accuracy: 0.84761 |  0:01:22s\n",
            "epoch 32 | loss: 0.32189 | val_0_accuracy: 0.86682 | val_1_accuracy: 0.8552  |  0:01:24s\n",
            "epoch 33 | loss: 0.32391 | val_0_accuracy: 0.86323 | val_1_accuracy: 0.85587 |  0:01:27s\n",
            "epoch 34 | loss: 0.32049 | val_0_accuracy: 0.86598 | val_1_accuracy: 0.84962 |  0:01:29s\n",
            "epoch 35 | loss: 0.31664 | val_0_accuracy: 0.86826 | val_1_accuracy: 0.85631 |  0:01:32s\n",
            "epoch 36 | loss: 0.31266 | val_0_accuracy: 0.86757 | val_1_accuracy: 0.85341 |  0:01:35s\n",
            "epoch 37 | loss: 0.31706 | val_0_accuracy: 0.86923 | val_1_accuracy: 0.85587 |  0:01:37s\n",
            "epoch 38 | loss: 0.31374 | val_0_accuracy: 0.86221 | val_1_accuracy: 0.85051 |  0:01:40s\n",
            "epoch 39 | loss: 0.30839 | val_0_accuracy: 0.87054 | val_1_accuracy: 0.85855 |  0:01:42s\n",
            "epoch 40 | loss: 0.30917 | val_0_accuracy: 0.86933 | val_1_accuracy: 0.85207 |  0:01:45s\n",
            "epoch 41 | loss: 0.30619 | val_0_accuracy: 0.86955 | val_1_accuracy: 0.8552  |  0:01:48s\n",
            "epoch 42 | loss: 0.31356 | val_0_accuracy: 0.8667  | val_1_accuracy: 0.85921 |  0:01:50s\n",
            "epoch 43 | loss: 0.31252 | val_0_accuracy: 0.86831 | val_1_accuracy: 0.85207 |  0:01:53s\n",
            "epoch 44 | loss: 0.31904 | val_0_accuracy: 0.85611 | val_1_accuracy: 0.83936 |  0:01:55s\n",
            "epoch 45 | loss: 0.31011 | val_0_accuracy: 0.8719  | val_1_accuracy: 0.86033 |  0:01:58s\n",
            "epoch 46 | loss: 0.30097 | val_0_accuracy: 0.869   | val_1_accuracy: 0.85118 |  0:02:00s\n",
            "epoch 47 | loss: 0.30613 | val_0_accuracy: 0.86987 | val_1_accuracy: 0.85676 |  0:02:03s\n",
            "epoch 48 | loss: 0.30048 | val_0_accuracy: 0.87    | val_1_accuracy: 0.85788 |  0:02:06s\n",
            "epoch 49 | loss: 0.30663 | val_0_accuracy: 0.87059 | val_1_accuracy: 0.84962 |  0:02:08s\n",
            "epoch 50 | loss: 0.30325 | val_0_accuracy: 0.866   | val_1_accuracy: 0.85788 |  0:02:11s\n",
            "epoch 51 | loss: 0.30062 | val_0_accuracy: 0.87287 | val_1_accuracy: 0.85899 |  0:02:13s\n",
            "epoch 52 | loss: 0.2976  | val_0_accuracy: 0.87188 | val_1_accuracy: 0.85431 |  0:02:16s\n",
            "epoch 53 | loss: 0.29695 | val_0_accuracy: 0.87485 | val_1_accuracy: 0.86725 |  0:02:18s\n",
            "[499] CPU Utilization: 51.6%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 25.4%\n",
            "epoch 54 | loss: 0.29896 | val_0_accuracy: 0.87602 | val_1_accuracy: 0.85654 |  0:02:21s\n",
            "epoch 55 | loss: 0.2961  | val_0_accuracy: 0.87009 | val_1_accuracy: 0.85698 |  0:02:23s\n",
            "epoch 56 | loss: 0.29678 | val_0_accuracy: 0.87091 | val_1_accuracy: 0.85498 |  0:02:26s\n",
            "epoch 57 | loss: 0.29758 | val_0_accuracy: 0.86474 | val_1_accuracy: 0.85185 |  0:02:29s\n",
            "epoch 58 | loss: 0.30353 | val_0_accuracy: 0.87691 | val_1_accuracy: 0.85765 |  0:02:31s\n",
            "epoch 59 | loss: 0.29028 | val_0_accuracy: 0.87238 | val_1_accuracy: 0.85721 |  0:02:34s\n",
            "epoch 60 | loss: 0.2959  | val_0_accuracy: 0.87032 | val_1_accuracy: 0.85564 |  0:02:36s\n",
            "epoch 61 | loss: 0.2945  | val_0_accuracy: 0.8758  | val_1_accuracy: 0.861   |  0:02:39s\n",
            "epoch 62 | loss: 0.2904  | val_0_accuracy: 0.87758 | val_1_accuracy: 0.86033 |  0:02:42s\n",
            "epoch 63 | loss: 0.28725 | val_0_accuracy: 0.87837 | val_1_accuracy: 0.86301 |  0:02:44s\n",
            "\n",
            "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_1_accuracy = 0.86725\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            b             d         w predictions truth\n",
            "0   0.000005  2.002560e-08  0.999995           w     w\n",
            "1   0.000181  9.211792e-07  0.999818           w     w\n",
            "2   0.001316  5.214313e-06  0.998678           w     w\n",
            "3   0.000005  2.002560e-08  0.999995           w     w\n",
            "4   0.000089  3.968350e-06  0.999907           w     w\n",
            "5   0.016987  3.003487e-05  0.982983           w     w\n",
            "6   0.070154  7.353355e-01  0.194510           d     w\n",
            "7   0.037491  3.130772e-01  0.649432           w     w\n",
            "8   0.212654  8.956395e-02  0.697782           w     w\n",
            "9   0.472716  5.995792e-04  0.526684           w     w\n",
            "10  0.000645  8.458584e-06  0.999347           w     w\n",
            "11  0.000436  4.181857e-06  0.999560           w     w\n",
            "12  0.000228  4.945166e-06  0.999767           w     w\n",
            "13  0.061448  4.989340e-05  0.938502           w     w\n",
            "14  0.383673  2.810095e-02  0.588226           w     w\n",
            "15  0.001636  1.341000e-04  0.998230           w     w\n",
            "16  0.125631  6.501844e-02  0.809351           w     w\n",
            "17  0.000236  8.091281e-06  0.999756           w     w\n",
            "18  0.000064  1.338306e-05  0.999922           w     w\n",
            "19  0.219522  3.138796e-01  0.466598           w     w\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/jungle_chess_2pcs_raw_endgame_complete/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.8672467648371263,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.8042432406166417,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/167119',\n",
            "  'info': None,\n",
            "  'logloss': 0.27096859711150406,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.07954096794128418,\n",
            "  'result': 0.27096859711150406,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'jungle_chess_2pcs_raw_endgame_complete',\n",
            "  'training_duration': 165.44440460205078,\n",
            "  'utc': '2021-02-04T17:24:58',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.jungle_chess_2pcs_raw_endgame_complete.1.TabNet executed in 166.591 seconds.\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.KDDCup09_appetency.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task KDDCup09_appetency.\n",
            "Assigning 6629 MB (total=13021 MB) for new KDDCup09_appetency task.\n",
            "Running task KDDCup09_appetency on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='KDDCup09_appetency', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6629, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'r__I'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'r__I'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/3945',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'r__I'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'KDDCup09_appetency',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T17:25:33',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.KDDCup09_appetency.0.TabNet executed in 34.983 seconds.\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.KDDCup09_appetency.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task KDDCup09_appetency.\n",
            "Assigning 6608 MB (total=13021 MB) for new KDDCup09_appetency task.\n",
            "Running task KDDCup09_appetency on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='KDDCup09_appetency', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6608, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'r__I'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'r__I'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/KDDCup09_appetency/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/3945',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'r__I'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'KDDCup09_appetency',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T17:25:46',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.KDDCup09_appetency.1.TabNet executed in 12.785 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.MiniBooNE.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task MiniBooNE.\n",
            "Assigning 6656 MB (total=13021 MB) for new MiniBooNE task.\n",
            "Running task MiniBooNE on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='MiniBooNE', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6656, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "[499] CPU Utilization: 38.5%\n",
            "[499] Memory Usage: 34.1%\n",
            "[499] Disk Usage: 25.7%\n",
            "epoch 0  | loss: 0.39708 | val_0_auc: 0.88115 | val_1_auc: 0.8814  |  0:00:07s\n",
            "epoch 1  | loss: 0.30697 | val_0_auc: 0.92989 | val_1_auc: 0.93034 |  0:00:15s\n",
            "epoch 2  | loss: 0.27424 | val_0_auc: 0.94495 | val_1_auc: 0.94548 |  0:00:22s\n",
            "epoch 3  | loss: 0.25948 | val_0_auc: 0.94138 | val_1_auc: 0.941   |  0:00:30s\n",
            "epoch 4  | loss: 0.2486  | val_0_auc: 0.95078 | val_1_auc: 0.95068 |  0:00:38s\n",
            "epoch 5  | loss: 0.23972 | val_0_auc: 0.94037 | val_1_auc: 0.94024 |  0:00:45s\n",
            "epoch 6  | loss: 0.22535 | val_0_auc: 0.94651 | val_1_auc: 0.94678 |  0:00:53s\n",
            "epoch 7  | loss: 0.21785 | val_0_auc: 0.93748 | val_1_auc: 0.93949 |  0:01:01s\n",
            "epoch 8  | loss: 0.20881 | val_0_auc: 0.93307 | val_1_auc: 0.93595 |  0:01:09s\n",
            "epoch 9  | loss: 0.20717 | val_0_auc: 0.92758 | val_1_auc: 0.92896 |  0:01:17s\n",
            "epoch 10 | loss: 0.20294 | val_0_auc: 0.92714 | val_1_auc: 0.929   |  0:01:24s\n",
            "epoch 11 | loss: 0.20212 | val_0_auc: 0.94296 | val_1_auc: 0.94453 |  0:01:32s\n",
            "epoch 12 | loss: 0.19857 | val_0_auc: 0.95169 | val_1_auc: 0.953   |  0:01:40s\n",
            "epoch 13 | loss: 0.19684 | val_0_auc: 0.94009 | val_1_auc: 0.94177 |  0:01:47s\n",
            "epoch 14 | loss: 0.19085 | val_0_auc: 0.92126 | val_1_auc: 0.92294 |  0:01:55s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 34.1%\n",
            "[499] Disk Usage: 25.7%\n",
            "epoch 15 | loss: 0.19212 | val_0_auc: 0.93391 | val_1_auc: 0.93615 |  0:02:02s\n",
            "epoch 16 | loss: 0.19572 | val_0_auc: 0.95281 | val_1_auc: 0.9527  |  0:02:10s\n",
            "epoch 17 | loss: 0.19091 | val_0_auc: 0.94144 | val_1_auc: 0.94137 |  0:02:17s\n",
            "epoch 18 | loss: 0.19262 | val_0_auc: 0.94028 | val_1_auc: 0.94042 |  0:02:25s\n",
            "epoch 19 | loss: 0.19471 | val_0_auc: 0.94498 | val_1_auc: 0.94436 |  0:02:32s\n",
            "epoch 20 | loss: 0.19467 | val_0_auc: 0.94362 | val_1_auc: 0.94394 |  0:02:40s\n",
            "epoch 21 | loss: 0.18829 | val_0_auc: 0.94062 | val_1_auc: 0.94044 |  0:02:47s\n",
            "epoch 22 | loss: 0.18318 | val_0_auc: 0.94834 | val_1_auc: 0.94887 |  0:02:55s\n",
            "\n",
            "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_1_auc = 0.953\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "        false      true predictions  truth\n",
            "0   0.961482  0.038518       False  False\n",
            "1   0.981310  0.018689       False  False\n",
            "2   0.969812  0.030188       False  False\n",
            "3   0.981037  0.018963       False  False\n",
            "4   0.986740  0.013260       False  False\n",
            "5   0.963873  0.036127       False  False\n",
            "6   0.985064  0.014936       False  False\n",
            "7   0.987783  0.012217       False  False\n",
            "8   0.993091  0.006909       False  False\n",
            "9   0.983798  0.016202       False  False\n",
            "10  0.960990  0.039010       False  False\n",
            "11  0.994232  0.005768       False  False\n",
            "12  0.990005  0.009995       False  False\n",
            "13  0.990891  0.009109       False  False\n",
            "14  0.991702  0.008298       False  False\n",
            "15  0.988399  0.011601       False  False\n",
            "16  0.981008  0.018992       False  False\n",
            "17  0.965223  0.034777       False  False\n",
            "18  0.992766  0.007234       False  False\n",
            "19  0.990087  0.009913       False  False\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.7396786345813793,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.9529996442484638,\n",
            "  'balacc': 0.5368327865300464,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168335',\n",
            "  'info': None,\n",
            "  'logloss': 0.524336620603965,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.22982525825500488,\n",
            "  'result': 0.9529996442484638,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'MiniBooNE',\n",
            "  'training_duration': 177.8309395313263,\n",
            "  'utc': '2021-02-04T17:29:30',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.MiniBooNE.0.TabNet executed in 224.666 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.MiniBooNE.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task MiniBooNE.\n",
            "Assigning 6653 MB (total=13021 MB) for new MiniBooNE task.\n",
            "Running task MiniBooNE on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='MiniBooNE', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6653, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.43366 | val_0_auc: 0.87033 | val_1_auc: 0.86162 |  0:00:07s\n",
            "epoch 1  | loss: 0.3157  | val_0_auc: 0.92984 | val_1_auc: 0.92598 |  0:00:15s\n",
            "epoch 2  | loss: 0.29216 | val_0_auc: 0.91876 | val_1_auc: 0.91382 |  0:00:22s\n",
            "epoch 3  | loss: 0.27181 | val_0_auc: 0.92362 | val_1_auc: 0.91825 |  0:00:30s\n",
            "epoch 4  | loss: 0.26222 | val_0_auc: 0.93589 | val_1_auc: 0.93005 |  0:00:37s\n",
            "epoch 5  | loss: 0.2626  | val_0_auc: 0.93733 | val_1_auc: 0.93324 |  0:00:45s\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 34.1%\n",
            "[499] Disk Usage: 25.7%\n",
            "epoch 6  | loss: 0.25898 | val_0_auc: 0.93569 | val_1_auc: 0.93061 |  0:00:52s\n",
            "epoch 7  | loss: 0.25443 | val_0_auc: 0.92574 | val_1_auc: 0.92114 |  0:01:00s\n",
            "epoch 8  | loss: 0.25922 | val_0_auc: 0.93402 | val_1_auc: 0.92853 |  0:01:07s\n",
            "epoch 9  | loss: 0.24738 | val_0_auc: 0.89254 | val_1_auc: 0.88592 |  0:01:15s\n",
            "epoch 10 | loss: 0.24037 | val_0_auc: 0.92479 | val_1_auc: 0.91861 |  0:01:22s\n",
            "epoch 11 | loss: 0.22615 | val_0_auc: 0.91836 | val_1_auc: 0.91091 |  0:01:30s\n",
            "epoch 12 | loss: 0.23192 | val_0_auc: 0.90763 | val_1_auc: 0.90037 |  0:01:37s\n",
            "epoch 13 | loss: 0.21514 | val_0_auc: 0.92185 | val_1_auc: 0.91449 |  0:01:45s\n",
            "epoch 14 | loss: 0.21104 | val_0_auc: 0.91136 | val_1_auc: 0.90497 |  0:01:52s\n",
            "epoch 15 | loss: 0.20754 | val_0_auc: 0.92444 | val_1_auc: 0.9189  |  0:02:00s\n",
            "\n",
            "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_1_auc = 0.93324\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "        false      true predictions  truth\n",
            "0   0.996669  0.003331       False  False\n",
            "1   0.790540  0.209460       False  False\n",
            "2   0.998444  0.001556       False  False\n",
            "3   0.995399  0.004601       False  False\n",
            "4   0.968146  0.031854       False  False\n",
            "5   0.979481  0.020519       False  False\n",
            "6   0.997896  0.002104       False  False\n",
            "7   0.995564  0.004436       False  False\n",
            "8   0.631264  0.368736       False  False\n",
            "9   0.993220  0.006780       False  False\n",
            "10  0.985105  0.014895       False  False\n",
            "11  0.938807  0.061192       False  False\n",
            "12  0.936904  0.063096       False  False\n",
            "13  0.989951  0.010049       False  False\n",
            "14  0.996552  0.003448       False  False\n",
            "15  0.851287  0.148713       False  False\n",
            "16  0.970975  0.029025       False  False\n",
            "17  0.995478  0.004522       False  False\n",
            "18  0.995378  0.004622       False  False\n",
            "19  0.994028  0.005972       False  False\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/MiniBooNE/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.8266318136388099,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.9332351576213544,\n",
            "  'balacc': 0.6988660749186383,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168335',\n",
            "  'info': None,\n",
            "  'logloss': 0.40759190595091754,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.2523181438446045,\n",
            "  'result': 0.9332351576213544,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'MiniBooNE',\n",
            "  'training_duration': 122.89378499984741,\n",
            "  'utc': '2021-02-04T17:31:51',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.MiniBooNE.1.TabNet executed in 140.951 seconds.\n",
            "\n",
            "-----------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.nomao.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task nomao.\n",
            "Assigning 6658 MB (total=13021 MB) for new nomao task.\n",
            "Running task nomao on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='nomao', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6658, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.39304 | val_0_auc: 0.63345 | val_1_auc: 0.61613 |  0:00:02s\n",
            "epoch 1  | loss: 0.19467 | val_0_auc: 0.70296 | val_1_auc: 0.69825 |  0:00:04s\n",
            "epoch 2  | loss: 0.17376 | val_0_auc: 0.89379 | val_1_auc: 0.89439 |  0:00:06s\n",
            "epoch 3  | loss: 0.16597 | val_0_auc: 0.95677 | val_1_auc: 0.9565  |  0:00:08s\n",
            "epoch 4  | loss: 0.15631 | val_0_auc: 0.96992 | val_1_auc: 0.9679  |  0:00:10s\n",
            "epoch 5  | loss: 0.15366 | val_0_auc: 0.96978 | val_1_auc: 0.96662 |  0:00:12s\n",
            "epoch 6  | loss: 0.15306 | val_0_auc: 0.97929 | val_1_auc: 0.97524 |  0:00:14s\n",
            "epoch 7  | loss: 0.14621 | val_0_auc: 0.9809  | val_1_auc: 0.97666 |  0:00:16s\n",
            "epoch 8  | loss: 0.14141 | val_0_auc: 0.9832  | val_1_auc: 0.97942 |  0:00:18s\n",
            "[499] CPU Utilization: 46.6%\n",
            "[499] Memory Usage: 33.1%\n",
            "[499] Disk Usage: 25.8%\n",
            "epoch 9  | loss: 0.14777 | val_0_auc: 0.98332 | val_1_auc: 0.98025 |  0:00:20s\n",
            "epoch 10 | loss: 0.14151 | val_0_auc: 0.98499 | val_1_auc: 0.9806  |  0:00:22s\n",
            "epoch 11 | loss: 0.13509 | val_0_auc: 0.98731 | val_1_auc: 0.98328 |  0:00:24s\n",
            "epoch 12 | loss: 0.13204 | val_0_auc: 0.98817 | val_1_auc: 0.985   |  0:00:26s\n",
            "epoch 13 | loss: 0.13125 | val_0_auc: 0.98842 | val_1_auc: 0.98441 |  0:00:29s\n",
            "epoch 14 | loss: 0.13084 | val_0_auc: 0.9877  | val_1_auc: 0.98397 |  0:00:31s\n",
            "epoch 15 | loss: 0.1276  | val_0_auc: 0.98919 | val_1_auc: 0.98623 |  0:00:33s\n",
            "epoch 16 | loss: 0.12638 | val_0_auc: 0.98931 | val_1_auc: 0.9862  |  0:00:35s\n",
            "epoch 17 | loss: 0.12545 | val_0_auc: 0.98991 | val_1_auc: 0.98641 |  0:00:37s\n",
            "epoch 18 | loss: 0.1239  | val_0_auc: 0.98979 | val_1_auc: 0.98646 |  0:00:39s\n",
            "epoch 19 | loss: 0.12554 | val_0_auc: 0.99029 | val_1_auc: 0.98628 |  0:00:41s\n",
            "epoch 20 | loss: 0.12833 | val_0_auc: 0.98895 | val_1_auc: 0.98406 |  0:00:43s\n",
            "epoch 21 | loss: 0.12911 | val_0_auc: 0.98932 | val_1_auc: 0.98543 |  0:00:46s\n",
            "epoch 22 | loss: 0.1297  | val_0_auc: 0.98776 | val_1_auc: 0.98433 |  0:00:48s\n",
            "epoch 23 | loss: 0.13454 | val_0_auc: 0.98889 | val_1_auc: 0.98509 |  0:00:50s\n",
            "epoch 24 | loss: 0.12399 | val_0_auc: 0.98945 | val_1_auc: 0.98531 |  0:00:52s\n",
            "epoch 25 | loss: 0.1219  | val_0_auc: 0.99057 | val_1_auc: 0.98751 |  0:00:54s\n",
            "epoch 26 | loss: 0.11808 | val_0_auc: 0.99113 | val_1_auc: 0.98859 |  0:00:56s\n",
            "epoch 27 | loss: 0.11615 | val_0_auc: 0.98971 | val_1_auc: 0.98597 |  0:00:58s\n",
            "epoch 28 | loss: 0.12396 | val_0_auc: 0.99033 | val_1_auc: 0.98807 |  0:01:00s\n",
            "epoch 29 | loss: 0.11952 | val_0_auc: 0.99093 | val_1_auc: 0.98817 |  0:01:03s\n",
            "epoch 30 | loss: 0.11754 | val_0_auc: 0.99139 | val_1_auc: 0.98822 |  0:01:05s\n",
            "epoch 31 | loss: 0.11407 | val_0_auc: 0.99157 | val_1_auc: 0.98935 |  0:01:07s\n",
            "epoch 32 | loss: 0.11086 | val_0_auc: 0.99217 | val_1_auc: 0.98942 |  0:01:09s\n",
            "epoch 33 | loss: 0.11154 | val_0_auc: 0.99235 | val_1_auc: 0.98974 |  0:01:11s\n",
            "epoch 34 | loss: 0.10967 | val_0_auc: 0.99235 | val_1_auc: 0.98914 |  0:01:13s\n",
            "epoch 35 | loss: 0.10517 | val_0_auc: 0.99273 | val_1_auc: 0.98824 |  0:01:15s\n",
            "epoch 36 | loss: 0.10711 | val_0_auc: 0.99276 | val_1_auc: 0.98999 |  0:01:17s\n",
            "epoch 37 | loss: 0.10377 | val_0_auc: 0.99305 | val_1_auc: 0.99022 |  0:01:19s\n",
            "epoch 38 | loss: 0.102   | val_0_auc: 0.99342 | val_1_auc: 0.99028 |  0:01:22s\n",
            "epoch 39 | loss: 0.10084 | val_0_auc: 0.99298 | val_1_auc: 0.98832 |  0:01:24s\n",
            "epoch 40 | loss: 0.10303 | val_0_auc: 0.99198 | val_1_auc: 0.98794 |  0:01:26s\n",
            "epoch 41 | loss: 0.10389 | val_0_auc: 0.99304 | val_1_auc: 0.99008 |  0:01:28s\n",
            "epoch 42 | loss: 0.11197 | val_0_auc: 0.99113 | val_1_auc: 0.98702 |  0:01:30s\n",
            "epoch 43 | loss: 0.1119  | val_0_auc: 0.99184 | val_1_auc: 0.98697 |  0:01:32s\n",
            "epoch 44 | loss: 0.10875 | val_0_auc: 0.99233 | val_1_auc: 0.98877 |  0:01:34s\n",
            "epoch 45 | loss: 0.10336 | val_0_auc: 0.99315 | val_1_auc: 0.98989 |  0:01:36s\n",
            "epoch 46 | loss: 0.10216 | val_0_auc: 0.99358 | val_1_auc: 0.99061 |  0:01:39s\n",
            "epoch 47 | loss: 0.09902 | val_0_auc: 0.99335 | val_1_auc: 0.99051 |  0:01:41s\n",
            "epoch 48 | loss: 0.09893 | val_0_auc: 0.99381 | val_1_auc: 0.99123 |  0:01:43s\n",
            "epoch 49 | loss: 0.09533 | val_0_auc: 0.9941  | val_1_auc: 0.99155 |  0:01:45s\n",
            "epoch 50 | loss: 0.09456 | val_0_auc: 0.9941  | val_1_auc: 0.99112 |  0:01:47s\n",
            "epoch 51 | loss: 0.09605 | val_0_auc: 0.99385 | val_1_auc: 0.99096 |  0:01:49s\n",
            "epoch 52 | loss: 0.09508 | val_0_auc: 0.99412 | val_1_auc: 0.99049 |  0:01:51s\n",
            "epoch 53 | loss: 0.09961 | val_0_auc: 0.99417 | val_1_auc: 0.99098 |  0:01:53s\n",
            "epoch 54 | loss: 0.09379 | val_0_auc: 0.99431 | val_1_auc: 0.99105 |  0:01:55s\n",
            "epoch 55 | loss: 0.09219 | val_0_auc: 0.9947  | val_1_auc: 0.99187 |  0:01:58s\n",
            "epoch 56 | loss: 0.09305 | val_0_auc: 0.99482 | val_1_auc: 0.99157 |  0:02:00s\n",
            "epoch 57 | loss: 0.09309 | val_0_auc: 0.99456 | val_1_auc: 0.99101 |  0:02:02s\n",
            "epoch 58 | loss: 0.09137 | val_0_auc: 0.9948  | val_1_auc: 0.99111 |  0:02:04s\n",
            "epoch 59 | loss: 0.09293 | val_0_auc: 0.99482 | val_1_auc: 0.99088 |  0:02:06s\n",
            "epoch 60 | loss: 0.08971 | val_0_auc: 0.99508 | val_1_auc: 0.99158 |  0:02:08s\n",
            "epoch 61 | loss: 0.08912 | val_0_auc: 0.99487 | val_1_auc: 0.99166 |  0:02:10s\n",
            "epoch 62 | loss: 0.08999 | val_0_auc: 0.99503 | val_1_auc: 0.99163 |  0:02:12s\n",
            "epoch 63 | loss: 0.09099 | val_0_auc: 0.99467 | val_1_auc: 0.99143 |  0:02:14s\n",
            "epoch 64 | loss: 0.09015 | val_0_auc: 0.99454 | val_1_auc: 0.99105 |  0:02:17s\n",
            "[499] CPU Utilization: 51.8%\n",
            "[499] Memory Usage: 33.3%\n",
            "[499] Disk Usage: 25.8%\n",
            "epoch 65 | loss: 0.08986 | val_0_auc: 0.99517 | val_1_auc: 0.99175 |  0:02:19s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_1_auc = 0.99187\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "                1         2 predictions truth\n",
            "0   2.496097e-06  0.999997           2     2\n",
            "1   5.232297e-05  0.999948           2     2\n",
            "2   2.081766e-05  0.999979           2     2\n",
            "3   1.085729e-04  0.999891           2     2\n",
            "4   5.332716e-06  0.999995           2     2\n",
            "5   1.336970e-04  0.999866           2     2\n",
            "6   1.046229e-02  0.989538           2     2\n",
            "7   2.496097e-06  0.999997           2     2\n",
            "8   2.106620e-04  0.999789           2     2\n",
            "9   6.048520e-06  0.999994           2     2\n",
            "10  5.534063e-06  0.999995           2     2\n",
            "11  1.076779e-03  0.998923           2     2\n",
            "12  1.989303e-07  1.000000           2     2\n",
            "13  2.071529e-03  0.997929           2     2\n",
            "14  2.168835e-04  0.999783           2     2\n",
            "15  1.545779e-02  0.984542           2     2\n",
            "16  1.109216e-02  0.988908           2     2\n",
            "17  1.342248e-04  0.999866           2     2\n",
            "18  1.287935e-03  0.998712           2     2\n",
            "19  1.310967e-02  0.986890           2     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9588047577603713,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.9918723943634077,\n",
            "  'balacc': 0.9501196983650714,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/9977',\n",
            "  'info': None,\n",
            "  'logloss': 0.10470861972555988,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.06730341911315918,\n",
            "  'result': 0.9918723943634077,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'nomao',\n",
            "  'training_duration': 139.90546083450317,\n",
            "  'utc': '2021-02-04T17:34:35',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.nomao.0.TabNet executed in 163.603 seconds.\n",
            "\n",
            "-----------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.nomao.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task nomao.\n",
            "Assigning 6634 MB (total=13021 MB) for new nomao task.\n",
            "Running task nomao on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='nomao', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6634, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.43957 | val_0_auc: 0.5954  | val_1_auc: 0.60504 |  0:00:02s\n",
            "epoch 1  | loss: 0.21158 | val_0_auc: 0.91158 | val_1_auc: 0.9168  |  0:00:04s\n",
            "epoch 2  | loss: 0.1798  | val_0_auc: 0.95068 | val_1_auc: 0.95532 |  0:00:06s\n",
            "epoch 3  | loss: 0.16823 | val_0_auc: 0.96239 | val_1_auc: 0.96751 |  0:00:08s\n",
            "epoch 4  | loss: 0.16223 | val_0_auc: 0.96393 | val_1_auc: 0.96671 |  0:00:10s\n",
            "epoch 5  | loss: 0.15469 | val_0_auc: 0.9676  | val_1_auc: 0.96802 |  0:00:12s\n",
            "epoch 6  | loss: 0.15171 | val_0_auc: 0.97646 | val_1_auc: 0.97584 |  0:00:14s\n",
            "epoch 7  | loss: 0.14848 | val_0_auc: 0.97657 | val_1_auc: 0.97704 |  0:00:16s\n",
            "epoch 8  | loss: 0.144   | val_0_auc: 0.98258 | val_1_auc: 0.98336 |  0:00:19s\n",
            "epoch 9  | loss: 0.13917 | val_0_auc: 0.98456 | val_1_auc: 0.98365 |  0:00:21s\n",
            "epoch 10 | loss: 0.13799 | val_0_auc: 0.98577 | val_1_auc: 0.98689 |  0:00:23s\n",
            "epoch 11 | loss: 0.13246 | val_0_auc: 0.98743 | val_1_auc: 0.98746 |  0:00:25s\n",
            "epoch 12 | loss: 0.13141 | val_0_auc: 0.9873  | val_1_auc: 0.9871  |  0:00:27s\n",
            "epoch 13 | loss: 0.13674 | val_0_auc: 0.98697 | val_1_auc: 0.98754 |  0:00:29s\n",
            "epoch 14 | loss: 0.13648 | val_0_auc: 0.98729 | val_1_auc: 0.98634 |  0:00:31s\n",
            "epoch 15 | loss: 0.13569 | val_0_auc: 0.98778 | val_1_auc: 0.98735 |  0:00:34s\n",
            "epoch 16 | loss: 0.13222 | val_0_auc: 0.98841 | val_1_auc: 0.9878  |  0:00:36s\n",
            "epoch 17 | loss: 0.13493 | val_0_auc: 0.98665 | val_1_auc: 0.98565 |  0:00:38s\n",
            "epoch 18 | loss: 0.13428 | val_0_auc: 0.98786 | val_1_auc: 0.9865  |  0:00:40s\n",
            "epoch 19 | loss: 0.13068 | val_0_auc: 0.98852 | val_1_auc: 0.98686 |  0:00:42s\n",
            "epoch 20 | loss: 0.1277  | val_0_auc: 0.9893  | val_1_auc: 0.98784 |  0:00:44s\n",
            "epoch 21 | loss: 0.12563 | val_0_auc: 0.98964 | val_1_auc: 0.98865 |  0:00:46s\n",
            "epoch 22 | loss: 0.12224 | val_0_auc: 0.99036 | val_1_auc: 0.9885  |  0:00:48s\n",
            "epoch 23 | loss: 0.11955 | val_0_auc: 0.99083 | val_1_auc: 0.98967 |  0:00:51s\n",
            "epoch 24 | loss: 0.11772 | val_0_auc: 0.9909  | val_1_auc: 0.98991 |  0:00:53s\n",
            "epoch 25 | loss: 0.11773 | val_0_auc: 0.99108 | val_1_auc: 0.98952 |  0:00:55s\n",
            "epoch 26 | loss: 0.1151  | val_0_auc: 0.98958 | val_1_auc: 0.98766 |  0:00:57s\n",
            "epoch 27 | loss: 0.1193  | val_0_auc: 0.99085 | val_1_auc: 0.99008 |  0:00:59s\n",
            "epoch 28 | loss: 0.121   | val_0_auc: 0.99121 | val_1_auc: 0.99004 |  0:01:01s\n",
            "epoch 29 | loss: 0.11376 | val_0_auc: 0.99143 | val_1_auc: 0.99021 |  0:01:03s\n",
            "epoch 30 | loss: 0.11121 | val_0_auc: 0.99183 | val_1_auc: 0.99015 |  0:01:05s\n",
            "epoch 31 | loss: 0.10982 | val_0_auc: 0.99212 | val_1_auc: 0.99087 |  0:01:07s\n",
            "epoch 32 | loss: 0.10795 | val_0_auc: 0.99164 | val_1_auc: 0.98984 |  0:01:09s\n",
            "epoch 33 | loss: 0.11042 | val_0_auc: 0.99195 | val_1_auc: 0.99029 |  0:01:12s\n",
            "epoch 34 | loss: 0.10941 | val_0_auc: 0.99243 | val_1_auc: 0.99106 |  0:01:14s\n",
            "epoch 35 | loss: 0.11002 | val_0_auc: 0.99238 | val_1_auc: 0.99052 |  0:01:16s\n",
            "epoch 36 | loss: 0.10783 | val_0_auc: 0.99259 | val_1_auc: 0.99126 |  0:01:18s\n",
            "epoch 37 | loss: 0.11367 | val_0_auc: 0.99165 | val_1_auc: 0.9907  |  0:01:20s\n",
            "epoch 38 | loss: 0.11357 | val_0_auc: 0.9917  | val_1_auc: 0.99017 |  0:01:22s\n",
            "epoch 39 | loss: 0.11161 | val_0_auc: 0.99198 | val_1_auc: 0.98981 |  0:01:24s\n",
            "epoch 40 | loss: 0.11244 | val_0_auc: 0.99212 | val_1_auc: 0.99104 |  0:01:26s\n",
            "epoch 41 | loss: 0.10667 | val_0_auc: 0.99248 | val_1_auc: 0.99022 |  0:01:28s\n",
            "epoch 42 | loss: 0.1069  | val_0_auc: 0.99309 | val_1_auc: 0.99121 |  0:01:30s\n",
            "epoch 43 | loss: 0.10359 | val_0_auc: 0.99339 | val_1_auc: 0.99109 |  0:01:32s\n",
            "epoch 44 | loss: 0.10188 | val_0_auc: 0.99308 | val_1_auc: 0.9899  |  0:01:35s\n",
            "epoch 45 | loss: 0.11503 | val_0_auc: 0.9918  | val_1_auc: 0.98992 |  0:01:37s\n",
            "epoch 46 | loss: 0.10753 | val_0_auc: 0.99296 | val_1_auc: 0.99096 |  0:01:39s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_1_auc = 0.99126\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            1         2 predictions truth\n",
            "0   0.002134  0.997866           2     2\n",
            "1   0.002242  0.997758           2     2\n",
            "2   0.001046  0.998954           2     2\n",
            "3   0.006697  0.993303           2     2\n",
            "4   0.000569  0.999431           2     2\n",
            "5   0.002115  0.997886           2     2\n",
            "6   0.000683  0.999317           2     2\n",
            "7   0.000021  0.999979           2     2\n",
            "8   0.002991  0.997009           2     2\n",
            "9   0.168493  0.831507           2     2\n",
            "10  0.028872  0.971128           2     2\n",
            "11  0.008798  0.991202           2     2\n",
            "12  0.004540  0.995460           2     2\n",
            "13  0.000218  0.999782           2     2\n",
            "14  0.013194  0.986806           2     2\n",
            "15  0.001562  0.998438           2     2\n",
            "16  0.022080  0.977920           2     2\n",
            "17  0.000015  0.999985           2     2\n",
            "18  0.011358  0.988642           2     2\n",
            "19  0.000134  0.999866           2     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/nomao/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9573542210617929,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.9912600461017621,\n",
            "  'balacc': 0.9485247848515713,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/9977',\n",
            "  'info': None,\n",
            "  'logloss': 0.10871039748158297,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.06670975685119629,\n",
            "  'result': 0.9912600461017621,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'nomao',\n",
            "  'training_duration': 99.98873114585876,\n",
            "  'utc': '2021-02-04T17:36:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.nomao.1.TabNet executed in 107.885 seconds.\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.numerai28_6.0.TabNet.\n",
            "[499] CPU Utilization: 47.4%\n",
            "[499] Memory Usage: 33.4%\n",
            "[499] Disk Usage: 25.8%\n",
            "Assigning 2 cores (total=2) for new task numerai28_6.\n",
            "Assigning 6613 MB (total=13021 MB) for new numerai28_6 task.\n",
            "Running task numerai28_6 on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='numerai28_6', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6613, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.70437 | val_0_auc: 0.505   | val_1_auc: 0.50449 |  0:00:05s\n",
            "epoch 1  | loss: 0.69366 | val_0_auc: 0.509   | val_1_auc: 0.50484 |  0:00:11s\n",
            "epoch 2  | loss: 0.69332 | val_0_auc: 0.51532 | val_1_auc: 0.50736 |  0:00:16s\n",
            "epoch 3  | loss: 0.69333 | val_0_auc: 0.52567 | val_1_auc: 0.51323 |  0:00:22s\n",
            "epoch 4  | loss: 0.69292 | val_0_auc: 0.52209 | val_1_auc: 0.51458 |  0:00:28s\n",
            "epoch 5  | loss: 0.69286 | val_0_auc: 0.52723 | val_1_auc: 0.51726 |  0:00:33s\n",
            "epoch 6  | loss: 0.69273 | val_0_auc: 0.52908 | val_1_auc: 0.51549 |  0:00:39s\n",
            "epoch 7  | loss: 0.69255 | val_0_auc: 0.53017 | val_1_auc: 0.51453 |  0:00:44s\n",
            "epoch 8  | loss: 0.69247 | val_0_auc: 0.52855 | val_1_auc: 0.51642 |  0:00:49s\n",
            "epoch 9  | loss: 0.69248 | val_0_auc: 0.52806 | val_1_auc: 0.51499 |  0:00:55s\n",
            "epoch 10 | loss: 0.69243 | val_0_auc: 0.5289  | val_1_auc: 0.51575 |  0:01:01s\n",
            "epoch 11 | loss: 0.6924  | val_0_auc: 0.52886 | val_1_auc: 0.51833 |  0:01:06s\n",
            "epoch 12 | loss: 0.69231 | val_0_auc: 0.5295  | val_1_auc: 0.5176  |  0:01:12s\n",
            "epoch 13 | loss: 0.6923  | val_0_auc: 0.52906 | val_1_auc: 0.51553 |  0:01:17s\n",
            "epoch 14 | loss: 0.69245 | val_0_auc: 0.52806 | val_1_auc: 0.51824 |  0:01:23s\n",
            "epoch 15 | loss: 0.69249 | val_0_auc: 0.52643 | val_1_auc: 0.51294 |  0:01:28s\n",
            "epoch 16 | loss: 0.69238 | val_0_auc: 0.52155 | val_1_auc: 0.50958 |  0:01:34s\n",
            "epoch 17 | loss: 0.69249 | val_0_auc: 0.52724 | val_1_auc: 0.51216 |  0:01:39s\n",
            "[499] CPU Utilization: 49.6%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 25.9%\n",
            "epoch 18 | loss: 0.69244 | val_0_auc: 0.52717 | val_1_auc: 0.51344 |  0:01:45s\n",
            "epoch 19 | loss: 0.69246 | val_0_auc: 0.52933 | val_1_auc: 0.51466 |  0:01:51s\n",
            "epoch 20 | loss: 0.69223 | val_0_auc: 0.53037 | val_1_auc: 0.51211 |  0:01:56s\n",
            "epoch 21 | loss: 0.69233 | val_0_auc: 0.5275  | val_1_auc: 0.51225 |  0:02:02s\n",
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_1_auc = 0.51833\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.598454  0.401546           0     0\n",
            "1   0.563194  0.436806           0     0\n",
            "2   0.518132  0.481868           0     0\n",
            "3   0.494066  0.505934           1     0\n",
            "4   0.494417  0.505583           1     0\n",
            "5   0.527808  0.472192           0     0\n",
            "6   0.503949  0.496051           0     0\n",
            "7   0.482433  0.517567           1     0\n",
            "8   0.484277  0.515723           1     0\n",
            "9   0.500631  0.499369           0     0\n",
            "10  0.498183  0.501817           1     0\n",
            "11  0.483532  0.516468           1     0\n",
            "12  0.518142  0.481858           0     0\n",
            "13  0.485150  0.514850           1     0\n",
            "14  0.503403  0.496597           0     0\n",
            "15  0.500000  0.500000           0     0\n",
            "16  0.549042  0.450958           0     0\n",
            "17  0.540423  0.459577           0     0\n",
            "18  0.498218  0.501782           1     0\n",
            "19  0.483647  0.516353           1     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.5156769102990033,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.5183274615585783,\n",
            "  'balacc': 0.5141657347501483,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/167120',\n",
            "  'info': None,\n",
            "  'logloss': 0.6928539020146968,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.1674811840057373,\n",
            "  'result': 0.5183274615585783,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'numerai28_6',\n",
            "  'training_duration': 123.86637473106384,\n",
            "  'utc': '2021-02-04T17:38:55',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.numerai28_6.0.TabNet executed in 152.616 seconds.\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.numerai28_6.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task numerai28_6.\n",
            "Assigning 6586 MB (total=13021 MB) for new numerai28_6 task.\n",
            "Running task numerai28_6 on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='numerai28_6', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6586, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.70344 | val_0_auc: 0.51991 | val_1_auc: 0.51272 |  0:00:05s\n",
            "epoch 1  | loss: 0.69381 | val_0_auc: 0.5126  | val_1_auc: 0.51754 |  0:00:11s\n",
            "epoch 2  | loss: 0.69355 | val_0_auc: 0.51853 | val_1_auc: 0.5185  |  0:00:16s\n",
            "epoch 3  | loss: 0.69329 | val_0_auc: 0.5214  | val_1_auc: 0.52556 |  0:00:22s\n",
            "epoch 4  | loss: 0.69289 | val_0_auc: 0.52256 | val_1_auc: 0.51971 |  0:00:27s\n",
            "epoch 5  | loss: 0.69289 | val_0_auc: 0.52614 | val_1_auc: 0.52123 |  0:00:32s\n",
            "epoch 6  | loss: 0.69283 | val_0_auc: 0.52518 | val_1_auc: 0.52297 |  0:00:38s\n",
            "epoch 7  | loss: 0.6925  | val_0_auc: 0.52886 | val_1_auc: 0.52518 |  0:00:44s\n",
            "epoch 8  | loss: 0.69259 | val_0_auc: 0.52828 | val_1_auc: 0.51799 |  0:00:49s\n",
            "epoch 9  | loss: 0.69263 | val_0_auc: 0.5283  | val_1_auc: 0.52409 |  0:00:54s\n",
            "epoch 10 | loss: 0.69262 | val_0_auc: 0.52946 | val_1_auc: 0.53063 |  0:01:00s\n",
            "epoch 11 | loss: 0.69225 | val_0_auc: 0.53009 | val_1_auc: 0.52523 |  0:01:05s\n",
            "epoch 12 | loss: 0.69232 | val_0_auc: 0.53079 | val_1_auc: 0.52747 |  0:01:11s\n",
            "epoch 13 | loss: 0.69201 | val_0_auc: 0.53402 | val_1_auc: 0.53082 |  0:01:16s\n",
            "epoch 14 | loss: 0.69187 | val_0_auc: 0.53415 | val_1_auc: 0.52726 |  0:01:22s\n",
            "epoch 15 | loss: 0.69189 | val_0_auc: 0.53619 | val_1_auc: 0.5257  |  0:01:27s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 33.7%\n",
            "[499] Disk Usage: 25.9%\n",
            "epoch 16 | loss: 0.69179 | val_0_auc: 0.53593 | val_1_auc: 0.52471 |  0:01:33s\n",
            "epoch 17 | loss: 0.69191 | val_0_auc: 0.53619 | val_1_auc: 0.52438 |  0:01:38s\n",
            "epoch 18 | loss: 0.69194 | val_0_auc: 0.5355  | val_1_auc: 0.52434 |  0:01:44s\n",
            "epoch 19 | loss: 0.69196 | val_0_auc: 0.53618 | val_1_auc: 0.52326 |  0:01:49s\n",
            "epoch 20 | loss: 0.69187 | val_0_auc: 0.53591 | val_1_auc: 0.52632 |  0:01:55s\n",
            "epoch 21 | loss: 0.69197 | val_0_auc: 0.53408 | val_1_auc: 0.52523 |  0:02:00s\n",
            "epoch 22 | loss: 0.69167 | val_0_auc: 0.53692 | val_1_auc: 0.52142 |  0:02:06s\n",
            "epoch 23 | loss: 0.69196 | val_0_auc: 0.53314 | val_1_auc: 0.52229 |  0:02:11s\n",
            "\n",
            "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_1_auc = 0.53082\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.494190  0.505810           1     0\n",
            "1   0.480921  0.519079           1     0\n",
            "2   0.488031  0.511969           1     0\n",
            "3   0.497442  0.502558           1     0\n",
            "4   0.534185  0.465815           0     0\n",
            "5   0.472856  0.527144           1     0\n",
            "6   0.466367  0.533633           1     0\n",
            "7   0.504955  0.495045           0     0\n",
            "8   0.448689  0.551311           1     0\n",
            "9   0.515770  0.484230           0     0\n",
            "10  0.453256  0.546744           1     0\n",
            "11  0.511058  0.488942           0     0\n",
            "12  0.516529  0.483471           0     0\n",
            "13  0.524172  0.475828           0     0\n",
            "14  0.472216  0.527784           1     0\n",
            "15  0.490014  0.509986           1     0\n",
            "16  0.499955  0.500045           1     0\n",
            "17  0.436232  0.563768           1     0\n",
            "18  0.491070  0.508930           1     0\n",
            "19  0.524587  0.475413           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/numerai28_6/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.520452657807309,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.5308246291575928,\n",
            "  'balacc': 0.5195018811885671,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/167120',\n",
            "  'info': None,\n",
            "  'logloss': 0.6920098650315166,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.16498947143554688,\n",
            "  'result': 0.5308246291575928,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'numerai28_6',\n",
            "  'training_duration': 133.57217288017273,\n",
            "  'utc': '2021-02-04T17:41:16',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.numerai28_6.1.TabNet executed in 140.553 seconds.\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.riccardo.0.TabNet.\n",
            "[499] CPU Utilization: 34.9%\n",
            "[499] Memory Usage: 31.9%\n",
            "[499] Disk Usage: 26.2%\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 41.1%\n",
            "[499] Disk Usage: 26.2%\n",
            "Assigning 2 cores (total=2) for new task riccardo.\n",
            "Assigning 7273 MB (total=13021 MB) for new riccardo task.\n",
            "Running task riccardo on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='riccardo', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7273, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/0/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 50.1%\n",
            "[499] Memory Usage: 31.8%\n",
            "[499] Disk Usage: 26.6%\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 40.9%\n",
            "[499] Disk Usage: 26.6%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 45.8%\n",
            "[499] Disk Usage: 26.9%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.667   | val_0_auc: 0.51137 | val_1_auc: 0.50714 |  0:00:05s\n",
            "epoch 1  | loss: 0.57089 | val_0_auc: 0.55821 | val_1_auc: 0.55364 |  0:00:10s\n",
            "epoch 2  | loss: 0.5465  | val_0_auc: 0.62565 | val_1_auc: 0.61925 |  0:00:15s\n",
            "epoch 3  | loss: 0.53456 | val_0_auc: 0.68895 | val_1_auc: 0.69761 |  0:00:20s\n",
            "epoch 4  | loss: 0.50609 | val_0_auc: 0.75835 | val_1_auc: 0.75336 |  0:00:25s\n",
            "epoch 5  | loss: 0.47543 | val_0_auc: 0.77658 | val_1_auc: 0.75502 |  0:00:30s\n",
            "epoch 6  | loss: 0.44625 | val_0_auc: 0.8378  | val_1_auc: 0.83165 |  0:00:35s\n",
            "epoch 7  | loss: 0.40763 | val_0_auc: 0.89633 | val_1_auc: 0.88287 |  0:00:40s\n",
            "epoch 8  | loss: 0.33696 | val_0_auc: 0.93617 | val_1_auc: 0.92054 |  0:00:45s\n",
            "epoch 9  | loss: 0.29568 | val_0_auc: 0.9485  | val_1_auc: 0.93293 |  0:00:50s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 48.3%\n",
            "[499] Disk Usage: 26.9%\n",
            "epoch 10 | loss: 0.25689 | val_0_auc: 0.96629 | val_1_auc: 0.95295 |  0:00:55s\n",
            "epoch 11 | loss: 0.22741 | val_0_auc: 0.98217 | val_1_auc: 0.97349 |  0:01:00s\n",
            "epoch 12 | loss: 0.16699 | val_0_auc: 0.98795 | val_1_auc: 0.98186 |  0:01:05s\n",
            "epoch 13 | loss: 0.14719 | val_0_auc: 0.99267 | val_1_auc: 0.9868  |  0:01:10s\n",
            "epoch 14 | loss: 0.12402 | val_0_auc: 0.99392 | val_1_auc: 0.98859 |  0:01:15s\n",
            "epoch 15 | loss: 0.11933 | val_0_auc: 0.99377 | val_1_auc: 0.9913  |  0:01:20s\n",
            "epoch 16 | loss: 0.10659 | val_0_auc: 0.99636 | val_1_auc: 0.99547 |  0:01:25s\n",
            "epoch 17 | loss: 0.08169 | val_0_auc: 0.99634 | val_1_auc: 0.99378 |  0:01:30s\n",
            "epoch 18 | loss: 0.08332 | val_0_auc: 0.99658 | val_1_auc: 0.99258 |  0:01:35s\n",
            "epoch 19 | loss: 0.06522 | val_0_auc: 0.99779 | val_1_auc: 0.99414 |  0:01:40s\n",
            "epoch 20 | loss: 0.05624 | val_0_auc: 0.99746 | val_1_auc: 0.99546 |  0:01:45s\n",
            "epoch 21 | loss: 0.05393 | val_0_auc: 0.9982  | val_1_auc: 0.99664 |  0:01:50s\n",
            "epoch 22 | loss: 0.04881 | val_0_auc: 0.99827 | val_1_auc: 0.99565 |  0:01:55s\n",
            "epoch 23 | loss: 0.04195 | val_0_auc: 0.99827 | val_1_auc: 0.99714 |  0:01:59s\n",
            "epoch 24 | loss: 0.03633 | val_0_auc: 0.99842 | val_1_auc: 0.99691 |  0:02:04s\n",
            "epoch 25 | loss: 0.03408 | val_0_auc: 0.99851 | val_1_auc: 0.9966  |  0:02:09s\n",
            "epoch 26 | loss: 0.03546 | val_0_auc: 0.9982  | val_1_auc: 0.99612 |  0:02:14s\n",
            "epoch 27 | loss: 0.03701 | val_0_auc: 0.99858 | val_1_auc: 0.99659 |  0:02:19s\n",
            "epoch 28 | loss: 0.03238 | val_0_auc: 0.99872 | val_1_auc: 0.99679 |  0:02:23s\n",
            "epoch 29 | loss: 0.03466 | val_0_auc: 0.99846 | val_1_auc: 0.99601 |  0:02:28s\n",
            "epoch 30 | loss: 0.03768 | val_0_auc: 0.9986  | val_1_auc: 0.99658 |  0:02:33s\n",
            "epoch 31 | loss: 0.03503 | val_0_auc: 0.99872 | val_1_auc: 0.99675 |  0:02:38s\n",
            "epoch 32 | loss: 0.02914 | val_0_auc: 0.9987  | val_1_auc: 0.99686 |  0:02:42s\n",
            "epoch 33 | loss: 0.03432 | val_0_auc: 0.99861 | val_1_auc: 0.9962  |  0:02:47s\n",
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_1_auc = 0.99714\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.999082  0.000918           0     0\n",
            "1   0.999984  0.000016           0     0\n",
            "2   0.999712  0.000288           0     0\n",
            "3   0.999971  0.000029           0     0\n",
            "4   0.374989  0.625011           1     0\n",
            "5   0.999964  0.000036           0     0\n",
            "6   0.999916  0.000084           0     0\n",
            "7   0.999330  0.000670           0     0\n",
            "8   0.999927  0.000073           0     0\n",
            "9   0.963946  0.036054           0     0\n",
            "10  0.999247  0.000753           0     0\n",
            "11  0.996801  0.003198           0     0\n",
            "12  0.999960  0.000040           0     0\n",
            "13  0.999231  0.000769           0     0\n",
            "14  0.999989  0.000011           0     0\n",
            "15  0.984199  0.015801           0     0\n",
            "16  0.999962  0.000038           0     0\n",
            "17  0.999935  0.000065           0     0\n",
            "18  0.999985  0.000015           0     0\n",
            "19  0.683651  0.316349           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.99,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.997144,\n",
            "  'balacc': 0.9933333333333334,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168338',\n",
            "  'info': None,\n",
            "  'logloss': 0.036618466990867675,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.19437146186828613,\n",
            "  'result': 0.997144,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'riccardo',\n",
            "  'training_duration': 170.8293068408966,\n",
            "  'utc': '2021-02-04T17:54:35',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.riccardo.0.TabNet executed in 799.264 seconds.\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.riccardo.1.TabNet.\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 28.7%\n",
            "[499] Disk Usage: 26.9%\n",
            "Assigning 2 cores (total=2) for new task riccardo.\n",
            "Assigning 7239 MB (total=13021 MB) for new riccardo task.\n",
            "Running task riccardo on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='riccardo', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7239, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/1/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 47.9%\n",
            "[499] Memory Usage: 37.9%\n",
            "[499] Disk Usage: 26.9%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.3%\n",
            "[499] Memory Usage: 44.0%\n",
            "[499] Disk Usage: 27.0%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.66601 | val_0_auc: 0.5515  | val_1_auc: 0.56464 |  0:00:05s\n",
            "epoch 1  | loss: 0.56959 | val_0_auc: 0.58685 | val_1_auc: 0.55981 |  0:00:10s\n",
            "epoch 2  | loss: 0.54824 | val_0_auc: 0.60301 | val_1_auc: 0.6131  |  0:00:15s\n",
            "[499] CPU Utilization: 51.6%\n",
            "[499] Memory Usage: 48.2%\n",
            "[499] Disk Usage: 27.3%\n",
            "epoch 3  | loss: 0.53214 | val_0_auc: 0.66944 | val_1_auc: 0.65383 |  0:00:20s\n",
            "epoch 4  | loss: 0.51409 | val_0_auc: 0.73586 | val_1_auc: 0.73888 |  0:00:25s\n",
            "epoch 5  | loss: 0.48564 | val_0_auc: 0.75167 | val_1_auc: 0.76851 |  0:00:30s\n",
            "epoch 6  | loss: 0.4559  | val_0_auc: 0.8034  | val_1_auc: 0.81025 |  0:00:36s\n",
            "epoch 7  | loss: 0.41987 | val_0_auc: 0.84762 | val_1_auc: 0.85107 |  0:00:41s\n",
            "epoch 8  | loss: 0.39534 | val_0_auc: 0.8813  | val_1_auc: 0.86616 |  0:00:46s\n",
            "epoch 9  | loss: 0.34361 | val_0_auc: 0.92687 | val_1_auc: 0.90928 |  0:00:51s\n",
            "epoch 10 | loss: 0.30401 | val_0_auc: 0.9488  | val_1_auc: 0.93429 |  0:00:56s\n",
            "epoch 11 | loss: 0.25307 | val_0_auc: 0.97177 | val_1_auc: 0.96294 |  0:01:02s\n",
            "epoch 12 | loss: 0.2043  | val_0_auc: 0.98107 | val_1_auc: 0.97318 |  0:01:07s\n",
            "epoch 13 | loss: 0.18065 | val_0_auc: 0.98588 | val_1_auc: 0.98034 |  0:01:12s\n",
            "epoch 14 | loss: 0.14777 | val_0_auc: 0.99181 | val_1_auc: 0.98879 |  0:01:17s\n",
            "epoch 15 | loss: 0.1123  | val_0_auc: 0.9953  | val_1_auc: 0.9932  |  0:01:22s\n",
            "epoch 16 | loss: 0.09982 | val_0_auc: 0.9965  | val_1_auc: 0.99399 |  0:01:27s\n",
            "epoch 17 | loss: 0.09879 | val_0_auc: 0.99229 | val_1_auc: 0.98748 |  0:01:33s\n",
            "epoch 18 | loss: 0.09894 | val_0_auc: 0.99702 | val_1_auc: 0.99546 |  0:01:38s\n",
            "epoch 19 | loss: 0.07962 | val_0_auc: 0.99728 | val_1_auc: 0.99531 |  0:01:43s\n",
            "epoch 20 | loss: 0.07206 | val_0_auc: 0.99729 | val_1_auc: 0.9957  |  0:01:48s\n",
            "epoch 21 | loss: 0.06337 | val_0_auc: 0.99839 | val_1_auc: 0.99633 |  0:01:53s\n",
            "epoch 22 | loss: 0.04923 | val_0_auc: 0.99866 | val_1_auc: 0.9966  |  0:01:58s\n",
            "epoch 23 | loss: 0.04648 | val_0_auc: 0.99755 | val_1_auc: 0.99584 |  0:02:04s\n",
            "epoch 24 | loss: 0.0539  | val_0_auc: 0.99852 | val_1_auc: 0.99627 |  0:02:09s\n",
            "epoch 25 | loss: 0.05448 | val_0_auc: 0.99841 | val_1_auc: 0.99553 |  0:02:14s\n",
            "[499] CPU Utilization: 51.6%\n",
            "[499] Memory Usage: 49.5%\n",
            "[499] Disk Usage: 27.3%\n",
            "epoch 26 | loss: 0.05551 | val_0_auc: 0.99792 | val_1_auc: 0.99715 |  0:02:19s\n",
            "epoch 27 | loss: 0.05942 | val_0_auc: 0.99833 | val_1_auc: 0.99526 |  0:02:24s\n",
            "epoch 28 | loss: 0.05431 | val_0_auc: 0.99839 | val_1_auc: 0.99706 |  0:02:29s\n",
            "epoch 29 | loss: 0.07053 | val_0_auc: 0.99746 | val_1_auc: 0.9966  |  0:02:35s\n",
            "epoch 30 | loss: 0.0735  | val_0_auc: 0.99764 | val_1_auc: 0.99563 |  0:02:40s\n",
            "epoch 31 | loss: 0.07188 | val_0_auc: 0.99666 | val_1_auc: 0.99542 |  0:02:45s\n",
            "epoch 32 | loss: 0.0671  | val_0_auc: 0.99801 | val_1_auc: 0.99646 |  0:02:50s\n",
            "epoch 33 | loss: 0.056   | val_0_auc: 0.99843 | val_1_auc: 0.9974  |  0:02:55s\n",
            "epoch 34 | loss: 0.04742 | val_0_auc: 0.99832 | val_1_auc: 0.99582 |  0:03:01s\n",
            "epoch 35 | loss: 0.04293 | val_0_auc: 0.99874 | val_1_auc: 0.99581 |  0:03:06s\n",
            "epoch 36 | loss: 0.03753 | val_0_auc: 0.99873 | val_1_auc: 0.99645 |  0:03:11s\n",
            "epoch 37 | loss: 0.03481 | val_0_auc: 0.99893 | val_1_auc: 0.99703 |  0:03:16s\n",
            "epoch 38 | loss: 0.03435 | val_0_auc: 0.99891 | val_1_auc: 0.9974  |  0:03:21s\n",
            "epoch 39 | loss: 0.03717 | val_0_auc: 0.99904 | val_1_auc: 0.99767 |  0:03:27s\n",
            "epoch 40 | loss: 0.03677 | val_0_auc: 0.99834 | val_1_auc: 0.99734 |  0:03:32s\n",
            "epoch 41 | loss: 0.04376 | val_0_auc: 0.99891 | val_1_auc: 0.99759 |  0:03:37s\n",
            "epoch 42 | loss: 0.03916 | val_0_auc: 0.9989  | val_1_auc: 0.99754 |  0:03:42s\n",
            "epoch 43 | loss: 0.03478 | val_0_auc: 0.99894 | val_1_auc: 0.99722 |  0:03:47s\n",
            "epoch 44 | loss: 0.03252 | val_0_auc: 0.99906 | val_1_auc: 0.99762 |  0:03:52s\n",
            "epoch 45 | loss: 0.03648 | val_0_auc: 0.99808 | val_1_auc: 0.99665 |  0:03:58s\n",
            "epoch 46 | loss: 0.04151 | val_0_auc: 0.99898 | val_1_auc: 0.99746 |  0:04:03s\n",
            "epoch 47 | loss: 0.03869 | val_0_auc: 0.99869 | val_1_auc: 0.99693 |  0:04:08s\n",
            "epoch 48 | loss: 0.03543 | val_0_auc: 0.99874 | val_1_auc: 0.99705 |  0:04:13s\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 49.5%\n",
            "[499] Disk Usage: 27.3%\n",
            "epoch 49 | loss: 0.03361 | val_0_auc: 0.99877 | val_1_auc: 0.99641 |  0:04:18s\n",
            "\n",
            "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_1_auc = 0.99767\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1 predictions truth\n",
            "0   0.999996  0.000004           0     0\n",
            "1   0.999998  0.000002           0     0\n",
            "2   0.999998  0.000002           0     0\n",
            "3   0.999981  0.000019           0     0\n",
            "4   0.999993  0.000007           0     0\n",
            "5   0.999860  0.000140           0     0\n",
            "6   0.999997  0.000002           0     0\n",
            "7   0.999432  0.000568           0     0\n",
            "8   0.999992  0.000008           0     0\n",
            "9   0.999879  0.000121           0     0\n",
            "10  0.999941  0.000058           0     0\n",
            "11  0.999851  0.000149           0     0\n",
            "12  0.999808  0.000192           0     0\n",
            "13  0.999997  0.000003           0     0\n",
            "14  0.750291  0.249709           0     0\n",
            "15  0.999864  0.000135           0     0\n",
            "16  0.999981  0.000019           0     0\n",
            "17  0.999996  0.000004           0     0\n",
            "18  0.999776  0.000224           0     0\n",
            "19  0.999709  0.000291           0     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/riccardo/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.992,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': 0.997672,\n",
            "  'balacc': 0.9946666666666666,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168338',\n",
            "  'info': None,\n",
            "  'logloss': 0.03301121446945573,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.2136693000793457,\n",
            "  'result': 0.997672,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'riccardo',\n",
            "  'training_duration': 262.19192337989807,\n",
            "  'utc': '2021-02-04T18:04:46',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.riccardo.1.TabNet executed in 610.393 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Robert.0.TabNet.\n",
            "[499] CPU Utilization: 28.8%\n",
            "[499] Memory Usage: 32.9%\n",
            "[499] Disk Usage: 27.4%\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 39.1%\n",
            "[499] Disk Usage: 27.4%\n",
            "Assigning 2 cores (total=2) for new task Robert.\n",
            "Assigning 7237 MB (total=13021 MB) for new Robert task.\n",
            "Running task Robert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Robert', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7237, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/0/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 50.2%\n",
            "[499] Memory Usage: 31.9%\n",
            "[499] Disk Usage: 27.8%\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 38.5%\n",
            "[499] Disk Usage: 27.8%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 42.7%\n",
            "[499] Disk Usage: 28.0%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 2.54314 | val_0_accuracy: 0.10089 | val_1_accuracy: 0.086   |  0:00:04s\n",
            "epoch 1  | loss: 2.33573 | val_0_accuracy: 0.10333 | val_1_accuracy: 0.1     |  0:00:07s\n",
            "epoch 2  | loss: 2.30318 | val_0_accuracy: 0.10744 | val_1_accuracy: 0.108   |  0:00:11s\n",
            "epoch 3  | loss: 2.28729 | val_0_accuracy: 0.11344 | val_1_accuracy: 0.114   |  0:00:15s\n",
            "epoch 4  | loss: 2.25787 | val_0_accuracy: 0.12522 | val_1_accuracy: 0.128   |  0:00:19s\n",
            "epoch 5  | loss: 2.20774 | val_0_accuracy: 0.129   | val_1_accuracy: 0.131   |  0:00:23s\n",
            "epoch 6  | loss: 2.18323 | val_0_accuracy: 0.13    | val_1_accuracy: 0.12    |  0:00:27s\n",
            "epoch 7  | loss: 2.16956 | val_0_accuracy: 0.14456 | val_1_accuracy: 0.152   |  0:00:31s\n",
            "epoch 8  | loss: 2.1632  | val_0_accuracy: 0.14422 | val_1_accuracy: 0.127   |  0:00:35s\n",
            "epoch 9  | loss: 2.15906 | val_0_accuracy: 0.13533 | val_1_accuracy: 0.121   |  0:00:39s\n",
            "epoch 10 | loss: 2.14097 | val_0_accuracy: 0.15122 | val_1_accuracy: 0.147   |  0:00:43s\n",
            "epoch 11 | loss: 2.11973 | val_0_accuracy: 0.16244 | val_1_accuracy: 0.164   |  0:00:47s\n",
            "epoch 12 | loss: 2.11637 | val_0_accuracy: 0.16411 | val_1_accuracy: 0.156   |  0:00:51s\n",
            "epoch 13 | loss: 2.10245 | val_0_accuracy: 0.17089 | val_1_accuracy: 0.155   |  0:00:55s\n",
            "epoch 14 | loss: 2.09176 | val_0_accuracy: 0.19244 | val_1_accuracy: 0.194   |  0:00:59s\n",
            "epoch 15 | loss: 2.08903 | val_0_accuracy: 0.19111 | val_1_accuracy: 0.184   |  0:01:03s\n",
            "[499] CPU Utilization: 51.7%\n",
            "[499] Memory Usage: 45.7%\n",
            "[499] Disk Usage: 28.1%\n",
            "epoch 16 | loss: 2.06976 | val_0_accuracy: 0.20744 | val_1_accuracy: 0.188   |  0:01:07s\n",
            "epoch 17 | loss: 2.07094 | val_0_accuracy: 0.20922 | val_1_accuracy: 0.197   |  0:01:11s\n",
            "epoch 18 | loss: 2.06236 | val_0_accuracy: 0.21133 | val_1_accuracy: 0.199   |  0:01:15s\n",
            "epoch 19 | loss: 2.0583  | val_0_accuracy: 0.22078 | val_1_accuracy: 0.204   |  0:01:19s\n",
            "epoch 20 | loss: 2.03679 | val_0_accuracy: 0.22222 | val_1_accuracy: 0.208   |  0:01:23s\n",
            "epoch 21 | loss: 2.02651 | val_0_accuracy: 0.22856 | val_1_accuracy: 0.225   |  0:01:27s\n",
            "epoch 22 | loss: 2.03284 | val_0_accuracy: 0.24033 | val_1_accuracy: 0.228   |  0:01:31s\n",
            "epoch 23 | loss: 2.03199 | val_0_accuracy: 0.24556 | val_1_accuracy: 0.229   |  0:01:35s\n",
            "epoch 24 | loss: 2.02306 | val_0_accuracy: 0.25111 | val_1_accuracy: 0.228   |  0:01:39s\n",
            "epoch 25 | loss: 2.0092  | val_0_accuracy: 0.25456 | val_1_accuracy: 0.224   |  0:01:43s\n",
            "epoch 26 | loss: 1.99928 | val_0_accuracy: 0.25522 | val_1_accuracy: 0.229   |  0:01:47s\n",
            "epoch 27 | loss: 1.97927 | val_0_accuracy: 0.26367 | val_1_accuracy: 0.23    |  0:01:51s\n",
            "epoch 28 | loss: 1.9691  | val_0_accuracy: 0.26833 | val_1_accuracy: 0.248   |  0:01:55s\n",
            "epoch 29 | loss: 1.97132 | val_0_accuracy: 0.26667 | val_1_accuracy: 0.253   |  0:01:59s\n",
            "epoch 30 | loss: 1.96976 | val_0_accuracy: 0.27233 | val_1_accuracy: 0.261   |  0:02:03s\n",
            "epoch 31 | loss: 1.96524 | val_0_accuracy: 0.27467 | val_1_accuracy: 0.255   |  0:02:07s\n",
            "epoch 32 | loss: 1.95125 | val_0_accuracy: 0.27789 | val_1_accuracy: 0.258   |  0:02:11s\n",
            "epoch 33 | loss: 1.94196 | val_0_accuracy: 0.27256 | val_1_accuracy: 0.252   |  0:02:15s\n",
            "epoch 34 | loss: 1.92693 | val_0_accuracy: 0.282   | val_1_accuracy: 0.265   |  0:02:19s\n",
            "epoch 35 | loss: 1.92466 | val_0_accuracy: 0.27844 | val_1_accuracy: 0.27    |  0:02:23s\n",
            "epoch 36 | loss: 1.92744 | val_0_accuracy: 0.27867 | val_1_accuracy: 0.254   |  0:02:27s\n",
            "epoch 37 | loss: 1.93631 | val_0_accuracy: 0.28489 | val_1_accuracy: 0.255   |  0:02:31s\n",
            "epoch 38 | loss: 1.92678 | val_0_accuracy: 0.28733 | val_1_accuracy: 0.272   |  0:02:35s\n",
            "epoch 39 | loss: 1.92278 | val_0_accuracy: 0.28778 | val_1_accuracy: 0.286   |  0:02:39s\n",
            "epoch 40 | loss: 1.92247 | val_0_accuracy: 0.28733 | val_1_accuracy: 0.283   |  0:02:43s\n",
            "epoch 41 | loss: 1.91266 | val_0_accuracy: 0.29644 | val_1_accuracy: 0.287   |  0:02:47s\n",
            "epoch 42 | loss: 1.9063  | val_0_accuracy: 0.30356 | val_1_accuracy: 0.316   |  0:02:51s\n",
            "epoch 43 | loss: 1.89753 | val_0_accuracy: 0.30256 | val_1_accuracy: 0.298   |  0:02:55s\n",
            "epoch 44 | loss: 1.87676 | val_0_accuracy: 0.30944 | val_1_accuracy: 0.295   |  0:02:59s\n",
            "epoch 45 | loss: 1.87529 | val_0_accuracy: 0.30856 | val_1_accuracy: 0.282   |  0:03:03s\n",
            "[499] CPU Utilization: 51.7%\n",
            "[499] Memory Usage: 46.1%\n",
            "[499] Disk Usage: 28.1%\n",
            "epoch 46 | loss: 1.87047 | val_0_accuracy: 0.32011 | val_1_accuracy: 0.302   |  0:03:07s\n",
            "epoch 47 | loss: 1.85941 | val_0_accuracy: 0.32311 | val_1_accuracy: 0.284   |  0:03:11s\n",
            "epoch 48 | loss: 1.8517  | val_0_accuracy: 0.325   | val_1_accuracy: 0.278   |  0:03:15s\n",
            "epoch 49 | loss: 1.84841 | val_0_accuracy: 0.32022 | val_1_accuracy: 0.297   |  0:03:18s\n",
            "epoch 50 | loss: 1.84053 | val_0_accuracy: 0.32489 | val_1_accuracy: 0.305   |  0:03:22s\n",
            "epoch 51 | loss: 1.84037 | val_0_accuracy: 0.32433 | val_1_accuracy: 0.313   |  0:03:26s\n",
            "epoch 52 | loss: 1.83735 | val_0_accuracy: 0.33144 | val_1_accuracy: 0.314   |  0:03:30s\n",
            "\n",
            "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_1_accuracy = 0.316\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3         4         5         6         7         8         9 predictions truth\n",
            "0   0.035317  0.018264  0.214740  0.114683  0.161674  0.128601  0.150060  0.132664  0.013473  0.030525           2     2\n",
            "1   0.011375  0.004028  0.107487  0.231724  0.107640  0.198029  0.222612  0.107136  0.001274  0.008696           3     2\n",
            "2   0.011361  0.005741  0.111817  0.166623  0.152540  0.174361  0.202922  0.159910  0.001574  0.013152           6     2\n",
            "3   0.047333  0.024918  0.067619  0.147229  0.075283  0.218994  0.026248  0.286966  0.008606  0.096804           7     2\n",
            "4   0.083372  0.170995  0.075113  0.085131  0.069132  0.084351  0.063175  0.083712  0.096868  0.188150           9     2\n",
            "5   0.090474  0.144913  0.095945  0.090834  0.072661  0.091225  0.064174  0.084871  0.099779  0.165123           9     2\n",
            "6   0.462873  0.027951  0.092327  0.033026  0.041030  0.042903  0.009835  0.058187  0.206167  0.025700           0     2\n",
            "7   0.027574  0.061938  0.092491  0.120526  0.107112  0.205256  0.036524  0.273814  0.007639  0.067125           7     2\n",
            "8   0.027933  0.034657  0.156862  0.105398  0.162908  0.157316  0.082056  0.219421  0.009665  0.043784           7     2\n",
            "9   0.086990  0.061289  0.136216  0.053308  0.114190  0.083787  0.035317  0.169100  0.080940  0.178863           9     2\n",
            "10  0.071134  0.062449  0.177049  0.065319  0.146948  0.084737  0.081816  0.133427  0.069051  0.108070           2     2\n",
            "11  0.052007  0.248218  0.023770  0.173773  0.026133  0.097504  0.086683  0.035240  0.048594  0.208076           1     2\n",
            "12  0.320825  0.024821  0.160111  0.120718  0.049762  0.092545  0.052455  0.042198  0.116926  0.019639           0     2\n",
            "13  0.311272  0.029571  0.184039  0.075250  0.058091  0.071473  0.038242  0.044088  0.164559  0.023416           0     2\n",
            "14  0.011680  0.014598  0.148297  0.115857  0.185724  0.145226  0.191488  0.147407  0.005143  0.034579           6     2\n",
            "15  0.010683  0.008254  0.040570  0.144877  0.174833  0.219761  0.090982  0.302446  0.000588  0.007006           7     2\n",
            "16  0.086238  0.055467  0.157950  0.103111  0.131145  0.107369  0.120188  0.099644  0.067733  0.071155           2     2\n",
            "17  0.062928  0.347341  0.041402  0.058601  0.059195  0.062070  0.049779  0.050313  0.109590  0.158782           1     2\n",
            "18  0.013562  0.008519  0.068029  0.196859  0.129887  0.201206  0.161171  0.202499  0.001358  0.016910           7     2\n",
            "19  0.051079  0.284334  0.057309  0.043070  0.037800  0.050314  0.024901  0.047499  0.127331  0.276362           1     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.316,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.318427776761688,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168332',\n",
            "  'info': None,\n",
            "  'logloss': 1.9427597013067834,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.11124992370605469,\n",
            "  'result': 1.9427597013067834,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Robert',\n",
            "  'training_duration': 213.73605108261108,\n",
            "  'utc': '2021-02-04T18:19:09',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Robert.0.TabNet executed in 863.767 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Robert.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Robert.\n",
            "Assigning 7132 MB (total=13021 MB) for new Robert task.\n",
            "Running task Robert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Robert', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7132, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/1/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 48.3%\n",
            "[499] Memory Usage: 35.3%\n",
            "[499] Disk Usage: 28.1%\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.1%\n",
            "[499] Disk Usage: 28.1%\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 43.5%\n",
            "[499] Disk Usage: 28.3%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 2.54645 | val_0_accuracy: 0.10233 | val_1_accuracy: 0.112   |  0:00:03s\n",
            "epoch 1  | loss: 2.33985 | val_0_accuracy: 0.104   | val_1_accuracy: 0.098   |  0:00:07s\n",
            "epoch 2  | loss: 2.30921 | val_0_accuracy: 0.102   | val_1_accuracy: 0.11    |  0:00:11s\n",
            "epoch 3  | loss: 2.28939 | val_0_accuracy: 0.10067 | val_1_accuracy: 0.111   |  0:00:15s\n",
            "epoch 4  | loss: 2.25023 | val_0_accuracy: 0.11322 | val_1_accuracy: 0.106   |  0:00:19s\n",
            "epoch 5  | loss: 2.19482 | val_0_accuracy: 0.12589 | val_1_accuracy: 0.12    |  0:00:23s\n",
            "epoch 6  | loss: 2.15433 | val_0_accuracy: 0.13356 | val_1_accuracy: 0.148   |  0:00:27s\n",
            "epoch 7  | loss: 2.13022 | val_0_accuracy: 0.15056 | val_1_accuracy: 0.169   |  0:00:31s\n",
            "epoch 8  | loss: 2.11236 | val_0_accuracy: 0.16122 | val_1_accuracy: 0.18    |  0:00:35s\n",
            "epoch 9  | loss: 2.10006 | val_0_accuracy: 0.16922 | val_1_accuracy: 0.174   |  0:00:39s\n",
            "epoch 10 | loss: 2.09095 | val_0_accuracy: 0.16789 | val_1_accuracy: 0.168   |  0:00:43s\n",
            "epoch 11 | loss: 2.07979 | val_0_accuracy: 0.17889 | val_1_accuracy: 0.17    |  0:00:47s\n",
            "epoch 12 | loss: 2.0728  | val_0_accuracy: 0.19378 | val_1_accuracy: 0.196   |  0:00:51s\n",
            "epoch 13 | loss: 2.06148 | val_0_accuracy: 0.208   | val_1_accuracy: 0.217   |  0:00:55s\n",
            "epoch 14 | loss: 2.03972 | val_0_accuracy: 0.21556 | val_1_accuracy: 0.221   |  0:00:59s\n",
            "epoch 15 | loss: 2.02824 | val_0_accuracy: 0.21989 | val_1_accuracy: 0.232   |  0:01:03s\n",
            "epoch 16 | loss: 2.01663 | val_0_accuracy: 0.23    | val_1_accuracy: 0.221   |  0:01:07s\n",
            "epoch 17 | loss: 2.00165 | val_0_accuracy: 0.25433 | val_1_accuracy: 0.246   |  0:01:11s\n",
            "epoch 18 | loss: 1.98536 | val_0_accuracy: 0.24233 | val_1_accuracy: 0.241   |  0:01:15s\n",
            "epoch 19 | loss: 1.97595 | val_0_accuracy: 0.25344 | val_1_accuracy: 0.244   |  0:01:18s\n",
            "epoch 20 | loss: 1.9616  | val_0_accuracy: 0.265   | val_1_accuracy: 0.257   |  0:01:22s\n",
            "epoch 21 | loss: 1.94825 | val_0_accuracy: 0.27356 | val_1_accuracy: 0.259   |  0:01:26s\n",
            "epoch 22 | loss: 1.93194 | val_0_accuracy: 0.28444 | val_1_accuracy: 0.248   |  0:01:30s\n",
            "epoch 23 | loss: 1.92516 | val_0_accuracy: 0.28333 | val_1_accuracy: 0.274   |  0:01:34s\n",
            "epoch 24 | loss: 1.94078 | val_0_accuracy: 0.28111 | val_1_accuracy: 0.272   |  0:01:38s\n",
            "epoch 25 | loss: 1.94275 | val_0_accuracy: 0.28922 | val_1_accuracy: 0.274   |  0:01:42s\n",
            "epoch 26 | loss: 1.92362 | val_0_accuracy: 0.29778 | val_1_accuracy: 0.274   |  0:01:46s\n",
            "epoch 27 | loss: 1.89869 | val_0_accuracy: 0.30089 | val_1_accuracy: 0.28    |  0:01:50s\n",
            "epoch 28 | loss: 1.89839 | val_0_accuracy: 0.28744 | val_1_accuracy: 0.291   |  0:01:54s\n",
            "[499] CPU Utilization: 51.7%\n",
            "[499] Memory Usage: 46.3%\n",
            "[499] Disk Usage: 28.3%\n",
            "epoch 29 | loss: 1.90218 | val_0_accuracy: 0.30011 | val_1_accuracy: 0.293   |  0:01:58s\n",
            "epoch 30 | loss: 1.89129 | val_0_accuracy: 0.30533 | val_1_accuracy: 0.287   |  0:02:02s\n",
            "epoch 31 | loss: 1.87999 | val_0_accuracy: 0.31367 | val_1_accuracy: 0.293   |  0:02:06s\n",
            "epoch 32 | loss: 1.86504 | val_0_accuracy: 0.318   | val_1_accuracy: 0.29    |  0:02:10s\n",
            "epoch 33 | loss: 1.8665  | val_0_accuracy: 0.32056 | val_1_accuracy: 0.299   |  0:02:14s\n",
            "epoch 34 | loss: 1.85794 | val_0_accuracy: 0.31567 | val_1_accuracy: 0.294   |  0:02:18s\n",
            "epoch 35 | loss: 1.8687  | val_0_accuracy: 0.32233 | val_1_accuracy: 0.305   |  0:02:22s\n",
            "epoch 36 | loss: 1.84928 | val_0_accuracy: 0.32611 | val_1_accuracy: 0.312   |  0:02:26s\n",
            "epoch 37 | loss: 1.8176  | val_0_accuracy: 0.33522 | val_1_accuracy: 0.302   |  0:02:30s\n",
            "epoch 38 | loss: 1.79564 | val_0_accuracy: 0.34344 | val_1_accuracy: 0.313   |  0:02:34s\n",
            "epoch 39 | loss: 1.79105 | val_0_accuracy: 0.335   | val_1_accuracy: 0.315   |  0:02:38s\n",
            "epoch 40 | loss: 1.7853  | val_0_accuracy: 0.345   | val_1_accuracy: 0.331   |  0:02:42s\n",
            "epoch 41 | loss: 1.78115 | val_0_accuracy: 0.337   | val_1_accuracy: 0.296   |  0:02:46s\n",
            "epoch 42 | loss: 1.78053 | val_0_accuracy: 0.35267 | val_1_accuracy: 0.302   |  0:02:49s\n",
            "epoch 43 | loss: 1.76352 | val_0_accuracy: 0.35467 | val_1_accuracy: 0.312   |  0:02:53s\n",
            "epoch 44 | loss: 1.75521 | val_0_accuracy: 0.35644 | val_1_accuracy: 0.302   |  0:02:57s\n",
            "epoch 45 | loss: 1.75221 | val_0_accuracy: 0.35744 | val_1_accuracy: 0.32    |  0:03:01s\n",
            "epoch 46 | loss: 1.74498 | val_0_accuracy: 0.36233 | val_1_accuracy: 0.308   |  0:03:05s\n",
            "epoch 47 | loss: 1.74219 | val_0_accuracy: 0.36244 | val_1_accuracy: 0.315   |  0:03:09s\n",
            "epoch 48 | loss: 1.73084 | val_0_accuracy: 0.36644 | val_1_accuracy: 0.301   |  0:03:13s\n",
            "epoch 49 | loss: 1.72467 | val_0_accuracy: 0.36756 | val_1_accuracy: 0.313   |  0:03:17s\n",
            "epoch 50 | loss: 1.71936 | val_0_accuracy: 0.37589 | val_1_accuracy: 0.332   |  0:03:21s\n",
            "epoch 51 | loss: 1.7104  | val_0_accuracy: 0.38133 | val_1_accuracy: 0.337   |  0:03:25s\n",
            "epoch 52 | loss: 1.6886  | val_0_accuracy: 0.38844 | val_1_accuracy: 0.338   |  0:03:29s\n",
            "epoch 53 | loss: 1.68649 | val_0_accuracy: 0.38767 | val_1_accuracy: 0.329   |  0:03:33s\n",
            "epoch 54 | loss: 1.68467 | val_0_accuracy: 0.38711 | val_1_accuracy: 0.331   |  0:03:37s\n",
            "epoch 55 | loss: 1.69128 | val_0_accuracy: 0.383   | val_1_accuracy: 0.322   |  0:03:41s\n",
            "epoch 56 | loss: 1.6963  | val_0_accuracy: 0.37611 | val_1_accuracy: 0.315   |  0:03:45s\n",
            "epoch 57 | loss: 1.7054  | val_0_accuracy: 0.381   | val_1_accuracy: 0.313   |  0:03:49s\n",
            "epoch 58 | loss: 1.73093 | val_0_accuracy: 0.37633 | val_1_accuracy: 0.305   |  0:03:53s\n",
            "epoch 59 | loss: 1.73459 | val_0_accuracy: 0.37633 | val_1_accuracy: 0.33    |  0:03:57s\n",
            "[499] CPU Utilization: 51.7%\n",
            "[499] Memory Usage: 46.6%\n",
            "[499] Disk Usage: 28.3%\n",
            "epoch 60 | loss: 1.6954  | val_0_accuracy: 0.37722 | val_1_accuracy: 0.321   |  0:04:01s\n",
            "epoch 61 | loss: 1.71278 | val_0_accuracy: 0.37611 | val_1_accuracy: 0.321   |  0:04:05s\n",
            "epoch 62 | loss: 1.70534 | val_0_accuracy: 0.37933 | val_1_accuracy: 0.334   |  0:04:09s\n",
            "\n",
            "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_1_accuracy = 0.338\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3         4         5         6         7         8         9 predictions truth\n",
            "0   0.009629  0.009697  0.053963  0.172609  0.115010  0.090669  0.184067  0.313488  0.005460  0.045408           7     2\n",
            "1   0.114965  0.037968  0.039111  0.000778  0.003442  0.001497  0.000917  0.001642  0.779646  0.020035           8     2\n",
            "2   0.003745  0.005780  0.087919  0.198559  0.165318  0.179388  0.185595  0.165154  0.001016  0.007527           3     2\n",
            "3   0.006788  0.005422  0.259608  0.116580  0.158251  0.288248  0.050395  0.106297  0.004848  0.003563           5     2\n",
            "4   0.006662  0.011913  0.092334  0.128104  0.150129  0.079487  0.403730  0.110622  0.001816  0.015203           6     2\n",
            "5   0.149433  0.204501  0.033581  0.050134  0.032023  0.037991  0.019724  0.046741  0.285277  0.140594           8     2\n",
            "6   0.010109  0.005560  0.291872  0.055706  0.306895  0.089239  0.159248  0.070757  0.007013  0.003600           4     2\n",
            "7   0.015979  0.012977  0.231339  0.090138  0.263167  0.146568  0.114813  0.102289  0.015166  0.007561           4     2\n",
            "8   0.603460  0.012571  0.022318  0.083388  0.033417  0.033299  0.012919  0.030699  0.140676  0.027252           0     2\n",
            "9   0.004013  0.005054  0.050765  0.166342  0.129386  0.081593  0.286740  0.254832  0.001495  0.019780           6     2\n",
            "10  0.123241  0.015957  0.256421  0.068041  0.211469  0.073686  0.111952  0.055391  0.070838  0.013004           2     2\n",
            "11  0.128423  0.026645  0.233996  0.081754  0.087399  0.112292  0.035363  0.102638  0.146463  0.045027           2     2\n",
            "12  0.006943  0.004364  0.183348  0.185089  0.130468  0.255118  0.105696  0.121930  0.002036  0.005008           5     2\n",
            "13  0.009965  0.003005  0.278901  0.076472  0.296191  0.115648  0.136380  0.076262  0.004891  0.002284           4     2\n",
            "14  0.015461  0.002434  0.124372  0.242794  0.095407  0.203990  0.069604  0.229798  0.003344  0.012795           3     2\n",
            "15  0.009818  0.092888  0.067525  0.148109  0.158036  0.173456  0.091121  0.196539  0.015785  0.046724           7     2\n",
            "16  0.076986  0.124338  0.110527  0.103741  0.116627  0.100846  0.090349  0.107323  0.065713  0.103550           1     2\n",
            "17  0.006335  0.001502  0.343126  0.045467  0.347659  0.104381  0.084740  0.058645  0.007410  0.000736           4     2\n",
            "18  0.004357  0.713531  0.001620  0.021489  0.013439  0.016150  0.004603  0.039799  0.032672  0.152339           1     2\n",
            "19  0.210814  0.087604  0.057801  0.017039  0.019458  0.016184  0.011540  0.030241  0.376586  0.172734           8     2\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Robert/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.338,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.3385538126151857,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168332',\n",
            "  'info': None,\n",
            "  'logloss': 1.8762716408618698,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.12888884544372559,\n",
            "  'result': 1.8762716408618698,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Robert',\n",
            "  'training_duration': 252.22026371955872,\n",
            "  'utc': '2021-02-04T18:28:55',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Robert.1.TabNet executed in 585.433 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Shuttle.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Shuttle.\n",
            "Assigning 7149 MB (total=13021 MB) for new Shuttle task.\n",
            "Running task Shuttle on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Shuttle', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=7149, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.46207 | val_0_accuracy: 0.32975 | val_1_accuracy: 0.3231  |  0:00:03s\n",
            "epoch 1  | loss: 0.05412 | val_0_accuracy: 0.57308 | val_1_accuracy: 0.58259 |  0:00:06s\n",
            "epoch 2  | loss: 0.03077 | val_0_accuracy: 0.7119  | val_1_accuracy: 0.70414 |  0:00:10s\n",
            "epoch 3  | loss: 0.02544 | val_0_accuracy: 0.91837 | val_1_accuracy: 0.91879 |  0:00:13s\n",
            "epoch 4  | loss: 0.02176 | val_0_accuracy: 0.9842  | val_1_accuracy: 0.98293 |  0:00:16s\n",
            "epoch 5  | loss: 0.01705 | val_0_accuracy: 0.96034 | val_1_accuracy: 0.95948 |  0:00:20s\n",
            "epoch 6  | loss: 0.01803 | val_0_accuracy: 0.99592 | val_1_accuracy: 0.99603 |  0:00:23s\n",
            "epoch 7  | loss: 0.01622 | val_0_accuracy: 0.99619 | val_1_accuracy: 0.99621 |  0:00:26s\n",
            "epoch 8  | loss: 0.01418 | val_0_accuracy: 0.99571 | val_1_accuracy: 0.99603 |  0:00:30s\n",
            "epoch 9  | loss: 0.01874 | val_0_accuracy: 0.99602 | val_1_accuracy: 0.99586 |  0:00:33s\n",
            "epoch 10 | loss: 0.02038 | val_0_accuracy: 0.99577 | val_1_accuracy: 0.99569 |  0:00:36s\n",
            "epoch 11 | loss: 0.01672 | val_0_accuracy: 0.99619 | val_1_accuracy: 0.99621 |  0:00:40s\n",
            "epoch 12 | loss: 0.01239 | val_0_accuracy: 0.99632 | val_1_accuracy: 0.99621 |  0:00:43s\n",
            "epoch 13 | loss: 0.01195 | val_0_accuracy: 0.99628 | val_1_accuracy: 0.99621 |  0:00:47s\n",
            "epoch 14 | loss: 0.01565 | val_0_accuracy: 0.98762 | val_1_accuracy: 0.98724 |  0:00:50s\n",
            "epoch 15 | loss: 0.01337 | val_0_accuracy: 0.9954  | val_1_accuracy: 0.99466 |  0:00:53s\n",
            "epoch 16 | loss: 0.01213 | val_0_accuracy: 0.99667 | val_1_accuracy: 0.9969  |  0:00:57s\n",
            "epoch 17 | loss: 0.0111  | val_0_accuracy: 0.99632 | val_1_accuracy: 0.99638 |  0:01:00s\n",
            "epoch 18 | loss: 0.01106 | val_0_accuracy: 0.9969  | val_1_accuracy: 0.99672 |  0:01:03s\n",
            "epoch 19 | loss: 0.01147 | val_0_accuracy: 0.99701 | val_1_accuracy: 0.99707 |  0:01:07s\n",
            "epoch 20 | loss: 0.01248 | val_0_accuracy: 0.99669 | val_1_accuracy: 0.9969  |  0:01:10s\n",
            "epoch 21 | loss: 0.00968 | val_0_accuracy: 0.99648 | val_1_accuracy: 0.99672 |  0:01:13s\n",
            "epoch 22 | loss: 0.01101 | val_0_accuracy: 0.98375 | val_1_accuracy: 0.98345 |  0:01:17s\n",
            "epoch 23 | loss: 0.01242 | val_0_accuracy: 0.99661 | val_1_accuracy: 0.9969  |  0:01:20s\n",
            "epoch 24 | loss: 0.01253 | val_0_accuracy: 0.9841  | val_1_accuracy: 0.98362 |  0:01:23s\n",
            "epoch 25 | loss: 0.01363 | val_0_accuracy: 0.99638 | val_1_accuracy: 0.99707 |  0:01:27s\n",
            "[499] CPU Utilization: 46.7%\n",
            "[499] Memory Usage: 30.1%\n",
            "[499] Disk Usage: 28.4%\n",
            "epoch 26 | loss: 0.01078 | val_0_accuracy: 0.98914 | val_1_accuracy: 0.98931 |  0:01:30s\n",
            "epoch 27 | loss: 0.01193 | val_0_accuracy: 0.99684 | val_1_accuracy: 0.9969  |  0:01:34s\n",
            "epoch 28 | loss: 0.01646 | val_0_accuracy: 0.99663 | val_1_accuracy: 0.99638 |  0:01:37s\n",
            "epoch 29 | loss: 0.02269 | val_0_accuracy: 0.99619 | val_1_accuracy: 0.99586 |  0:01:40s\n",
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_1_accuracy = 0.99707\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            1             2             3             4             5             6             7 predictions truth\n",
            "0   0.999993  1.480328e-06  3.394440e-06  1.253692e-09  1.643305e-06  2.852735e-10  5.868610e-07           1     1\n",
            "1   0.999766  6.592824e-05  1.223047e-04  4.981224e-07  3.277423e-05  1.031994e-07  1.227784e-05           1     1\n",
            "2   1.000000  1.742659e-07  9.786549e-08  1.087089e-14  2.078640e-07  3.456310e-11  1.898787e-08           1     1\n",
            "3   0.999995  1.375957e-06  2.238474e-06  1.169216e-10  9.653628e-07  3.670923e-10  4.188284e-07           1     1\n",
            "4   0.999997  7.033679e-07  2.465096e-07  1.548635e-10  1.726921e-06  2.305115e-10  7.865068e-10           1     1\n",
            "5   0.999999  3.068062e-07  2.857139e-07  1.772135e-14  3.100916e-07  5.928497e-11  1.550855e-07           1     1\n",
            "6   0.999999  4.648385e-07  4.449832e-07  2.903481e-12  3.277635e-07  1.350073e-10  1.224786e-07           1     1\n",
            "7   0.999999  3.229531e-07  2.361455e-07  3.378754e-12  2.307285e-07  1.021013e-10  4.494593e-08           1     1\n",
            "8   0.999996  8.074302e-07  1.581122e-06  5.339848e-09  1.039884e-06  7.002058e-10  3.334341e-08           1     1\n",
            "9   0.999996  3.526760e-07  2.019656e-06  4.863655e-08  1.825160e-06  6.377850e-10  1.721633e-08           1     1\n",
            "10  0.999999  4.952944e-07  3.492324e-07  2.034581e-11  3.220804e-07  1.788867e-10  3.242035e-08           1     1\n",
            "11  0.999999  3.089445e-07  3.199753e-07  4.126154e-15  3.889328e-07  4.185844e-11  2.116578e-07           1     1\n",
            "12  0.999999  3.385365e-07  2.632964e-07  5.504695e-12  2.829331e-07  9.777276e-11  4.625800e-08           1     1\n",
            "13  0.999997  7.048034e-07  2.468850e-07  1.545383e-10  1.731021e-06  2.311869e-10  7.885496e-10           1     1\n",
            "14  0.999997  7.869658e-07  2.613759e-07  1.610802e-10  1.406432e-06  2.550902e-10  9.723556e-10           1     1\n",
            "15  0.999993  1.938616e-06  3.126339e-06  1.598860e-10  1.274540e-06  5.634154e-10  5.202153e-07           1     1\n",
            "16  0.999986  3.061468e-06  6.642028e-06  4.317553e-09  3.035946e-06  1.080718e-09  1.345403e-06           1     1\n",
            "17  0.999971  1.291800e-05  1.147908e-05  1.420562e-09  2.437490e-06  2.821706e-08  2.007981e-06           1     1\n",
            "18  0.999997  7.033679e-07  2.465096e-07  1.548635e-10  1.726921e-06  2.305115e-10  7.865068e-10           1     1\n",
            "19  0.999996  1.774539e-06  8.270346e-07  1.419976e-09  1.720604e-06  1.022043e-09  1.171817e-08           1     1\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9970689655172413,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.6583553222227049,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146212',\n",
            "  'info': None,\n",
            "  'logloss': 0.02063025241296877,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.10440945625305176,\n",
            "  'result': 0.02063025241296877,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Shuttle',\n",
            "  'training_duration': 101.80422520637512,\n",
            "  'utc': '2021-02-04T18:30:53',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Shuttle.0.TabNet executed in 118.479 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Shuttle.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Shuttle.\n",
            "Assigning 7056 MB (total=13021 MB) for new Shuttle task.\n",
            "Running task Shuttle on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Shuttle', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7056, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.48674 | val_0_accuracy: 0.7801  | val_1_accuracy: 0.77517 |  0:00:03s\n",
            "epoch 1  | loss: 0.0495  | val_0_accuracy: 0.59195 | val_1_accuracy: 0.59138 |  0:00:06s\n",
            "epoch 2  | loss: 0.03131 | val_0_accuracy: 0.75728 | val_1_accuracy: 0.76431 |  0:00:10s\n",
            "epoch 3  | loss: 0.02695 | val_0_accuracy: 0.92284 | val_1_accuracy: 0.91793 |  0:00:13s\n",
            "epoch 4  | loss: 0.02485 | val_0_accuracy: 0.98741 | val_1_accuracy: 0.98448 |  0:00:16s\n",
            "epoch 5  | loss: 0.01848 | val_0_accuracy: 0.98655 | val_1_accuracy: 0.98414 |  0:00:20s\n",
            "epoch 6  | loss: 0.01592 | val_0_accuracy: 0.99628 | val_1_accuracy: 0.99672 |  0:00:23s\n",
            "epoch 7  | loss: 0.01581 | val_0_accuracy: 0.99695 | val_1_accuracy: 0.99724 |  0:00:26s\n",
            "epoch 8  | loss: 0.01531 | val_0_accuracy: 0.99686 | val_1_accuracy: 0.99707 |  0:00:30s\n",
            "epoch 9  | loss: 0.01212 | val_0_accuracy: 0.99709 | val_1_accuracy: 0.99741 |  0:00:33s\n",
            "epoch 10 | loss: 0.01135 | val_0_accuracy: 0.98923 | val_1_accuracy: 0.9869  |  0:00:36s\n",
            "epoch 11 | loss: 0.00964 | val_0_accuracy: 0.99741 | val_1_accuracy: 0.99741 |  0:00:40s\n",
            "epoch 12 | loss: 0.00958 | val_0_accuracy: 0.99726 | val_1_accuracy: 0.99724 |  0:00:43s\n",
            "epoch 13 | loss: 0.00845 | val_0_accuracy: 0.99747 | val_1_accuracy: 0.99741 |  0:00:46s\n",
            "epoch 14 | loss: 0.00927 | val_0_accuracy: 0.99686 | val_1_accuracy: 0.99707 |  0:00:50s\n",
            "epoch 15 | loss: 0.01065 | val_0_accuracy: 0.9969  | val_1_accuracy: 0.99724 |  0:00:53s\n",
            "epoch 16 | loss: 0.00925 | val_0_accuracy: 0.99761 | val_1_accuracy: 0.99759 |  0:00:57s\n",
            "epoch 17 | loss: 0.00991 | val_0_accuracy: 0.99734 | val_1_accuracy: 0.99776 |  0:01:00s\n",
            "epoch 18 | loss: 0.00699 | val_0_accuracy: 0.9978  | val_1_accuracy: 0.99776 |  0:01:03s\n",
            "epoch 19 | loss: 0.0095  | val_0_accuracy: 0.99743 | val_1_accuracy: 0.99759 |  0:01:07s\n",
            "epoch 20 | loss: 0.01023 | val_0_accuracy: 0.99707 | val_1_accuracy: 0.99741 |  0:01:10s\n",
            "epoch 21 | loss: 0.00759 | val_0_accuracy: 0.99787 | val_1_accuracy: 0.9981  |  0:01:13s\n",
            "epoch 22 | loss: 0.00956 | val_0_accuracy: 0.99684 | val_1_accuracy: 0.99724 |  0:01:17s\n",
            "epoch 23 | loss: 0.00856 | val_0_accuracy: 0.99753 | val_1_accuracy: 0.99759 |  0:01:20s\n",
            "epoch 24 | loss: 0.00641 | val_0_accuracy: 0.99766 | val_1_accuracy: 0.99793 |  0:01:23s\n",
            "epoch 25 | loss: 0.00607 | val_0_accuracy: 0.99726 | val_1_accuracy: 0.99776 |  0:01:27s\n",
            "epoch 26 | loss: 0.00558 | val_0_accuracy: 0.99749 | val_1_accuracy: 0.99776 |  0:01:30s\n",
            "epoch 27 | loss: 0.00882 | val_0_accuracy: 0.9891  | val_1_accuracy: 0.98517 |  0:01:33s\n",
            "epoch 28 | loss: 0.00903 | val_0_accuracy: 0.99757 | val_1_accuracy: 0.99776 |  0:01:37s\n",
            "epoch 29 | loss: 0.01319 | val_0_accuracy: 0.99738 | val_1_accuracy: 0.99776 |  0:01:40s\n",
            "epoch 30 | loss: 0.01338 | val_0_accuracy: 0.99766 | val_1_accuracy: 0.9981  |  0:01:43s\n",
            "[499] CPU Utilization: 51.6%\n",
            "[499] Memory Usage: 30.2%\n",
            "[499] Disk Usage: 28.4%\n",
            "epoch 31 | loss: 0.01009 | val_0_accuracy: 0.98941 | val_1_accuracy: 0.98672 |  0:01:47s\n",
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_1_accuracy = 0.9981\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            1             2         3             4             5             6             7 predictions truth\n",
            "0   0.999785  3.845513e-06  0.000173  1.075543e-06  3.324657e-05  9.806362e-09  3.788993e-06           1     1\n",
            "1   0.998632  4.459530e-04  0.000907  5.101447e-09  1.381624e-05  4.522820e-10  1.196635e-06           1     1\n",
            "2   0.999991  3.316052e-08  0.000008  1.027256e-10  2.027953e-07  3.368715e-12  3.470364e-08           1     1\n",
            "3   0.999521  1.120182e-05  0.000455  1.334480e-06  4.355766e-06  1.057461e-08  6.895968e-06           1     1\n",
            "4   0.999578  9.029550e-06  0.000398  2.637390e-06  5.822554e-06  1.777188e-08  6.656754e-06           1     1\n",
            "5   0.999999  1.082535e-09  0.000001  3.926174e-14  1.805727e-07  3.353146e-14  1.304507e-08           1     1\n",
            "6   0.999995  1.053423e-08  0.000004  1.266982e-12  4.623684e-07  5.088531e-13  3.770998e-08           1     1\n",
            "7   0.999170  6.541181e-05  0.000758  3.409229e-09  3.058216e-06  2.559127e-10  3.762040e-06           1     1\n",
            "8   0.999995  1.014360e-08  0.000004  1.763748e-11  1.928484e-07  1.309646e-12  3.112126e-08           1     1\n",
            "9   0.999259  7.421130e-05  0.000652  1.308476e-06  1.244921e-05  3.128489e-09  1.252145e-06           1     1\n",
            "10  0.999992  7.633531e-08  0.000007  1.442891e-10  8.223390e-07  1.403386e-12  4.907770e-09           1     1\n",
            "11  0.999831  1.655242e-06  0.000141  7.434185e-06  1.396454e-05  2.956680e-08  4.599980e-06           1     1\n",
            "12  0.999780  2.369716e-06  0.000203  8.657990e-08  7.171849e-06  3.311305e-09  6.837620e-06           1     1\n",
            "13  0.999989  1.010200e-07  0.000010  2.704364e-10  3.653389e-07  3.583250e-12  1.292478e-08           1     1\n",
            "14  0.999353  2.642372e-05  0.000613  1.712351e-06  4.884458e-06  7.766980e-10  4.044917e-07           1     1\n",
            "15  0.999998  1.429996e-09  0.000001  9.474488e-14  1.581704e-07  4.315966e-14  1.244259e-08           1     1\n",
            "16  0.999992  2.911403e-08  0.000008  8.021123e-11  2.258577e-07  3.268163e-12  3.997041e-08           1     1\n",
            "17  0.999997  6.089221e-09  0.000003  7.636445e-12  1.463037e-07  4.435738e-13  1.639586e-08           1     1\n",
            "18  0.999994  1.664655e-08  0.000006  3.805838e-11  2.007805e-07  1.989806e-12  3.550327e-08           1     1\n",
            "19  0.999205  1.582398e-04  0.000630  9.348213e-09  5.958301e-06  2.972786e-10  7.851374e-07           1     1\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Shuttle/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.9981034482758621,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.7126050420168067,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/146212',\n",
            "  'info': None,\n",
            "  'logloss': 0.01041926004341205,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.09983372688293457,\n",
            "  'result': 0.01041926004341205,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Shuttle',\n",
            "  'training_duration': 108.24155592918396,\n",
            "  'utc': '2021-02-04T18:32:43',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Shuttle.1.TabNet executed in 110.088 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Volkert.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Volkert.\n",
            "Assigning 6989 MB (total=13021 MB) for new Volkert task.\n",
            "Running task Volkert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Volkert', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6989, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.94923 | val_0_accuracy: 0.21729 | val_1_accuracy: 0.21214 |  0:00:03s\n",
            "epoch 1  | loss: 1.55179 | val_0_accuracy: 0.27354 | val_1_accuracy: 0.26702 |  0:00:07s\n",
            "epoch 2  | loss: 1.45383 | val_0_accuracy: 0.23811 | val_1_accuracy: 0.23341 |  0:00:11s\n",
            "epoch 3  | loss: 1.40222 | val_0_accuracy: 0.23895 | val_1_accuracy: 0.23289 |  0:00:14s\n",
            "epoch 4  | loss: 1.34978 | val_0_accuracy: 0.22459 | val_1_accuracy: 0.22123 |  0:00:18s\n",
            "epoch 5  | loss: 1.32091 | val_0_accuracy: 0.26965 | val_1_accuracy: 0.26719 |  0:00:21s\n",
            "epoch 6  | loss: 1.29447 | val_0_accuracy: 0.31651 | val_1_accuracy: 0.3099  |  0:00:25s\n",
            "epoch 7  | loss: 1.27151 | val_0_accuracy: 0.32169 | val_1_accuracy: 0.31298 |  0:00:29s\n",
            "epoch 8  | loss: 1.25922 | val_0_accuracy: 0.37889 | val_1_accuracy: 0.37146 |  0:00:32s\n",
            "epoch 9  | loss: 1.24079 | val_0_accuracy: 0.40094 | val_1_accuracy: 0.39221 |  0:00:36s\n",
            "epoch 10 | loss: 1.2225  | val_0_accuracy: 0.42108 | val_1_accuracy: 0.42085 |  0:00:40s\n",
            "epoch 11 | loss: 1.21354 | val_0_accuracy: 0.44601 | val_1_accuracy: 0.43903 |  0:00:43s\n",
            "epoch 12 | loss: 1.20247 | val_0_accuracy: 0.46369 | val_1_accuracy: 0.45704 |  0:00:47s\n",
            "epoch 13 | loss: 1.1993  | val_0_accuracy: 0.4869  | val_1_accuracy: 0.48071 |  0:00:51s\n",
            "epoch 14 | loss: 1.18463 | val_0_accuracy: 0.49324 | val_1_accuracy: 0.48225 |  0:00:54s\n",
            "epoch 15 | loss: 1.18053 | val_0_accuracy: 0.52913 | val_1_accuracy: 0.51295 |  0:00:58s\n",
            "epoch 16 | loss: 1.18087 | val_0_accuracy: 0.537   | val_1_accuracy: 0.52632 |  0:01:02s\n",
            "epoch 17 | loss: 1.16133 | val_0_accuracy: 0.57265 | val_1_accuracy: 0.56097 |  0:01:05s\n",
            "[499] CPU Utilization: 45.6%\n",
            "[499] Memory Usage: 32.8%\n",
            "[499] Disk Usage: 28.5%\n",
            "epoch 18 | loss: 1.1549  | val_0_accuracy: 0.58919 | val_1_accuracy: 0.57246 |  0:01:09s\n",
            "epoch 19 | loss: 1.15009 | val_0_accuracy: 0.59117 | val_1_accuracy: 0.57554 |  0:01:13s\n",
            "epoch 20 | loss: 1.14102 | val_0_accuracy: 0.60946 | val_1_accuracy: 0.60213 |  0:01:16s\n",
            "epoch 21 | loss: 1.13618 | val_0_accuracy: 0.60998 | val_1_accuracy: 0.60264 |  0:01:20s\n",
            "epoch 22 | loss: 1.136   | val_0_accuracy: 0.61804 | val_1_accuracy: 0.59355 |  0:01:24s\n",
            "epoch 23 | loss: 1.12376 | val_0_accuracy: 0.59812 | val_1_accuracy: 0.58446 |  0:01:27s\n",
            "epoch 24 | loss: 1.12231 | val_0_accuracy: 0.6208  | val_1_accuracy: 0.6059  |  0:01:31s\n",
            "epoch 25 | loss: 1.11013 | val_0_accuracy: 0.62446 | val_1_accuracy: 0.60539 |  0:01:34s\n",
            "epoch 26 | loss: 1.10483 | val_0_accuracy: 0.62252 | val_1_accuracy: 0.59853 |  0:01:38s\n",
            "epoch 27 | loss: 1.10182 | val_0_accuracy: 0.62356 | val_1_accuracy: 0.60487 |  0:01:42s\n",
            "epoch 28 | loss: 1.09762 | val_0_accuracy: 0.60624 | val_1_accuracy: 0.59441 |  0:01:45s\n",
            "epoch 29 | loss: 1.10341 | val_0_accuracy: 0.62393 | val_1_accuracy: 0.61293 |  0:01:49s\n",
            "epoch 30 | loss: 1.09121 | val_0_accuracy: 0.63197 | val_1_accuracy: 0.60813 |  0:01:52s\n",
            "epoch 31 | loss: 1.08503 | val_0_accuracy: 0.62831 | val_1_accuracy: 0.6107  |  0:01:56s\n",
            "epoch 32 | loss: 1.08104 | val_0_accuracy: 0.63019 | val_1_accuracy: 0.6131  |  0:02:00s\n",
            "epoch 33 | loss: 1.07489 | val_0_accuracy: 0.63345 | val_1_accuracy: 0.60573 |  0:02:03s\n",
            "epoch 34 | loss: 1.06815 | val_0_accuracy: 0.64062 | val_1_accuracy: 0.61756 |  0:02:07s\n",
            "epoch 35 | loss: 1.06277 | val_0_accuracy: 0.63614 | val_1_accuracy: 0.61482 |  0:02:10s\n",
            "epoch 36 | loss: 1.06202 | val_0_accuracy: 0.64308 | val_1_accuracy: 0.62271 |  0:02:14s\n",
            "epoch 37 | loss: 1.06427 | val_0_accuracy: 0.63822 | val_1_accuracy: 0.61585 |  0:02:18s\n",
            "epoch 38 | loss: 1.05937 | val_0_accuracy: 0.63616 | val_1_accuracy: 0.61173 |  0:02:21s\n",
            "epoch 39 | loss: 1.05718 | val_0_accuracy: 0.63159 | val_1_accuracy: 0.61516 |  0:02:25s\n",
            "epoch 40 | loss: 1.06972 | val_0_accuracy: 0.63677 | val_1_accuracy: 0.61327 |  0:02:29s\n",
            "epoch 41 | loss: 1.05348 | val_0_accuracy: 0.64365 | val_1_accuracy: 0.62065 |  0:02:32s\n",
            "epoch 42 | loss: 1.04234 | val_0_accuracy: 0.64209 | val_1_accuracy: 0.61962 |  0:02:36s\n",
            "epoch 43 | loss: 1.04933 | val_0_accuracy: 0.64075 | val_1_accuracy: 0.61859 |  0:02:39s\n",
            "epoch 44 | loss: 1.04294 | val_0_accuracy: 0.63789 | val_1_accuracy: 0.61499 |  0:02:43s\n",
            "epoch 45 | loss: 1.04138 | val_0_accuracy: 0.64064 | val_1_accuracy: 0.61619 |  0:02:47s\n",
            "epoch 46 | loss: 1.03485 | val_0_accuracy: 0.64411 | val_1_accuracy: 0.62065 |  0:02:50s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_1_accuracy = 0.62271\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3         4         5             6             7         8         9 predictions truth\n",
            "0   0.266305  0.010784  0.134180  0.004457  0.000242  0.025666  3.224848e-05  2.578921e-04  0.552285  0.005792           8     0\n",
            "1   0.658351  0.015019  0.026898  0.015185  0.009172  0.105341  1.172561e-02  7.705027e-02  0.001993  0.079266           0     0\n",
            "2   0.556723  0.003652  0.049842  0.015442  0.002025  0.167773  8.208596e-03  9.238926e-02  0.020007  0.083938           0     0\n",
            "3   0.328224  0.008937  0.030755  0.002048  0.001322  0.208097  2.548064e-03  3.080527e-03  0.409879  0.005110           8     0\n",
            "4   0.196693  0.013936  0.289804  0.009093  0.014814  0.159979  1.069263e-03  6.014988e-04  0.312742  0.001268           8     0\n",
            "5   0.066065  0.003752  0.002432  0.091503  0.073648  0.010240  1.405441e-02  1.741742e-02  0.000296  0.720592           9     0\n",
            "6   0.239552  0.026894  0.138098  0.146421  0.110454  0.274027  1.346249e-02  6.593085e-04  0.003159  0.047274           5     0\n",
            "7   0.146379  0.007585  0.666229  0.015569  0.014476  0.094772  1.319467e-04  7.423334e-04  0.032704  0.021412           2     0\n",
            "8   0.506002  0.002152  0.003969  0.006174  0.000521  0.021481  6.928119e-03  3.721569e-01  0.000240  0.080376           0     0\n",
            "9   0.782595  0.003349  0.006702  0.001736  0.000098  0.019144  1.029886e-03  1.559310e-01  0.000472  0.028944           0     0\n",
            "10  0.071857  0.497766  0.400159  0.011540  0.009661  0.003973  5.634416e-07  1.983562e-08  0.004706  0.000339           1     0\n",
            "11  0.053841  0.410160  0.490066  0.010126  0.025096  0.008890  5.892962e-07  1.950943e-09  0.001715  0.000106           2     0\n",
            "12  0.451197  0.000863  0.034945  0.012940  0.000383  0.117246  8.308327e-03  2.817302e-01  0.002977  0.089412           0     0\n",
            "13  0.199399  0.004551  0.266916  0.095214  0.007169  0.191344  4.169062e-03  9.443027e-03  0.001799  0.219996           2     0\n",
            "14  0.095266  0.007012  0.418026  0.118430  0.025539  0.161535  8.597353e-03  1.289500e-03  0.159614  0.004690           2     0\n",
            "15  0.345783  0.000415  0.001026  0.000590  0.000026  0.005312  1.065250e-03  6.287726e-01  0.000064  0.016945           7     0\n",
            "16  0.361516  0.030672  0.043170  0.090735  0.053935  0.056607  3.790403e-03  4.872750e-03  0.001463  0.353239           0     0\n",
            "17  0.288098  0.026173  0.019156  0.093631  0.198850  0.113508  2.060332e-02  3.490423e-03  0.001438  0.235051           0     0\n",
            "18  0.510945  0.017656  0.035107  0.001020  0.001064  0.187076  7.120529e-04  2.320797e-03  0.236058  0.008040           0     0\n",
            "19  0.220605  0.005611  0.005781  0.002454  0.037540  0.651693  3.856415e-02  5.269992e-03  0.002243  0.030241           5     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/0/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/0/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/0/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.6227062253472818,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.5097985719546552,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168331',\n",
            "  'info': None,\n",
            "  'logloss': 1.0617810046745235,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.11701154708862305,\n",
            "  'result': 1.0617810046745235,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Volkert',\n",
            "  'training_duration': 172.11973929405212,\n",
            "  'utc': '2021-02-04T18:36:26',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Volkert.0.TabNet executed in 222.215 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Volkert.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Volkert.\n",
            "Assigning 6810 MB (total=13021 MB) for new Volkert task.\n",
            "Running task Volkert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Volkert', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6810, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 33.0%\n",
            "[499] Disk Usage: 28.6%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.96779 | val_0_accuracy: 0.13289 | val_1_accuracy: 0.13222 |  0:00:03s\n",
            "epoch 1  | loss: 1.53354 | val_0_accuracy: 0.30772 | val_1_accuracy: 0.30801 |  0:00:07s\n",
            "epoch 2  | loss: 1.43753 | val_0_accuracy: 0.27931 | val_1_accuracy: 0.27594 |  0:00:10s\n",
            "epoch 3  | loss: 1.37525 | val_0_accuracy: 0.30951 | val_1_accuracy: 0.30612 |  0:00:14s\n",
            "epoch 4  | loss: 1.31812 | val_0_accuracy: 0.34534 | val_1_accuracy: 0.34076 |  0:00:18s\n",
            "epoch 5  | loss: 1.28974 | val_0_accuracy: 0.34458 | val_1_accuracy: 0.34471 |  0:00:21s\n",
            "epoch 6  | loss: 1.2672  | val_0_accuracy: 0.35932 | val_1_accuracy: 0.36443 |  0:00:25s\n",
            "epoch 7  | loss: 1.24377 | val_0_accuracy: 0.33686 | val_1_accuracy: 0.33596 |  0:00:29s\n",
            "epoch 8  | loss: 1.23228 | val_0_accuracy: 0.38703 | val_1_accuracy: 0.38741 |  0:00:32s\n",
            "epoch 9  | loss: 1.21316 | val_0_accuracy: 0.42648 | val_1_accuracy: 0.42857 |  0:00:36s\n",
            "epoch 10 | loss: 1.20464 | val_0_accuracy: 0.4139  | val_1_accuracy: 0.4176  |  0:00:40s\n",
            "epoch 11 | loss: 1.19408 | val_0_accuracy: 0.44025 | val_1_accuracy: 0.44675 |  0:00:43s\n",
            "epoch 12 | loss: 1.17537 | val_0_accuracy: 0.47791 | val_1_accuracy: 0.4723  |  0:00:47s\n",
            "epoch 13 | loss: 1.16812 | val_0_accuracy: 0.48595 | val_1_accuracy: 0.47968 |  0:00:50s\n",
            "epoch 14 | loss: 1.15246 | val_0_accuracy: 0.51779 | val_1_accuracy: 0.51758 |  0:00:54s\n",
            "epoch 15 | loss: 1.14784 | val_0_accuracy: 0.53313 | val_1_accuracy: 0.5301  |  0:00:58s\n",
            "epoch 16 | loss: 1.14198 | val_0_accuracy: 0.56895 | val_1_accuracy: 0.56217 |  0:01:01s\n",
            "epoch 17 | loss: 1.1286  | val_0_accuracy: 0.58526 | val_1_accuracy: 0.57349 |  0:01:05s\n",
            "epoch 18 | loss: 1.12318 | val_0_accuracy: 0.60096 | val_1_accuracy: 0.58944 |  0:01:09s\n",
            "epoch 19 | loss: 1.11705 | val_0_accuracy: 0.59971 | val_1_accuracy: 0.58995 |  0:01:12s\n",
            "epoch 20 | loss: 1.10472 | val_0_accuracy: 0.62107 | val_1_accuracy: 0.61139 |  0:01:16s\n",
            "epoch 21 | loss: 1.1005  | val_0_accuracy: 0.62242 | val_1_accuracy: 0.61173 |  0:01:20s\n",
            "epoch 22 | loss: 1.0949  | val_0_accuracy: 0.6257  | val_1_accuracy: 0.6119  |  0:01:23s\n",
            "epoch 23 | loss: 1.0935  | val_0_accuracy: 0.6096  | val_1_accuracy: 0.60213 |  0:01:27s\n",
            "epoch 24 | loss: 1.0883  | val_0_accuracy: 0.6317  | val_1_accuracy: 0.61928 |  0:01:31s\n",
            "epoch 25 | loss: 1.07759 | val_0_accuracy: 0.62433 | val_1_accuracy: 0.60727 |  0:01:34s\n",
            "epoch 26 | loss: 1.07915 | val_0_accuracy: 0.62682 | val_1_accuracy: 0.61276 |  0:01:38s\n",
            "epoch 27 | loss: 1.06972 | val_0_accuracy: 0.6386  | val_1_accuracy: 0.62305 |  0:01:41s\n",
            "epoch 28 | loss: 1.06253 | val_0_accuracy: 0.64271 | val_1_accuracy: 0.62614 |  0:01:45s\n",
            "epoch 29 | loss: 1.06073 | val_0_accuracy: 0.63972 | val_1_accuracy: 0.62528 |  0:01:49s\n",
            "[499] CPU Utilization: 51.5%\n",
            "[499] Memory Usage: 33.1%\n",
            "[499] Disk Usage: 28.6%\n",
            "epoch 30 | loss: 1.05806 | val_0_accuracy: 0.64395 | val_1_accuracy: 0.62802 |  0:01:52s\n",
            "epoch 31 | loss: 1.05216 | val_0_accuracy: 0.63688 | val_1_accuracy: 0.61859 |  0:01:56s\n",
            "epoch 32 | loss: 1.04924 | val_0_accuracy: 0.65055 | val_1_accuracy: 0.633   |  0:02:00s\n",
            "epoch 33 | loss: 1.04526 | val_0_accuracy: 0.65234 | val_1_accuracy: 0.63145 |  0:02:03s\n",
            "epoch 34 | loss: 1.03677 | val_0_accuracy: 0.6503  | val_1_accuracy: 0.63248 |  0:02:07s\n",
            "epoch 35 | loss: 1.03555 | val_0_accuracy: 0.65137 | val_1_accuracy: 0.6318  |  0:02:11s\n",
            "epoch 36 | loss: 1.03037 | val_0_accuracy: 0.65561 | val_1_accuracy: 0.633   |  0:02:14s\n",
            "epoch 37 | loss: 1.02696 | val_0_accuracy: 0.6483  | val_1_accuracy: 0.6318  |  0:02:18s\n",
            "epoch 38 | loss: 1.02646 | val_0_accuracy: 0.65544 | val_1_accuracy: 0.63403 |  0:02:21s\n",
            "epoch 39 | loss: 1.0236  | val_0_accuracy: 0.65161 | val_1_accuracy: 0.62545 |  0:02:25s\n",
            "epoch 40 | loss: 1.02491 | val_0_accuracy: 0.65474 | val_1_accuracy: 0.63042 |  0:02:29s\n",
            "epoch 41 | loss: 1.02142 | val_0_accuracy: 0.65727 | val_1_accuracy: 0.63711 |  0:02:33s\n",
            "epoch 42 | loss: 1.01589 | val_0_accuracy: 0.65935 | val_1_accuracy: 0.6318  |  0:02:36s\n",
            "epoch 43 | loss: 1.01589 | val_0_accuracy: 0.6643  | val_1_accuracy: 0.64157 |  0:02:40s\n",
            "epoch 44 | loss: 1.00789 | val_0_accuracy: 0.65725 | val_1_accuracy: 0.64071 |  0:02:43s\n",
            "epoch 45 | loss: 1.00829 | val_0_accuracy: 0.66265 | val_1_accuracy: 0.633   |  0:02:47s\n",
            "epoch 46 | loss: 1.00505 | val_0_accuracy: 0.66531 | val_1_accuracy: 0.63934 |  0:02:51s\n",
            "epoch 47 | loss: 0.99692 | val_0_accuracy: 0.66331 | val_1_accuracy: 0.63763 |  0:02:54s\n",
            "epoch 48 | loss: 0.99766 | val_0_accuracy: 0.658   | val_1_accuracy: 0.63797 |  0:02:58s\n",
            "epoch 49 | loss: 0.99409 | val_0_accuracy: 0.66592 | val_1_accuracy: 0.63763 |  0:03:01s\n",
            "epoch 50 | loss: 0.992   | val_0_accuracy: 0.66516 | val_1_accuracy: 0.6402  |  0:03:05s\n",
            "epoch 51 | loss: 0.9971  | val_0_accuracy: 0.66646 | val_1_accuracy: 0.63334 |  0:03:09s\n",
            "epoch 52 | loss: 0.98918 | val_0_accuracy: 0.66592 | val_1_accuracy: 0.63385 |  0:03:12s\n",
            "epoch 53 | loss: 0.98958 | val_0_accuracy: 0.66714 | val_1_accuracy: 0.63797 |  0:03:16s\n",
            "\n",
            "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_1_accuracy = 0.64157\n",
            "Best weights from best epoch are automatically used!\n",
            "Predictions preview:\n",
            "            0         1         2         3         4         5         6         7         8         9 predictions truth\n",
            "0   0.293622  0.001562  0.068697  0.193455  0.012384  0.088628  0.008039  0.049063  0.000852  0.283698           0     0\n",
            "1   0.077710  0.026661  0.814662  0.014889  0.005250  0.041597  0.000060  0.000021  0.017400  0.001749           2     0\n",
            "2   0.753581  0.003761  0.033356  0.003102  0.000943  0.095660  0.001342  0.060519  0.034992  0.012744           0     0\n",
            "3   0.081673  0.008204  0.001691  0.073018  0.121704  0.005267  0.117371  0.383700  0.000042  0.207330           7     0\n",
            "4   0.204730  0.016543  0.004173  0.012156  0.068313  0.136545  0.001447  0.000045  0.000036  0.556011           9     0\n",
            "5   0.081659  0.002132  0.143397  0.148763  0.064166  0.404767  0.014465  0.000949  0.000699  0.139003           5     0\n",
            "6   0.027772  0.000053  0.000966  0.000247  0.000028  0.008069  0.002630  0.923959  0.000381  0.035895           7     0\n",
            "7   0.028773  0.113408  0.125212  0.069885  0.528197  0.054442  0.003512  0.000002  0.076532  0.000037           4     0\n",
            "8   0.111756  0.002908  0.374020  0.021557  0.003420  0.368576  0.004216  0.005502  0.009680  0.098365           2     0\n",
            "9   0.336246  0.002057  0.005993  0.003157  0.000755  0.023258  0.003569  0.518544  0.001910  0.104511           7     0\n",
            "10  0.169509  0.001192  0.402457  0.104251  0.002608  0.157586  0.001819  0.009172  0.003452  0.147955           2     0\n",
            "11  0.591135  0.046066  0.121720  0.001430  0.002675  0.138204  0.000906  0.009472  0.075203  0.013188           0     0\n",
            "12  0.750594  0.004547  0.013921  0.003996  0.001669  0.051165  0.002020  0.133082  0.010836  0.028170           0     0\n",
            "13  0.109520  0.006130  0.141850  0.013723  0.035804  0.645625  0.014508  0.000778  0.027520  0.004542           5     0\n",
            "14  0.163166  0.023912  0.271301  0.019767  0.018265  0.369892  0.002551  0.000146  0.128630  0.002370           5     0\n",
            "15  0.925802  0.023472  0.012807  0.003791  0.001697  0.008011  0.000069  0.004462  0.002195  0.017694           0     0\n",
            "16  0.228526  0.007366  0.011886  0.007285  0.001059  0.014976  0.004154  0.472717  0.002690  0.249339           7     0\n",
            "17  0.594966  0.001750  0.050233  0.007380  0.000470  0.089242  0.001722  0.184749  0.026375  0.043113           0     0\n",
            "18  0.184141  0.000397  0.003156  0.002296  0.000691  0.021875  0.005661  0.740391  0.000929  0.040464           7     0\n",
            "19  0.120488  0.005429  0.422815  0.076901  0.011462  0.305532  0.004014  0.000857  0.041550  0.010952           2     0\n",
            "\n",
            "Predictions saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/1/predictions.csv`.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/1/metadata.json`.\n",
            "Loading predictions from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Volkert/1/predictions.csv`.\n",
            "Metric scores: { 'acc': 0.6415709140799177,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': 0.5312479196457287,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/168331',\n",
            "  'info': None,\n",
            "  'logloss': 1.0245906115934345,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': 1,\n",
            "  'params': '',\n",
            "  'predict_duration': 0.11411523818969727,\n",
            "  'result': 1.0245906115934345,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Volkert',\n",
            "  'training_duration': 197.61194348335266,\n",
            "  'utc': '2021-02-04T18:40:06',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Volkert.1.TabNet executed in 220.812 seconds.\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Airlines.0.TabNet.\n",
            "[499] CPU Utilization: 45.2%\n",
            "[499] Memory Usage: 32.0%\n",
            "[499] Disk Usage: 28.6%\n",
            "Assigning 2 cores (total=2) for new task Airlines.\n",
            "Assigning 6806 MB (total=13021 MB) for new Airlines task.\n",
            "Running task Airlines on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Airlines', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6806, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'MQ'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'MQ'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189354',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'MQ'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Airlines',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T18:41:06',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Airlines.0.TabNet executed in 59.366 seconds.\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Airlines.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Airlines.\n",
            "Assigning 6759 MB (total=13021 MB) for new Airlines task.\n",
            "Running task Airlines on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Airlines', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6759, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'EV'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 25, in run\n",
            "    X_train, X_test = impute(dataset.train.X, dataset.test.X)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/datautils.py\", line 296, in impute\n",
            "    imputed = imputer.fit_transform(X_fit)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 268, in fit\n",
            "    X = self._validate_input(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/impute/_base.py\", line 240, in _validate_input\n",
            "    raise new_ve from None\n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'EV'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Airlines/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189354',\n",
            "  'info': 'ValueError: Cannot use mean strategy with non-numeric data:\\n'\n",
            "          \"could not convert string to float: 'EV'\",\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Airlines',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T18:41:20',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Airlines.1.TabNet executed in 14.680 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Albert.0.TabNet.\n",
            "[499] CPU Utilization: 41.1%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 28.8%\n",
            "Assigning 2 cores (total=2) for new task Albert.\n",
            "Assigning 6827 MB (total=13021 MB) for new Albert task.\n",
            "Running task Albert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Albert', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6827, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/0/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 49.7%\n",
            "[499] Memory Usage: 43.0%\n",
            "[499] Disk Usage: 29.0%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.66774 | val_0_auc: 0.68556 | val_1_auc: 0.68684 |  0:00:25s\n",
            "epoch 1  | loss: 0.63763 | val_0_auc: 0.68491 | val_1_auc: 0.68367 |  0:00:50s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 39.5%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 2  | loss: 0.63414 | val_0_auc: 0.69295 | val_1_auc: 0.69227 |  0:01:15s\n",
            "epoch 3  | loss: 0.63273 | val_0_auc: 0.69164 | val_1_auc: 0.69105 |  0:01:40s\n",
            "epoch 4  | loss: 0.63221 | val_0_auc: 0.68942 | val_1_auc: 0.68827 |  0:02:05s\n",
            "epoch 5  | loss: 0.63308 | val_0_auc: 0.69378 | val_1_auc: 0.69271 |  0:02:30s\n",
            "epoch 6  | loss: 0.63142 | val_0_auc: 0.69243 | val_1_auc: 0.6914  |  0:02:55s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 39.5%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 7  | loss: 0.6311  | val_0_auc: 0.69142 | val_1_auc: 0.69016 |  0:03:20s\n",
            "epoch 8  | loss: 0.62998 | val_0_auc: 0.69464 | val_1_auc: 0.69457 |  0:03:45s\n",
            "epoch 9  | loss: 0.62614 | val_0_auc: 0.70503 | val_1_auc: 0.70425 |  0:04:10s\n",
            "epoch 10 | loss: 0.62293 | val_0_auc: 0.70474 | val_1_auc: 0.70324 |  0:04:35s\n",
            "epoch 11 | loss: 0.61974 | val_0_auc: 0.71271 | val_1_auc: 0.71019 |  0:05:00s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.0%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 12 | loss: 0.61751 | val_0_auc: 0.71454 | val_1_auc: 0.71282 |  0:05:26s\n",
            "epoch 13 | loss: 0.61628 | val_0_auc: 0.71863 | val_1_auc: 0.71544 |  0:05:51s\n",
            "epoch 14 | loss: 0.61526 | val_0_auc: 0.71789 | val_1_auc: 0.71451 |  0:06:16s\n",
            "epoch 15 | loss: 0.6151  | val_0_auc: 0.72007 | val_1_auc: 0.71622 |  0:06:41s\n",
            "epoch 16 | loss: 0.61314 | val_0_auc: 0.72256 | val_1_auc: 0.71803 |  0:07:06s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.0%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 17 | loss: 0.61237 | val_0_auc: 0.71782 | val_1_auc: 0.7133  |  0:07:30s\n",
            "epoch 18 | loss: 0.61147 | val_0_auc: 0.72276 | val_1_auc: 0.71782 |  0:07:56s\n",
            "epoch 19 | loss: 0.61099 | val_0_auc: 0.71979 | val_1_auc: 0.71433 |  0:08:20s\n",
            "epoch 20 | loss: 0.61012 | val_0_auc: 0.72746 | val_1_auc: 0.72129 |  0:08:45s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.0%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 21 | loss: 0.60941 | val_0_auc: 0.72828 | val_1_auc: 0.72278 |  0:09:11s\n",
            "epoch 22 | loss: 0.60905 | val_0_auc: 0.72505 | val_1_auc: 0.7171  |  0:09:36s\n",
            "epoch 23 | loss: 0.60841 | val_0_auc: 0.7278  | val_1_auc: 0.72064 |  0:10:00s\n",
            "epoch 24 | loss: 0.60777 | val_0_auc: 0.72934 | val_1_auc: 0.72218 |  0:10:26s\n",
            "epoch 25 | loss: 0.60682 | val_0_auc: 0.72948 | val_1_auc: 0.72181 |  0:10:50s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.0%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 26 | loss: 0.60642 | val_0_auc: 0.73161 | val_1_auc: 0.72418 |  0:11:15s\n",
            "epoch 27 | loss: 0.606   | val_0_auc: 0.73173 | val_1_auc: 0.72411 |  0:11:40s\n",
            "epoch 28 | loss: 0.6052  | val_0_auc: 0.73052 | val_1_auc: 0.72234 |  0:12:05s\n",
            "epoch 29 | loss: 0.60565 | val_0_auc: 0.73397 | val_1_auc: 0.72661 |  0:12:30s\n",
            "epoch 30 | loss: 0.6052  | val_0_auc: 0.73216 | val_1_auc: 0.72312 |  0:12:56s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 39.9%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 31 | loss: 0.60453 | val_0_auc: 0.73469 | val_1_auc: 0.72565 |  0:13:20s\n",
            "epoch 32 | loss: 0.60374 | val_0_auc: 0.73502 | val_1_auc: 0.72527 |  0:13:45s\n",
            "epoch 33 | loss: 0.60373 | val_0_auc: 0.73532 | val_1_auc: 0.72609 |  0:14:10s\n",
            "epoch 34 | loss: 0.6033  | val_0_auc: 0.73462 | val_1_auc: 0.72385 |  0:14:36s\n",
            "epoch 35 | loss: 0.60329 | val_0_auc: 0.73544 | val_1_auc: 0.72719 |  0:15:00s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 39.9%\n",
            "[499] Disk Usage: 29.1%\n",
            "epoch 36 | loss: 0.60294 | val_0_auc: 0.73585 | val_1_auc: 0.72573 |  0:15:25s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 223, in fit\n",
            "    self._train_epoch(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 434, in _train_epoch\n",
            "    batch_logs = self._train_batch(X, y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 469, in _train_batch\n",
            "    output, M_loss = self.network(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 583, in forward\n",
            "    return self.tabnet(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 468, in forward\n",
            "    steps_output, M_loss = self.encoder(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 168, in forward\n",
            "    out = self.feat_transformers[step](masked_x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 703, in forward\n",
            "    x = self.shared(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 746, in forward\n",
            "    x = torch.add(x, self.glu_layers[glu_id](x))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 770, in forward\n",
            "    x = self.bn(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in forward\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in <listcomp>\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 111, in forward\n",
            "    self.num_batches_tracked = self.num_batches_tracked + 1\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189356',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Albert',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T19:01:22',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Albert.0.TabNet executed in 1201.050 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Albert.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Albert.\n",
            "Assigning 7032 MB (total=13021 MB) for new Albert task.\n",
            "Running task Albert on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Albert', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=7032, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 40.4%\n",
            "[499] Disk Usage: 29.2%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.66933 | val_0_auc: 0.67722 | val_1_auc: 0.6762  |  0:00:25s\n",
            "epoch 1  | loss: 0.64031 | val_0_auc: 0.67693 | val_1_auc: 0.67503 |  0:00:50s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 41.0%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 2  | loss: 0.63804 | val_0_auc: 0.67664 | val_1_auc: 0.67389 |  0:01:15s\n",
            "epoch 3  | loss: 0.63679 | val_0_auc: 0.68091 | val_1_auc: 0.67906 |  0:01:40s\n",
            "epoch 4  | loss: 0.6344  | val_0_auc: 0.68492 | val_1_auc: 0.68322 |  0:02:05s\n",
            "epoch 5  | loss: 0.63123 | val_0_auc: 0.69283 | val_1_auc: 0.68986 |  0:02:30s\n",
            "epoch 6  | loss: 0.6295  | val_0_auc: 0.69841 | val_1_auc: 0.69541 |  0:02:55s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.9%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 7  | loss: 0.62728 | val_0_auc: 0.69557 | val_1_auc: 0.69288 |  0:03:21s\n",
            "epoch 8  | loss: 0.62567 | val_0_auc: 0.70231 | val_1_auc: 0.69949 |  0:03:46s\n",
            "epoch 9  | loss: 0.62371 | val_0_auc: 0.70683 | val_1_auc: 0.70438 |  0:04:10s\n",
            "epoch 10 | loss: 0.62225 | val_0_auc: 0.71028 | val_1_auc: 0.70757 |  0:04:35s\n",
            "epoch 11 | loss: 0.61924 | val_0_auc: 0.71286 | val_1_auc: 0.70969 |  0:05:00s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.9%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 12 | loss: 0.61751 | val_0_auc: 0.71471 | val_1_auc: 0.71023 |  0:05:25s\n",
            "epoch 13 | loss: 0.61641 | val_0_auc: 0.71913 | val_1_auc: 0.71535 |  0:05:50s\n",
            "epoch 14 | loss: 0.61522 | val_0_auc: 0.71957 | val_1_auc: 0.71544 |  0:06:15s\n",
            "epoch 15 | loss: 0.61452 | val_0_auc: 0.72179 | val_1_auc: 0.71799 |  0:06:40s\n",
            "epoch 16 | loss: 0.61365 | val_0_auc: 0.72144 | val_1_auc: 0.71559 |  0:07:05s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 40.9%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 17 | loss: 0.61311 | val_0_auc: 0.72183 | val_1_auc: 0.71723 |  0:07:30s\n",
            "epoch 18 | loss: 0.61219 | val_0_auc: 0.72252 | val_1_auc: 0.71667 |  0:07:55s\n",
            "epoch 19 | loss: 0.61213 | val_0_auc: 0.72005 | val_1_auc: 0.7129  |  0:08:20s\n",
            "epoch 20 | loss: 0.61129 | val_0_auc: 0.72622 | val_1_auc: 0.72071 |  0:08:45s\n",
            "epoch 21 | loss: 0.61071 | val_0_auc: 0.7258  | val_1_auc: 0.71845 |  0:09:10s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.2%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 22 | loss: 0.61026 | val_0_auc: 0.72572 | val_1_auc: 0.71892 |  0:09:35s\n",
            "epoch 23 | loss: 0.61016 | val_0_auc: 0.7231  | val_1_auc: 0.71389 |  0:10:00s\n",
            "epoch 24 | loss: 0.6096  | val_0_auc: 0.72904 | val_1_auc: 0.72225 |  0:10:25s\n",
            "epoch 25 | loss: 0.60877 | val_0_auc: 0.72892 | val_1_auc: 0.72047 |  0:10:50s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.2%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 26 | loss: 0.60829 | val_0_auc: 0.72855 | val_1_auc: 0.72034 |  0:11:15s\n",
            "epoch 27 | loss: 0.60799 | val_0_auc: 0.72964 | val_1_auc: 0.72102 |  0:11:40s\n",
            "epoch 28 | loss: 0.60832 | val_0_auc: 0.72888 | val_1_auc: 0.71926 |  0:12:05s\n",
            "epoch 29 | loss: 0.60714 | val_0_auc: 0.7326  | val_1_auc: 0.72306 |  0:12:31s\n",
            "epoch 30 | loss: 0.60693 | val_0_auc: 0.72942 | val_1_auc: 0.71948 |  0:12:56s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.2%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 31 | loss: 0.60751 | val_0_auc: 0.73166 | val_1_auc: 0.72252 |  0:13:21s\n",
            "epoch 32 | loss: 0.60655 | val_0_auc: 0.73355 | val_1_auc: 0.72341 |  0:13:46s\n",
            "epoch 33 | loss: 0.60618 | val_0_auc: 0.73147 | val_1_auc: 0.72137 |  0:14:11s\n",
            "epoch 34 | loss: 0.60575 | val_0_auc: 0.73099 | val_1_auc: 0.71982 |  0:14:36s\n",
            "epoch 35 | loss: 0.60571 | val_0_auc: 0.73345 | val_1_auc: 0.72289 |  0:15:01s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.3%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 36 | loss: 0.60516 | val_0_auc: 0.73192 | val_1_auc: 0.72099 |  0:15:26s\n",
            "epoch 37 | loss: 0.60493 | val_0_auc: 0.73289 | val_1_auc: 0.72125 |  0:15:51s\n",
            "epoch 38 | loss: 0.60471 | val_0_auc: 0.73427 | val_1_auc: 0.72249 |  0:16:16s\n",
            "epoch 39 | loss: 0.60447 | val_0_auc: 0.73271 | val_1_auc: 0.72042 |  0:16:41s\n",
            "epoch 40 | loss: 0.60461 | val_0_auc: 0.73368 | val_1_auc: 0.72224 |  0:17:06s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 41.2%\n",
            "[499] Disk Usage: 29.2%\n",
            "epoch 41 | loss: 0.60407 | val_0_auc: 0.7339  | val_1_auc: 0.722   |  0:17:31s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 223, in fit\n",
            "    self._train_epoch(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 431, in _train_epoch\n",
            "    for batch_idx, (X, y) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 63, in default_collate\n",
            "    return default_collate([torch.as_tensor(b) for b in batch])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 63, in <listcomp>\n",
            "    return default_collate([torch.as_tensor(b) for b in batch])\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Albert/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'auc': nan,\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189356',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'auc',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Albert',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T19:21:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Albert.1.TabNet executed in 1201.028 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Covertype.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Covertype.\n",
            "Assigning 6955 MB (total=13021 MB) for new Covertype task.\n",
            "Running task Covertype on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Covertype', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6955, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/0/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 43.6%\n",
            "Removing ignored columns None.\n",
            "[499] Memory Usage: 34.3%\n",
            "[499] Disk Usage: 29.3%\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.75239 | val_0_accuracy: 0.74237 | val_1_accuracy: 0.74114 |  0:00:35s\n",
            "epoch 1  | loss: 0.59424 | val_0_accuracy: 0.7758  | val_1_accuracy: 0.77471 |  0:01:10s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 2  | loss: 0.54962 | val_0_accuracy: 0.79059 | val_1_accuracy: 0.78753 |  0:01:45s\n",
            "epoch 3  | loss: 0.52278 | val_0_accuracy: 0.80453 | val_1_accuracy: 0.80374 |  0:02:20s\n",
            "epoch 4  | loss: 0.50378 | val_0_accuracy: 0.81171 | val_1_accuracy: 0.8113  |  0:02:54s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 5  | loss: 0.49047 | val_0_accuracy: 0.81472 | val_1_accuracy: 0.81333 |  0:03:28s\n",
            "epoch 6  | loss: 0.4719  | val_0_accuracy: 0.81991 | val_1_accuracy: 0.81832 |  0:04:02s\n",
            "epoch 7  | loss: 0.46451 | val_0_accuracy: 0.83247 | val_1_accuracy: 0.83009 |  0:04:36s\n",
            "epoch 8  | loss: 0.45296 | val_0_accuracy: 0.83245 | val_1_accuracy: 0.83214 |  0:05:10s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.1%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 9  | loss: 0.44583 | val_0_accuracy: 0.8377  | val_1_accuracy: 0.83644 |  0:05:45s\n",
            "epoch 10 | loss: 0.44016 | val_0_accuracy: 0.83505 | val_1_accuracy: 0.83395 |  0:06:19s\n",
            "epoch 11 | loss: 0.43467 | val_0_accuracy: 0.83297 | val_1_accuracy: 0.83173 |  0:06:53s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 12 | loss: 0.43146 | val_0_accuracy: 0.84227 | val_1_accuracy: 0.84295 |  0:07:28s\n",
            "epoch 13 | loss: 0.42886 | val_0_accuracy: 0.84147 | val_1_accuracy: 0.83954 |  0:08:02s\n",
            "epoch 14 | loss: 0.42247 | val_0_accuracy: 0.84442 | val_1_accuracy: 0.844   |  0:08:36s\n",
            "epoch 15 | loss: 0.42128 | val_0_accuracy: 0.83083 | val_1_accuracy: 0.82916 |  0:09:10s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.1%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 16 | loss: 0.42195 | val_0_accuracy: 0.84531 | val_1_accuracy: 0.84484 |  0:09:44s\n",
            "epoch 17 | loss: 0.41903 | val_0_accuracy: 0.84609 | val_1_accuracy: 0.84525 |  0:10:18s\n",
            "epoch 18 | loss: 0.41805 | val_0_accuracy: 0.84834 | val_1_accuracy: 0.84617 |  0:10:52s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 19 | loss: 0.41307 | val_0_accuracy: 0.84808 | val_1_accuracy: 0.84567 |  0:11:26s\n",
            "epoch 20 | loss: 0.4158  | val_0_accuracy: 0.85154 | val_1_accuracy: 0.85071 |  0:11:59s\n",
            "epoch 21 | loss: 0.41128 | val_0_accuracy: 0.84736 | val_1_accuracy: 0.84792 |  0:12:33s\n",
            "epoch 22 | loss: 0.41085 | val_0_accuracy: 0.85531 | val_1_accuracy: 0.85408 |  0:13:07s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 23 | loss: 0.41306 | val_0_accuracy: 0.84983 | val_1_accuracy: 0.85026 |  0:13:41s\n",
            "epoch 24 | loss: 0.40761 | val_0_accuracy: 0.85353 | val_1_accuracy: 0.85176 |  0:14:15s\n",
            "epoch 25 | loss: 0.40372 | val_0_accuracy: 0.85449 | val_1_accuracy: 0.85348 |  0:14:49s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 26 | loss: 0.40486 | val_0_accuracy: 0.85673 | val_1_accuracy: 0.85402 |  0:15:23s\n",
            "epoch 27 | loss: 0.40207 | val_0_accuracy: 0.86005 | val_1_accuracy: 0.85851 |  0:15:57s\n",
            "epoch 28 | loss: 0.39868 | val_0_accuracy: 0.85675 | val_1_accuracy: 0.85465 |  0:16:30s\n",
            "epoch 29 | loss: 0.40456 | val_0_accuracy: 0.85394 | val_1_accuracy: 0.85267 |  0:17:04s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 34.0%\n",
            "[499] Disk Usage: 29.4%\n",
            "epoch 30 | loss: 0.39813 | val_0_accuracy: 0.85347 | val_1_accuracy: 0.85329 |  0:17:38s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 223, in fit\n",
            "    self._train_epoch(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 431, in _train_epoch\n",
            "    for batch_idx, (X, y) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 63, in default_collate\n",
            "    return default_collate([torch.as_tensor(b) for b in batch])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 63, in <listcomp>\n",
            "    return default_collate([torch.as_tensor(b) for b in batch])\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/7593',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Covertype',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T19:41:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Covertype.0.TabNet executed in 1200.271 seconds.\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Covertype.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Covertype.\n",
            "Assigning 6963 MB (total=13021 MB) for new Covertype task.\n",
            "Running task Covertype on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Covertype', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6963, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.75172 | val_0_accuracy: 0.73712 | val_1_accuracy: 0.73984 |  0:00:33s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 1  | loss: 0.60627 | val_0_accuracy: 0.75013 | val_1_accuracy: 0.75083 |  0:01:07s\n",
            "epoch 2  | loss: 0.56552 | val_0_accuracy: 0.78253 | val_1_accuracy: 0.78438 |  0:01:41s\n",
            "epoch 3  | loss: 0.53129 | val_0_accuracy: 0.79641 | val_1_accuracy: 0.79483 |  0:02:15s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 4  | loss: 0.50634 | val_0_accuracy: 0.81146 | val_1_accuracy: 0.80989 |  0:02:48s\n",
            "epoch 5  | loss: 0.48576 | val_0_accuracy: 0.81639 | val_1_accuracy: 0.81588 |  0:03:22s\n",
            "epoch 6  | loss: 0.46985 | val_0_accuracy: 0.82229 | val_1_accuracy: 0.81928 |  0:03:56s\n",
            "epoch 7  | loss: 0.46054 | val_0_accuracy: 0.82883 | val_1_accuracy: 0.82625 |  0:04:30s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 33.8%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 8  | loss: 0.45179 | val_0_accuracy: 0.82939 | val_1_accuracy: 0.82637 |  0:05:04s\n",
            "epoch 9  | loss: 0.44498 | val_0_accuracy: 0.83628 | val_1_accuracy: 0.83455 |  0:05:37s\n",
            "epoch 10 | loss: 0.43942 | val_0_accuracy: 0.83505 | val_1_accuracy: 0.83217 |  0:06:11s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 34.5%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 11 | loss: 0.43581 | val_0_accuracy: 0.84094 | val_1_accuracy: 0.83732 |  0:06:45s\n",
            "epoch 12 | loss: 0.43103 | val_0_accuracy: 0.84367 | val_1_accuracy: 0.84023 |  0:07:19s\n",
            "epoch 13 | loss: 0.42972 | val_0_accuracy: 0.84249 | val_1_accuracy: 0.83945 |  0:07:53s\n",
            "epoch 14 | loss: 0.42474 | val_0_accuracy: 0.84509 | val_1_accuracy: 0.84185 |  0:08:27s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 35.2%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 15 | loss: 0.42446 | val_0_accuracy: 0.83947 | val_1_accuracy: 0.83625 |  0:09:01s\n",
            "epoch 16 | loss: 0.43266 | val_0_accuracy: 0.84045 | val_1_accuracy: 0.83744 |  0:09:35s\n",
            "epoch 17 | loss: 0.42413 | val_0_accuracy: 0.84002 | val_1_accuracy: 0.83784 |  0:10:08s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 35.2%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 18 | loss: 0.42318 | val_0_accuracy: 0.84617 | val_1_accuracy: 0.8425  |  0:10:43s\n",
            "epoch 19 | loss: 0.41876 | val_0_accuracy: 0.84388 | val_1_accuracy: 0.84013 |  0:11:17s\n",
            "epoch 20 | loss: 0.41915 | val_0_accuracy: 0.84869 | val_1_accuracy: 0.84754 |  0:11:51s\n",
            "epoch 21 | loss: 0.41551 | val_0_accuracy: 0.84958 | val_1_accuracy: 0.84655 |  0:12:25s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 35.3%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 22 | loss: 0.41655 | val_0_accuracy: 0.85242 | val_1_accuracy: 0.8489  |  0:12:58s\n",
            "epoch 23 | loss: 0.41271 | val_0_accuracy: 0.85266 | val_1_accuracy: 0.84827 |  0:13:32s\n",
            "epoch 24 | loss: 0.41268 | val_0_accuracy: 0.85176 | val_1_accuracy: 0.84799 |  0:14:06s\n",
            "[499] CPU Utilization: 51.0%\n",
            "[499] Memory Usage: 35.3%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 25 | loss: 0.41068 | val_0_accuracy: 0.8517  | val_1_accuracy: 0.84803 |  0:14:40s\n",
            "epoch 26 | loss: 0.41031 | val_0_accuracy: 0.85218 | val_1_accuracy: 0.84813 |  0:15:14s\n",
            "epoch 27 | loss: 0.40981 | val_0_accuracy: 0.85087 | val_1_accuracy: 0.84865 |  0:15:48s\n",
            "epoch 28 | loss: 0.40708 | val_0_accuracy: 0.85487 | val_1_accuracy: 0.85128 |  0:16:21s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 35.2%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 29 | loss: 0.40459 | val_0_accuracy: 0.85379 | val_1_accuracy: 0.8505  |  0:16:55s\n",
            "epoch 30 | loss: 0.40542 | val_0_accuracy: 0.85303 | val_1_accuracy: 0.85004 |  0:17:29s\n",
            "epoch 31 | loss: 0.40602 | val_0_accuracy: 0.85242 | val_1_accuracy: 0.84883 |  0:18:03s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 35.2%\n",
            "[499] Disk Usage: 29.5%\n",
            "epoch 32 | loss: 0.40474 | val_0_accuracy: 0.85729 | val_1_accuracy: 0.85482 |  0:18:36s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 227, in fit\n",
            "    self._predict_epoch(eval_name, valid_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 504, in _predict_epoch\n",
            "    scores = self._predict_batch(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 532, in _predict_batch\n",
            "    scores, _ = self.network(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 583, in forward\n",
            "    return self.tabnet(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 468, in forward\n",
            "    steps_output, M_loss = self.encoder(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 168, in forward\n",
            "    out = self.feat_transformers[step](masked_x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 704, in forward\n",
            "    x = self.specifics(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 746, in forward\n",
            "    x = torch.add(x, self.glu_layers[glu_id](x))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 770, in forward\n",
            "    x = self.bn(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in forward\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in <listcomp>\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 136, in forward\n",
            "    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 2058, in batch_norm\n",
            "    training, momentum, eps, torch.backends.cudnn.enabled\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Covertype/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/7593',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Covertype',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T20:01:23',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Covertype.1.TabNet executed in 1200.284 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Dionis.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Dionis.\n",
            "Assigning 6933 MB (total=13021 MB) for new Dionis task.\n",
            "Running task Dionis on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Dionis', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028745, max_runtime_seconds=600, cores=2, max_mem_size_mb=6933, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/0/metadata.json')\n",
            "****TabNet****\n",
            "[499] CPU Utilization: 38.8%\n",
            "[499] Memory Usage: 35.4%\n",
            "[499] Disk Usage: 29.7%\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 3.93252 | val_0_accuracy: 0.40747 | val_1_accuracy: 0.40782 |  0:00:25s\n",
            "epoch 1  | loss: 2.16856 | val_0_accuracy: 0.56196 | val_1_accuracy: 0.56368 |  0:00:51s\n",
            "epoch 2  | loss: 1.82966 | val_0_accuracy: 0.59192 | val_1_accuracy: 0.59422 |  0:01:17s\n",
            "[499] CPU Utilization: 51.4%\n",
            "[499] Memory Usage: 37.4%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 3  | loss: 1.66618 | val_0_accuracy: 0.6388  | val_1_accuracy: 0.6362  |  0:01:43s\n",
            "epoch 4  | loss: 1.56138 | val_0_accuracy: 0.65565 | val_1_accuracy: 0.65345 |  0:02:09s\n",
            "epoch 5  | loss: 1.4824  | val_0_accuracy: 0.6717  | val_1_accuracy: 0.67116 |  0:02:35s\n",
            "epoch 6  | loss: 1.42352 | val_0_accuracy: 0.66877 | val_1_accuracy: 0.66748 |  0:03:01s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.4%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 7  | loss: 1.37887 | val_0_accuracy: 0.67862 | val_1_accuracy: 0.67746 |  0:03:28s\n",
            "epoch 8  | loss: 1.3405  | val_0_accuracy: 0.7087  | val_1_accuracy: 0.70581 |  0:03:55s\n",
            "epoch 9  | loss: 1.31091 | val_0_accuracy: 0.715   | val_1_accuracy: 0.7129  |  0:04:21s\n",
            "epoch 10 | loss: 1.28561 | val_0_accuracy: 0.69074 | val_1_accuracy: 0.69048 |  0:04:48s\n",
            "epoch 11 | loss: 1.26073 | val_0_accuracy: 0.72355 | val_1_accuracy: 0.72258 |  0:05:14s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.4%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 12 | loss: 1.24419 | val_0_accuracy: 0.72274 | val_1_accuracy: 0.72287 |  0:05:40s\n",
            "epoch 13 | loss: 1.22793 | val_0_accuracy: 0.72282 | val_1_accuracy: 0.71948 |  0:06:06s\n",
            "epoch 14 | loss: 1.21559 | val_0_accuracy: 0.73708 | val_1_accuracy: 0.7349  |  0:06:33s\n",
            "epoch 15 | loss: 1.20509 | val_0_accuracy: 0.73582 | val_1_accuracy: 0.73553 |  0:06:59s\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 37.5%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 16 | loss: 1.19262 | val_0_accuracy: 0.73526 | val_1_accuracy: 0.73293 |  0:07:26s\n",
            "epoch 17 | loss: 1.18315 | val_0_accuracy: 0.74354 | val_1_accuracy: 0.74127 |  0:07:52s\n",
            "epoch 18 | loss: 1.17163 | val_0_accuracy: 0.73472 | val_1_accuracy: 0.73027 |  0:08:19s\n",
            "epoch 19 | loss: 1.1645  | val_0_accuracy: 0.72664 | val_1_accuracy: 0.72292 |  0:08:45s\n",
            "epoch 20 | loss: 1.16021 | val_0_accuracy: 0.74825 | val_1_accuracy: 0.74656 |  0:09:12s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.6%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 21 | loss: 1.15306 | val_0_accuracy: 0.7477  | val_1_accuracy: 0.74456 |  0:09:38s\n",
            "epoch 22 | loss: 1.1485  | val_0_accuracy: 0.66418 | val_1_accuracy: 0.66268 |  0:10:04s\n",
            "epoch 23 | loss: 1.14301 | val_0_accuracy: 0.71392 | val_1_accuracy: 0.71208 |  0:10:31s\n",
            "epoch 24 | loss: 1.13459 | val_0_accuracy: 0.75273 | val_1_accuracy: 0.75281 |  0:10:57s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.5%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 25 | loss: 1.13208 | val_0_accuracy: 0.74663 | val_1_accuracy: 0.74483 |  0:11:23s\n",
            "epoch 26 | loss: 1.12359 | val_0_accuracy: 0.72914 | val_1_accuracy: 0.72767 |  0:11:50s\n",
            "epoch 27 | loss: 1.12061 | val_0_accuracy: 0.74367 | val_1_accuracy: 0.74187 |  0:12:16s\n",
            "epoch 28 | loss: 1.114   | val_0_accuracy: 0.7448  | val_1_accuracy: 0.74257 |  0:12:42s\n",
            "epoch 29 | loss: 1.11678 | val_0_accuracy: 0.75808 | val_1_accuracy: 0.75747 |  0:13:08s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.5%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 30 | loss: 1.1108  | val_0_accuracy: 0.72228 | val_1_accuracy: 0.72239 |  0:13:35s\n",
            "epoch 31 | loss: 1.10409 | val_0_accuracy: 0.76573 | val_1_accuracy: 0.76316 |  0:14:01s\n",
            "epoch 32 | loss: 1.10031 | val_0_accuracy: 0.74603 | val_1_accuracy: 0.74596 |  0:14:28s\n",
            "epoch 33 | loss: 1.09859 | val_0_accuracy: 0.74852 | val_1_accuracy: 0.74802 |  0:14:54s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.4%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 34 | loss: 1.09023 | val_0_accuracy: 0.74367 | val_1_accuracy: 0.74158 |  0:15:20s\n",
            "epoch 35 | loss: 1.08976 | val_0_accuracy: 0.75877 | val_1_accuracy: 0.75732 |  0:15:47s\n",
            "epoch 36 | loss: 1.08937 | val_0_accuracy: 0.7553  | val_1_accuracy: 0.75417 |  0:16:14s\n",
            "epoch 37 | loss: 1.08376 | val_0_accuracy: 0.74011 | val_1_accuracy: 0.73805 |  0:16:40s\n",
            "epoch 38 | loss: 1.0793  | val_0_accuracy: 0.74278 | val_1_accuracy: 0.74192 |  0:17:06s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 37.5%\n",
            "[499] Disk Usage: 29.8%\n",
            "epoch 39 | loss: 1.07236 | val_0_accuracy: 0.70771 | val_1_accuracy: 0.70362 |  0:17:32s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 223, in fit\n",
            "    self._train_epoch(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 434, in _train_epoch\n",
            "    batch_logs = self._train_batch(X, y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 469, in _train_batch\n",
            "    output, M_loss = self.network(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 583, in forward\n",
            "    return self.tabnet(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 468, in forward\n",
            "    steps_output, M_loss = self.encoder(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 156, in forward\n",
            "    att = self.initial_splitter(x)[:, self.n_d :]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 704, in forward\n",
            "    x = self.specifics(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 746, in forward\n",
            "    x = torch.add(x, self.glu_layers[glu_id](x))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 770, in forward\n",
            "    x = self.bn(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in forward\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/tab_network.py\", line 36, in <listcomp>\n",
            "    res = [self.bn(x_) for x_ in chunks]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 136, in forward\n",
            "    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 2058, in batch_norm\n",
            "    training, momentum, eps, torch.backends.cudnn.enabled\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/0/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189355',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028745,\n",
            "  'task': 'Dionis',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T20:21:24',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Dionis.0.TabNet executed in 1200.639 seconds.\n",
            "\n",
            "------------------------------------------------------------\n",
            "Starting job local.benchmark39datasets.test.Dionis.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task Dionis.\n",
            "Assigning 6877 MB (total=13021 MB) for new Dionis task.\n",
            "Running task Dionis on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='Dionis', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=1547028746, max_runtime_seconds=600, cores=2, max_mem_size_mb=6877, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/1/metadata.json')\n",
            "****TabNet****\n",
            "Removing ignored columns None.\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 4.08305 | val_0_accuracy: 0.37603 | val_1_accuracy: 0.37589 |  0:00:26s\n",
            "[499] CPU Utilization: 50.4%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 1  | loss: 2.24689 | val_0_accuracy: 0.51886 | val_1_accuracy: 0.51741 |  0:00:52s\n",
            "epoch 2  | loss: 1.86828 | val_0_accuracy: 0.58982 | val_1_accuracy: 0.59151 |  0:01:18s\n",
            "epoch 3  | loss: 1.68644 | val_0_accuracy: 0.613   | val_1_accuracy: 0.6097  |  0:01:44s\n",
            "epoch 4  | loss: 1.55514 | val_0_accuracy: 0.65225 | val_1_accuracy: 0.65095 |  0:02:10s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.7%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 5  | loss: 1.46708 | val_0_accuracy: 0.67034 | val_1_accuracy: 0.66758 |  0:02:37s\n",
            "epoch 6  | loss: 1.40776 | val_0_accuracy: 0.67271 | val_1_accuracy: 0.67037 |  0:03:03s\n",
            "epoch 7  | loss: 1.36815 | val_0_accuracy: 0.69444 | val_1_accuracy: 0.69158 |  0:03:29s\n",
            "epoch 8  | loss: 1.33479 | val_0_accuracy: 0.64159 | val_1_accuracy: 0.64153 |  0:03:56s\n",
            "epoch 9  | loss: 1.30541 | val_0_accuracy: 0.68196 | val_1_accuracy: 0.67991 |  0:04:22s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 10 | loss: 1.2809  | val_0_accuracy: 0.68415 | val_1_accuracy: 0.68387 |  0:04:48s\n",
            "epoch 11 | loss: 1.26472 | val_0_accuracy: 0.67768 | val_1_accuracy: 0.67628 |  0:05:14s\n",
            "epoch 12 | loss: 1.24203 | val_0_accuracy: 0.72467 | val_1_accuracy: 0.72167 |  0:05:41s\n",
            "epoch 13 | loss: 1.23393 | val_0_accuracy: 0.70743 | val_1_accuracy: 0.70441 |  0:06:08s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.4%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 14 | loss: 1.21379 | val_0_accuracy: 0.72835 | val_1_accuracy: 0.72438 |  0:06:34s\n",
            "epoch 15 | loss: 1.20056 | val_0_accuracy: 0.72418 | val_1_accuracy: 0.72099 |  0:07:00s\n",
            "epoch 16 | loss: 1.19251 | val_0_accuracy: 0.72737 | val_1_accuracy: 0.72532 |  0:07:26s\n",
            "epoch 17 | loss: 1.18021 | val_0_accuracy: 0.73495 | val_1_accuracy: 0.73149 |  0:07:53s\n",
            "epoch 18 | loss: 1.17442 | val_0_accuracy: 0.74438 | val_1_accuracy: 0.74146 |  0:08:19s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 19 | loss: 1.15929 | val_0_accuracy: 0.74335 | val_1_accuracy: 0.7399  |  0:08:46s\n",
            "epoch 20 | loss: 1.15634 | val_0_accuracy: 0.73823 | val_1_accuracy: 0.73553 |  0:09:12s\n",
            "epoch 21 | loss: 1.14874 | val_0_accuracy: 0.72548 | val_1_accuracy: 0.72188 |  0:09:39s\n",
            "epoch 22 | loss: 1.14065 | val_0_accuracy: 0.73134 | val_1_accuracy: 0.72964 |  0:10:05s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 23 | loss: 1.13513 | val_0_accuracy: 0.74    | val_1_accuracy: 0.73899 |  0:10:31s\n",
            "epoch 24 | loss: 1.12613 | val_0_accuracy: 0.72622 | val_1_accuracy: 0.72402 |  0:10:58s\n",
            "epoch 25 | loss: 1.12257 | val_0_accuracy: 0.74015 | val_1_accuracy: 0.73733 |  0:11:24s\n",
            "epoch 26 | loss: 1.11769 | val_0_accuracy: 0.74488 | val_1_accuracy: 0.74118 |  0:11:50s\n",
            "epoch 27 | loss: 1.11348 | val_0_accuracy: 0.75822 | val_1_accuracy: 0.75468 |  0:12:17s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 28 | loss: 1.11145 | val_0_accuracy: 0.72474 | val_1_accuracy: 0.72284 |  0:12:43s\n",
            "epoch 29 | loss: 1.10619 | val_0_accuracy: 0.73807 | val_1_accuracy: 0.73558 |  0:13:10s\n",
            "epoch 30 | loss: 1.1066  | val_0_accuracy: 0.75698 | val_1_accuracy: 0.75415 |  0:13:36s\n",
            "epoch 31 | loss: 1.0993  | val_0_accuracy: 0.7431  | val_1_accuracy: 0.74158 |  0:14:02s\n",
            "epoch 32 | loss: 1.09591 | val_0_accuracy: 0.75196 | val_1_accuracy: 0.74978 |  0:14:29s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 33 | loss: 1.09217 | val_0_accuracy: 0.75313 | val_1_accuracy: 0.75064 |  0:14:55s\n",
            "epoch 34 | loss: 1.08844 | val_0_accuracy: 0.74237 | val_1_accuracy: 0.73933 |  0:15:21s\n",
            "epoch 35 | loss: 1.08465 | val_0_accuracy: 0.7378  | val_1_accuracy: 0.73587 |  0:15:48s\n",
            "epoch 36 | loss: 1.08337 | val_0_accuracy: 0.75131 | val_1_accuracy: 0.74879 |  0:16:14s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 37 | loss: 1.08165 | val_0_accuracy: 0.76849 | val_1_accuracy: 0.76388 |  0:16:41s\n",
            "epoch 38 | loss: 1.07661 | val_0_accuracy: 0.7429  | val_1_accuracy: 0.73894 |  0:17:07s\n",
            "epoch 39 | loss: 1.07375 | val_0_accuracy: 0.74159 | val_1_accuracy: 0.73834 |  0:17:34s\n",
            "epoch 40 | loss: 1.07223 | val_0_accuracy: 0.75235 | val_1_accuracy: 0.74822 |  0:18:00s\n",
            "epoch 41 | loss: 1.07015 | val_0_accuracy: 0.76504 | val_1_accuracy: 0.76215 |  0:18:26s\n",
            "[499] CPU Utilization: 51.1%\n",
            "[499] Memory Usage: 36.5%\n",
            "[499] Disk Usage: 29.9%\n",
            "epoch 42 | loss: 1.06925 | val_0_accuracy: 0.76642 | val_1_accuracy: 0.76294 |  0:18:53s\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Interrupting thread current after 1200s timeout.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 3, in run\n",
            "    return run(*args, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 44, in run\n",
            "    predictor.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 223, in fit\n",
            "    self._train_epoch(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 434, in _train_epoch\n",
            "    batch_logs = self._train_batch(X, y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_tabnet/abstract_model.py\", line 478, in _train_batch\n",
            "    clip_grad_norm_(self.network.parameters(), self.clip_value)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\", line 40, in clip_grad_norm_\n",
            "    p.grad.detach().mul_(clip_coef.to(p.grad.device))\n",
            "amlb.utils.process.TimeoutError: Interrupting thread current after 1200s timeout.\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/predictions/Dionis/1/metadata.json`.\n",
            "Metric scores: { 'acc': nan,\n",
            "  'app_version': 'dev [master, 24f7370]',\n",
            "  'balacc': nan,\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': 'TabNet',\n",
            "  'id': 'openml.org/t/189355',\n",
            "  'info': 'TimeoutError: Interrupting thread current after 1200s timeout.',\n",
            "  'logloss': nan,\n",
            "  'metric': 'logloss',\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': 1547028746,\n",
            "  'task': 'Dionis',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-04T20:41:24',\n",
            "  'version': 'stable'}\n",
            "Job local.benchmark39datasets.test.Dionis.1.TabNet executed in 1200.637 seconds.\n",
            "All jobs executed in 18549.632 seconds.\n",
            "[499] CPU Utilization: 51.2%\n",
            "[499] Memory Usage: 31.6%\n",
            "[499] Disk Usage: 29.9%\n",
            "Processing results for tabnet.benchmark39datasets.test.local.20210204T153206\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/scores/TabNet.benchmark_benchmark39datasets.csv`.\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.benchmark39datasets.test.local.20210204T153206/scores/results.csv`.\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/results.csv`.\n",
            "Summing up scores for current run:\n",
            "                     id                                    task framework constraint fold     result   metric   mode version params            app_version                  utc  duration  training_duration  predict_duration models_count        seed                                                                                                             info       acc       auc    balacc    logloss\n",
            "0   openml.org/t/146818                              Australian    TabNet       test    0   0.665110      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:35:43     208.2                7.3               0.0            1  1547028745                                                                                                             None  0.565217  0.665110  0.593379   2.346500\n",
            "1   openml.org/t/146818                              Australian    TabNet       test    1   0.732598      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:35:44       1.3                1.2               0.0            1  1547028746                                                                                                             None  0.608696  0.732598  0.635823   1.799330\n",
            "2    openml.org/t/10101                       blood-transfusion    TabNet       test    0   0.750000      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:35:57      12.6                2.7               0.0            1  1547028745                                                                                                             None  0.773333  0.750000  0.565789   0.678053\n",
            "3    openml.org/t/10101                       blood-transfusion    TabNet       test    1   0.717836      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:35:58       0.9                0.8               0.0            1  1547028746                                                                                                             None  0.480000  0.717836  0.619883   6.585850\n",
            "4   openml.org/t/146821                                     car    TabNet       test    0        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:36:09      11.1                NaN               NaN               1547028745            ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'low'       NaN       NaN       NaN        NaN\n",
            "5   openml.org/t/146821                                     car    TabNet       test    1        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:36:09       0.1                NaN               NaN               1547028746            ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'low'       NaN       NaN       NaN        NaN\n",
            "6   openml.org/t/168908                               christine    TabNet       test    0   0.703435      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:37:23      74.3               27.9               0.0            1  1547028745                                                                                                             None  0.642066  0.703435  0.642066   0.635640\n",
            "7   openml.org/t/168908                               christine    TabNet       test    1   0.691834      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:38:07      43.7               24.4               0.0            1  1547028746                                                                                                             None  0.654982  0.691834  0.654982   0.650253\n",
            "8     openml.org/t/9981                                  cnae-9    TabNet       test    0   2.197630  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:38:20      12.7                1.1               0.0            1  1547028745                                                                                                             None  0.111111       NaN  0.111111   2.197630\n",
            "9     openml.org/t/9981                                  cnae-9    TabNet       test    1   2.197070  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:38:22       2.7                1.3               0.0            1  1547028746                                                                                                             None  0.120370       NaN  0.120370   2.197070\n",
            "10      openml.org/t/31                                credit-g    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:38:33      10.8                NaN               NaN               1547028745          ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: '>=200'       NaN       NaN       NaN        NaN\n",
            "11      openml.org/t/31                                credit-g    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:38:33       0.1                NaN               NaN               1547028746    ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'no checking'       NaN       NaN       NaN        NaN\n",
            "12  openml.org/t/168909                                 dilbert    TabNet       test    0   0.107218  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:42:28     235.2              130.3               0.0            1  1547028745                                                                                                             None  0.975000       NaN  0.975158   0.107218\n",
            "13  openml.org/t/168909                                 dilbert    TabNet       test    1   0.067492  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:45:13     164.6              114.0               0.0            1  1547028746                                                                                                             None  0.983000       NaN  0.982937   0.067492\n",
            "14  openml.org/t/168910                                  fabert    TabNet       test    0   0.924907  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:46:32      79.4               48.5               0.0            1  1547028745                                                                                                             None  0.666262       NaN  0.653443   0.924907\n",
            "15  openml.org/t/168910                                  fabert    TabNet       test    1   1.896580  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:46:52      19.7                7.2               0.0            1  1547028746                                                                                                             None  0.234223       NaN  0.142857   1.896580\n",
            "16  openml.org/t/168911                                 jasmine    TabNet       test    0   0.810962      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:10      17.7                3.7               0.0            1  1547028745                                                                                                             None  0.745819  0.810962  0.745526   0.546293\n",
            "17  openml.org/t/168911                                 jasmine    TabNet       test    1   0.842774      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:19       9.5                8.2               0.0            1  1547028746                                                                                                             None  0.769231  0.842774  0.768501   0.552931\n",
            "18    openml.org/t/3917                                     kc1    TabNet       test    0   0.787797      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:37      17.1                5.3               0.0            1  1547028745                                                                                                             None  0.824645  0.787797  0.575855   0.423865\n",
            "19    openml.org/t/3917                                     kc1    TabNet       test    1   0.799756      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:42       5.0                4.9               0.0            1  1547028746                                                                                                             None  0.848341  0.799756  0.615485   0.409858\n",
            "20       openml.org/t/3                                kr-vs-kp    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:53      11.5                NaN               NaN               1547028745              ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'f'       NaN       NaN       NaN        NaN\n",
            "21       openml.org/t/3                                kr-vs-kp    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:47:53       0.4                NaN               NaN               1547028746              ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'f'       NaN       NaN       NaN        NaN\n",
            "22      openml.org/t/12                           mfeat-factors    TabNet       test    0  20.870200  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:48:08      14.1                1.6               0.0            1  1547028745                                                                                                             None  0.145000       NaN  0.145000  20.870200\n",
            "23      openml.org/t/12                           mfeat-factors    TabNet       test    1  15.604900  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:48:10       2.7                1.8               0.0            1  1547028746                                                                                                             None  0.155000       NaN  0.155000  15.604900\n",
            "24    openml.org/t/9952                                 phoneme    TabNet       test    0   0.912839      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:48:34      23.8               12.6               0.0            1  1547028745                                                                                                             None  0.841035  0.912839  0.801154   0.339076\n",
            "25    openml.org/t/9952                                 phoneme    TabNet       test    1   0.940515      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:48:56      21.7               21.6               0.0            1  1547028746                                                                                                             None  0.879852  0.940515  0.859849   0.281499\n",
            "26  openml.org/t/146822                                 segment    TabNet       test    0   0.331295  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:49:17      21.2               11.0               0.0            1  1547028745                                                                                                             None  0.883117       NaN  0.883117   0.331295\n",
            "27  openml.org/t/146822                                 segment    TabNet       test    1   0.410711  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:49:26       9.4                9.2               0.0            1  1547028746                                                                                                             None  0.839827       NaN  0.839827   0.410711\n",
            "28  openml.org/t/168912                                 sylvine    TabNet       test    0   0.824720      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:49:46      19.3                8.0               0.0            1  1547028745                                                                                                             None  0.500975  0.824720  0.500000   6.608270\n",
            "29  openml.org/t/168912                                 sylvine    TabNet       test    1   0.574728      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:49:50       4.4                4.1               0.0            1  1547028746                                                                                                             None  0.551657  0.574728  0.551496   4.208100\n",
            "30      openml.org/t/53                                 vehicle    TabNet       test    0  14.759500  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:50:00      10.4                0.9               0.0            1  1547028745                                                                                                             None  0.294118       NaN  0.290747  14.759500\n",
            "31      openml.org/t/53                                 vehicle    TabNet       test    1  11.606100  logloss  local  stable         dev [master, 24f7370]  2021-02-04T15:50:02       1.7                1.6               0.0            1  1547028746                                                                                                             None  0.364706       NaN  0.372673  11.606100\n",
            "32    openml.org/t/7592                                   adult    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:50:19      16.9                NaN               NaN               1547028745   ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'Self-emp-inc'       NaN       NaN       NaN        NaN\n",
            "33    openml.org/t/7592                                   adult    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:50:21       2.1                NaN               NaN               1547028746        ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'Private'       NaN       NaN       NaN        NaN\n",
            "34   openml.org/t/34539                  Amazon_employee_access    TabNet       test    0   0.645287      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:52:06     104.6               89.0               0.1            1  1547028745                                                                                                             None  0.942630  0.645287  0.502646   0.212743\n",
            "35   openml.org/t/34539                  Amazon_employee_access    TabNet       test    1   0.649575      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:53:14      67.8               66.3               0.1            1  1547028746                                                                                                             None  0.942325  0.649575  0.500000   0.213820\n",
            "36  openml.org/t/168868                              APSFailure    TabNet       test    0   0.983078      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:55:23     129.5               74.5               0.1            1  1547028745                                                                                                             None  0.982368  0.983078  0.528862   0.041514\n",
            "37  openml.org/t/168868                              APSFailure    TabNet       test    1   0.971553      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:58:23     179.8              155.9               0.1            1  1547028746                                                                                                             None  0.982632  0.971553  0.657971   0.045305\n",
            "38   openml.org/t/14965                          bank-marketing    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:58:40      16.8                NaN               NaN               1547028745  ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'self-employed'       NaN       NaN       NaN        NaN\n",
            "39   openml.org/t/14965                          bank-marketing    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T15:58:42       1.8                NaN               NaN               1547028746     ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'management'       NaN       NaN       NaN        NaN\n",
            "40  openml.org/t/146195                               connect-4    TabNet       test    0   0.514358  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:05:32     410.3              380.0               0.1            1  1547028745                                                                                                             None  0.799438       NaN  0.580531   0.514358\n",
            "41  openml.org/t/146195                               connect-4    TabNet       test    1   0.519632  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:11:21     349.3              344.1               0.1            1  1547028746                                                                                                             None  0.800326       NaN  0.562234   0.519632\n",
            "42  openml.org/t/146825                           Fashion-MNIST    TabNet       test    0   0.331777  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:16:30     308.5              160.5               0.2            1  1547028745                                                                                                             None  0.884571       NaN  0.884571   0.331777\n",
            "43  openml.org/t/146825                           Fashion-MNIST    TabNet       test    1   0.328028  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:21:40     310.5              224.2               0.2            1  1547028746                                                                                                             None  0.892571       NaN  0.892571   0.328028\n",
            "44  openml.org/t/168337                               guillermo    TabNet       test    0   0.588562      auc  local  stable         dev [master, 24f7370]  2021-02-04T16:34:56     796.1              158.4               0.2            1  1547028745                                                                                                             None  0.602500  0.588562  0.505000   0.660193\n",
            "45  openml.org/t/168337                               guillermo    TabNet       test    1   0.834462      auc  local  stable         dev [master, 24f7370]  2021-02-04T16:47:28     751.6              400.3               0.2            1  1547028746                                                                                                             None  0.761000  0.834462  0.756250   0.647939\n",
            "46  openml.org/t/168329                                  Helena    TabNet       test    0   2.830910  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:51:35     247.3              222.2               0.1            1  1547028745                                                                                                             None  0.326534       NaN  0.141379   2.830910\n",
            "47  openml.org/t/168329                                  Helena    TabNet       test    1   2.854170  logloss  local  stable         dev [master, 24f7370]  2021-02-04T16:54:48     193.8              186.6               0.1            1  1547028746                                                                                                             None  0.329908       NaN  0.136954   2.854170\n",
            "48  openml.org/t/146606                                   higgs    TabNet       test    0   0.802082      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:03:35     525.8              495.1               0.2            1  1547028745                                                                                                             None  0.726874  0.802082  0.723347   0.539780\n",
            "49  openml.org/t/146606                                   higgs    TabNet       test    1   0.802103      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:09:54     378.9              370.2               0.2            1  1547028746                                                                                                             None  0.721469  0.802103  0.717626   0.537807\n",
            "50  openml.org/t/168330                                  Jannis    TabNet       test    0   0.711791  logloss  local  stable         dev [master, 24f7370]  2021-02-04T17:14:59     305.1              269.0               0.2            1  1547028745                                                                                                             None  0.709100       NaN  0.524639   0.711791\n",
            "51  openml.org/t/168330                                  Jannis    TabNet       test    1   0.689200  logloss  local  stable         dev [master, 24f7370]  2021-02-04T17:20:28     329.4              317.3               0.2            1  1547028746                                                                                                             None  0.725579       NaN  0.545650   0.689200\n",
            "52  openml.org/t/167119  jungle_chess_2pcs_raw_endgame_complete    TabNet       test    0   0.327449  logloss  local  stable         dev [master, 24f7370]  2021-02-04T17:22:11     103.0               88.8               0.1            1  1547028745                                                                                                             None  0.859661       NaN  0.800722   0.327449\n",
            "53  openml.org/t/167119  jungle_chess_2pcs_raw_endgame_complete    TabNet       test    1   0.270969  logloss  local  stable         dev [master, 24f7370]  2021-02-04T17:24:58     166.6              165.4               0.1            1  1547028746                                                                                                             None  0.867247       NaN  0.804243   0.270969\n",
            "54    openml.org/t/3945                      KDDCup09_appetency    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:25:33      35.0                NaN               NaN               1547028745           ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'r__I'       NaN       NaN       NaN        NaN\n",
            "55    openml.org/t/3945                      KDDCup09_appetency    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:25:46      12.8                NaN               NaN               1547028746           ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'r__I'       NaN       NaN       NaN        NaN\n",
            "56  openml.org/t/168335                               MiniBooNE    TabNet       test    0   0.953000      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:29:30     224.7              177.8               0.2            1  1547028745                                                                                                             None  0.739679  0.953000  0.536833   0.524337\n",
            "57  openml.org/t/168335                               MiniBooNE    TabNet       test    1   0.933235      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:31:51     141.0              122.9               0.3            1  1547028746                                                                                                             None  0.826632  0.933235  0.698866   0.407592\n",
            "58    openml.org/t/9977                                   nomao    TabNet       test    0   0.991872      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:34:35     163.6              139.9               0.1            1  1547028745                                                                                                             None  0.958805  0.991872  0.950120   0.104709\n",
            "59    openml.org/t/9977                                   nomao    TabNet       test    1   0.991260      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:36:23     107.9              100.0               0.1            1  1547028746                                                                                                             None  0.957354  0.991260  0.948525   0.108710\n",
            "60  openml.org/t/167120                             numerai28_6    TabNet       test    0   0.518327      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:38:55     152.6              123.9               0.2            1  1547028745                                                                                                             None  0.515677  0.518327  0.514166   0.692854\n",
            "61  openml.org/t/167120                             numerai28_6    TabNet       test    1   0.530825      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:41:16     140.6              133.6               0.2            1  1547028746                                                                                                             None  0.520453  0.530825  0.519502   0.692010\n",
            "62  openml.org/t/168338                                riccardo    TabNet       test    0   0.997144      auc  local  stable         dev [master, 24f7370]  2021-02-04T17:54:35     799.3              170.8               0.2            1  1547028745                                                                                                             None  0.990000  0.997144  0.993333   0.036618\n",
            "63  openml.org/t/168338                                riccardo    TabNet       test    1   0.997672      auc  local  stable         dev [master, 24f7370]  2021-02-04T18:04:46     610.4              262.2               0.2            1  1547028746                                                                                                             None  0.992000  0.997672  0.994667   0.033011\n",
            "64  openml.org/t/168332                                  Robert    TabNet       test    0   1.942760  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:19:09     863.8              213.7               0.1            1  1547028745                                                                                                             None  0.316000       NaN  0.318428   1.942760\n",
            "65  openml.org/t/168332                                  Robert    TabNet       test    1   1.876270  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:28:55     585.4              252.2               0.1            1  1547028746                                                                                                             None  0.338000       NaN  0.338554   1.876270\n",
            "66  openml.org/t/146212                                 Shuttle    TabNet       test    0   0.020630  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:30:53     118.5              101.8               0.1            1  1547028745                                                                                                             None  0.997069       NaN  0.658355   0.020630\n",
            "67  openml.org/t/146212                                 Shuttle    TabNet       test    1   0.010419  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:32:43     110.1              108.2               0.1            1  1547028746                                                                                                             None  0.998103       NaN  0.712605   0.010419\n",
            "68  openml.org/t/168331                                 Volkert    TabNet       test    0   1.061780  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:36:26     222.2              172.1               0.1            1  1547028745                                                                                                             None  0.622706       NaN  0.509799   1.061780\n",
            "69  openml.org/t/168331                                 Volkert    TabNet       test    1   1.024590  logloss  local  stable         dev [master, 24f7370]  2021-02-04T18:40:06     220.8              197.6               0.1            1  1547028746                                                                                                             None  0.641571       NaN  0.531248   1.024590\n",
            "70  openml.org/t/189354                                Airlines    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T18:41:06      59.4                NaN               NaN               1547028745             ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'MQ'       NaN       NaN       NaN        NaN\n",
            "71  openml.org/t/189354                                Airlines    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T18:41:20      14.7                NaN               NaN               1547028746             ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'EV'       NaN       NaN       NaN        NaN\n",
            "72  openml.org/t/189356                                  Albert    TabNet       test    0        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T19:01:22    1201.1                NaN               NaN               1547028745                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n",
            "73  openml.org/t/189356                                  Albert    TabNet       test    1        NaN      auc  local  stable         dev [master, 24f7370]  2021-02-04T19:21:23    1201.0                NaN               NaN               1547028746                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n",
            "74    openml.org/t/7593                               Covertype    TabNet       test    0        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T19:41:23    1200.3                NaN               NaN               1547028745                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n",
            "75    openml.org/t/7593                               Covertype    TabNet       test    1        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T20:01:23    1200.3                NaN               NaN               1547028746                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n",
            "76  openml.org/t/189355                                  Dionis    TabNet       test    0        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T20:21:24    1200.6                NaN               NaN               1547028745                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n",
            "77  openml.org/t/189355                                  Dionis    TabNet       test    1        NaN  logloss  local  stable         dev [master, 24f7370]  2021-02-04T20:41:24    1200.6                NaN               NaN               1547028746                                                   TimeoutError: Interrupting thread current after 1200s timeout.       NaN       NaN       NaN        NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzkHctNC9QTD",
        "outputId": "ab4caaf0-20c8-4c8d-ab9a-22a12603306f"
      },
      "source": [
        "! python3 runbenchmark.py TabNet strfloatdata"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running `TabNet` on `strfloatdata` benchmarks in `local` mode.\n",
            "Loading frameworks definitions from /content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/resources/frameworks.yaml.\n",
            "Loading benchmark constraint definitions from /content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/resources/constraints.yaml.\n",
            "Loading benchmark definitions from /content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/resources/benchmarks/strfloatdata.yaml.\n",
            "Setting up framework TabNet.\n",
            "Setup of framework TabNet completed successfully.\n",
            "\n",
            "--------------------------------------------------\n",
            "Starting job local.strfloatdata.test.car.0.TabNet.\n",
            "[1836] CPU Utilization: 47.1%\n",
            "[1836] Memory Usage: 8.3%\n",
            "[1836] Disk Usage: 14.7%\n",
            "Assigning 2 cores (total=2) for new task car.\n",
            "Assigning 9896 MB (total=13021 MB) for new car task.\n",
            "Running task car on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='car', fold=0, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9896, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/146821',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'car',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.car.0.TabNet executed in 0.648 seconds.\n",
            "\n",
            "--------------------------------------------------\n",
            "Starting job local.strfloatdata.test.car.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task car.\n",
            "Assigning 9894 MB (total=13021 MB) for new car task.\n",
            "Running task car on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='car', fold=1, metrics=['logloss', 'acc', 'balacc'], metric='logloss', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/car/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/146821',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'car',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.car.1.TabNet executed in 0.038 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.credit-g.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task credit-g.\n",
            "Assigning 9894 MB (total=13021 MB) for new credit-g task.\n",
            "Running task credit-g on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='credit-g', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/31',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'credit-g',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.credit-g.0.TabNet executed in 0.035 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.credit-g.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task credit-g.\n",
            "Assigning 9894 MB (total=13021 MB) for new credit-g task.\n",
            "Running task credit-g on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='credit-g', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/credit-g/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/31',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'credit-g',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.credit-g.1.TabNet executed in 0.034 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.kr-vs-kp.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task kr-vs-kp.\n",
            "Assigning 9894 MB (total=13021 MB) for new kr-vs-kp task.\n",
            "Running task kr-vs-kp on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='kr-vs-kp', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'kr-vs-kp',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.kr-vs-kp.0.TabNet executed in 0.047 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.kr-vs-kp.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task kr-vs-kp.\n",
            "Assigning 9894 MB (total=13021 MB) for new kr-vs-kp task.\n",
            "Running task kr-vs-kp on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='kr-vs-kp', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'kr-vs-kp',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.kr-vs-kp.1.TabNet executed in 0.044 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.kr-vs-kp.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task kr-vs-kp.\n",
            "Assigning 9894 MB (total=13021 MB) for new kr-vs-kp task.\n",
            "Running task kr-vs-kp on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='kr-vs-kp', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9894, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'kr-vs-kp',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.kr-vs-kp.0.TabNet executed in 0.043 seconds.\n",
            "\n",
            "-------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.kr-vs-kp.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task kr-vs-kp.\n",
            "Assigning 9890 MB (total=13021 MB) for new kr-vs-kp task.\n",
            "Running task kr-vs-kp on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='kr-vs-kp', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9890, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/kr-vs-kp/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'kr-vs-kp',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.kr-vs-kp.1.TabNet executed in 0.059 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.bank-marketing.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task bank-marketing.\n",
            "Assigning 9890 MB (total=13021 MB) for new bank-marketing task.\n",
            "Running task bank-marketing on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='bank-marketing', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9890, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/14965',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'bank-marketing',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.bank-marketing.0.TabNet executed in 0.116 seconds.\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.bank-marketing.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task bank-marketing.\n",
            "Assigning 9890 MB (total=13021 MB) for new bank-marketing task.\n",
            "Running task bank-marketing on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='bank-marketing', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9890, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/bank-marketing/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/14965',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'bank-marketing',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:21',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.bank-marketing.1.TabNet executed in 0.060 seconds.\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.KDDCup09_appetency.0.TabNet.\n",
            "Assigning 2 cores (total=2) for new task KDDCup09_appetency.\n",
            "Assigning 9883 MB (total=13021 MB) for new KDDCup09_appetency task.\n",
            "Running task KDDCup09_appetency on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='KDDCup09_appetency', fold=0, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876490, max_runtime_seconds=600, cores=2, max_mem_size_mb=9883, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/0/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/0/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/0/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/0/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 0,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3945',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'KDDCup09_appetency',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:23',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.KDDCup09_appetency.0.TabNet executed in 1.278 seconds.\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "Starting job local.strfloatdata.test.KDDCup09_appetency.1.TabNet.\n",
            "Assigning 2 cores (total=2) for new task KDDCup09_appetency.\n",
            "Assigning 9879 MB (total=13021 MB) for new KDDCup09_appetency task.\n",
            "Running task KDDCup09_appetency on framework TabNet with config:\n",
            "TaskConfig(framework='TabNet', framework_params={}, framework_version='stable', type='classification', name='KDDCup09_appetency', fold=1, metrics=['auc', 'logloss', 'acc', 'balacc'], metric='auc', seed=461876491, max_runtime_seconds=600, cores=2, max_mem_size_mb=9879, min_vol_size_mb=-1, input_dir='/root/.openml/cache', output_dir='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220', output_predictions_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/1/predictions.csv', ext={}, output_metadata_file='/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/1/metadata.json')\n",
            "No module named 'sklearn.preporcessing'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/amlb/benchmark.py\", line 446, in run\n",
            "    meta_result = self.benchmark.framework_module.run(self._dataset, task_config)\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/__init__.py\", line 2, in run\n",
            "    from .exec import run\n",
            "  File \"/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/frameworks/TabNet/exec.py\", line 9, in <module>\n",
            "    from sklearn.preporcessing import OrdinalEncoder\n",
            "ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "Loading metadata from `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/1/metadata.json`.\n",
            "Metadata file `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/predictions/KDDCup09_appetency/1/metadata.json` is missing: framework either couldn't start or implementation doesn't save metadata.\n",
            "Metric scores: { 'app_version': 'dev [master, 24f7370]',\n",
            "  'constraint': 'test',\n",
            "  'duration': nan,\n",
            "  'fold': 1,\n",
            "  'framework': None,\n",
            "  'id': 'openml.org/t/3945',\n",
            "  'info': \"ModuleNotFoundError: No module named 'sklearn.preporcessing'\",\n",
            "  'metric': None,\n",
            "  'mode': 'local',\n",
            "  'models_count': nan,\n",
            "  'params': '',\n",
            "  'predict_duration': nan,\n",
            "  'result': nan,\n",
            "  'seed': None,\n",
            "  'task': 'KDDCup09_appetency',\n",
            "  'training_duration': nan,\n",
            "  'utc': '2021-02-05T08:42:24',\n",
            "  'version': None}\n",
            "Job local.strfloatdata.test.KDDCup09_appetency.1.TabNet executed in 1.191 seconds.\n",
            "All jobs executed in 3.612 seconds.\n",
            "[1836] CPU Utilization: 47.5%\n",
            "[1836] Memory Usage: 8.4%\n",
            "[1836] Disk Usage: 14.7%\n",
            "Processing results for tabnet.strfloatdata.test.local.20210205T084220\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/scores/TabNet.benchmark_strfloatdata.csv`.\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/tabnet.strfloatdata.test.local.20210205T084220/scores/results.csv`.\n",
            "Scores saved to `/content/gdrive/My Drive/AutoML_benchmark/automlbenchmark/results/results.csv`.\n",
            "Summing up scores for current run:\n",
            "                     id                task constraint fold   mode params            app_version                  utc  duration models_count seed                                                          info\n",
            "0   openml.org/t/146821                 car       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.6                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "1   openml.org/t/146821                 car       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "2       openml.org/t/31            credit-g       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "3       openml.org/t/31            credit-g       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "4        openml.org/t/3            kr-vs-kp       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "5        openml.org/t/3            kr-vs-kp       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "6        openml.org/t/3            kr-vs-kp       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.0                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "7        openml.org/t/3            kr-vs-kp       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.1                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "8    openml.org/t/14965      bank-marketing       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.1                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "9    openml.org/t/14965      bank-marketing       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:21       0.1                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "10    openml.org/t/3945  KDDCup09_appetency       test    0  local         dev [master, 24f7370]  2021-02-05T08:42:23       1.3                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n",
            "11    openml.org/t/3945  KDDCup09_appetency       test    1  local         dev [master, 24f7370]  2021-02-05T08:42:24       1.2                    ModuleNotFoundError: No module named 'sklearn.preporcessing'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1-XS2KP9Ws0",
        "outputId": "a2c5c0f7-dcee-40c6-e7e8-c77aa226f757"
      },
      "source": [
        "! python3 runbenchmark.py TabNet large"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[632] CPU Utilization: 51.3%\n",
            "[632] Memory Usage: 22.0%\n",
            "[632] Disk Usage: 14.7%\n",
            "Processing results for tabnet.large.test.local.20210205T065135\n",
            "Scores saved to `/content/gdrive/MyDrive/AutoML_benchmark/automlbenchmark/results/tabnet.large.test.local.20210205T065135/scores/TabNet.benchmark_large.csv`.\n",
            "Scores saved to `/content/gdrive/MyDrive/AutoML_benchmark/automlbenchmark/results/tabnet.large.test.local.20210205T065135/scores/results.csv`.\n",
            "Scores saved to `/content/gdrive/MyDrive/AutoML_benchmark/automlbenchmark/results/results.csv`.\n",
            "Summing up scores for current run:\n",
            "                    id      task framework constraint fold metric   mode version params            app_version                  utc  duration models_count       seed                                                                                                  info\n",
            "0  openml.org/t/189354  Airlines    TabNet       test    0    auc  local  stable         dev [master, 24f7370]  2021-02-05T06:54:05     147.0               609978832  ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'MQ'\n",
            "1  openml.org/t/189354  Airlines    TabNet       test    1    auc  local  stable         dev [master, 24f7370]  2021-02-05T06:54:23      17.8               609978833  ValueError: Cannot use mean strategy with non-numeric data:\\ncould not convert string to float: 'EV'\n",
            "2  openml.org/t/189356    Albert    TabNet       test    0    auc  local  stable         dev [master, 24f7370]  2021-02-05T07:14:24    1201.2               609978832                                        TimeoutError: Interrupting thread current after 1200s timeout.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNDa658Ezc9J"
      },
      "source": [
        "! python3 runbenchmark.py DecisionTree large"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}